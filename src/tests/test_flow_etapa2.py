#!/usr/bin/env python
"""
üß™ TESTES DA ETAPA 2 - AN√ÅLISES PARALELAS

Este arquivo testa:
- Execu√ß√£o paralela de an√°lises
- Dependencies com and_() e or_()
- Performance otimizada
- Consolida√ß√£o de resultados
"""

import unittest
import sys
import time
from datetime import datetime, timedelta
from unittest.mock import patch, MagicMock

# Importar m√≥dulos para teste
from insights.flow_main import InsightsFlow, criar_flow_com_parametros
from insights.flow_integration import InsightsRunner, run_insights

class TestEtapa2Parallelization(unittest.TestCase):
    """Testes para an√°lises paralelas da Etapa 2"""
    
    def setUp(self):
        """Configurar ambiente de teste"""
        self.data_inicio = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
        self.data_fim = datetime.now().strftime('%Y-%m-%d')
    
    def test_parallel_analysis_trigger(self):
        """Testar se an√°lises paralelas s√£o acionadas corretamente"""
        try:
            flow = criar_flow_com_parametros(self.data_inicio, self.data_fim)
            
            # Simular estado ap√≥s extra√ß√£o de dados
            flow.state.dados_extraidos = True
            flow.state.qualidade_dados = {"score_confiabilidade": 85.0}
            flow.state.pode_executar_analises_basicas = True
            
            # Verificar se m√©todos de an√°lise paralela existem
            self.assertTrue(hasattr(flow, 'executar_analise_tendencias'))
            self.assertTrue(hasattr(flow, 'executar_analise_sazonalidade'))
            self.assertTrue(hasattr(flow, 'executar_analise_segmentos'))
            self.assertTrue(hasattr(flow, 'executar_analise_projecoes'))
            
            print("‚úÖ Test Parallel Analysis Trigger: PASSOU")
            
        except Exception as e:
            print(f"‚ùå Test Parallel Analysis Trigger: FALHOU - {e}")
            self.fail(f"Falha no teste de acionamento paralelo: {e}")
    
    def test_dependency_system(self):
        """Testar sistema de depend√™ncias and_() e or_()"""
        try:
            flow = criar_flow_com_parametros(self.data_inicio, self.data_fim)
            
            # Verificar se proje√ß√µes tem depend√™ncia correta
            projecoes_method = flow.executar_analise_projecoes
            self.assertTrue(hasattr(projecoes_method, '__trigger_methods__'))
            
            # Verificar se relat√≥rio final tem depend√™ncia or_()
            relatorio_method = flow.gerar_relatorio_final
            self.assertTrue(hasattr(relatorio_method, '__trigger_methods__'))
            
            print("‚úÖ Test Dependency System: PASSOU")
            
        except Exception as e:
            print(f"‚ùå Test Dependency System: FALHOU - {e}")
            self.fail(f"Falha no sistema de depend√™ncias: {e}")
    
    def test_state_management_parallel(self):
        """Testar gerenciamento de estado durante execu√ß√£o paralela"""
        try:
            flow = criar_flow_com_parametros(self.data_inicio, self.data_fim)
            
            # Verificar estrutura inicial dos estados das an√°lises
            expected_analyses = [
                'analise_tendencias', 'analise_sazonalidade', 
                'analise_segmentos', 'analise_projecoes'
            ]
            
            for analysis in expected_analyses:
                self.assertTrue(hasattr(flow.state, analysis))
                self.assertIsInstance(getattr(flow.state, analysis), dict)
            
            # Verificar campos de controle
            self.assertIsInstance(flow.state.analises_concluidas, list)
            self.assertIsInstance(flow.state.analises_em_execucao, list)
            self.assertIsInstance(flow.state.tempo_por_analise, dict)
            
            print("‚úÖ Test State Management Parallel: PASSOU")
            
        except Exception as e:
            print(f"‚ùå Test State Management Parallel: FALHOU - {e}")
            self.fail(f"Falha no gerenciamento de estado: {e}")

class TestEtapa2Performance(unittest.TestCase):
    """Testes de performance da Etapa 2"""
    
    def test_cache_efficiency(self):
        """Testar efici√™ncia do cache de crews"""
        try:
            flow = criar_flow_com_parametros(
                (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d'),
                datetime.now().strftime('%Y-%m-%d')
            )
            
            # Verificar se cache est√° inicializado
            self.assertIsInstance(flow.crews_cache, dict)
            self.assertEqual(len(flow.crews_cache), 0)  # Inicialmente vazio
            
            # Simular adi√ß√£o ao cache
            flow.crews_cache["test_crew"] = "mock_crew"
            self.assertEqual(len(flow.crews_cache), 1)
            
            print("‚úÖ Test Cache Efficiency: PASSOU")
            
        except Exception as e:
            print(f"‚ùå Test Cache Efficiency: FALHOU - {e}")
            self.fail(f"Falha no teste de cache: {e}")
    
    def test_progress_tracking(self):
        """Testar rastreamento de progresso das an√°lises"""
        try:
            flow = criar_flow_com_parametros(
                (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d'),
                datetime.now().strftime('%Y-%m-%d')
            )
            
            # Verificar progresso inicial
            self.assertEqual(flow.state.progresso_percent, 0.0)
            
            # Simular avan√ßo de progresso
            flow.state.progresso_percent = 45.0
            self.assertEqual(flow.state.progresso_percent, 45.0)
            
            # Verificar se status √© atualiz√°vel
            status = flow.get_status_detalhado()
            self.assertIn('progresso_percent', status)
            
            print("‚úÖ Test Progress Tracking: PASSOU")
            
        except Exception as e:
            print(f"‚ùå Test Progress Tracking: FALHOU - {e}")
            self.fail(f"Falha no rastreamento de progresso: {e}")

class TestEtapa2Integration(unittest.TestCase):
    """Testes de integra√ß√£o da Etapa 2"""
    
    def test_integration_with_etapa1(self):
        """Testar integra√ß√£o com funcionalidades da Etapa 1"""
        try:
            # Testar se todas as funcionalidades da Etapa 1 ainda funcionam
            runner = InsightsRunner()
            
            # Verificar se ainda consegue decidir entre Flow/Crew
            criterios = runner._analisar_criterios_execucao(
                (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d'),
                datetime.now().strftime('%Y-%m-%d')
            )
            
            self.assertIn('usar_flow', criterios)
            self.assertIn('razoes', criterios)
            
            print("‚úÖ Test Integration with Etapa1: PASSOU")
            
        except Exception as e:
            print(f"‚ùå Test Integration with Etapa1: FALHOU - {e}")
            self.fail(f"Falha na integra√ß√£o com Etapa 1: {e}")
    
    def test_backward_compatibility(self):
        """Testar compatibilidade retroativa"""
        try:
            # Verificar se sistema h√≠brido ainda funciona
            from insights.flow_integration import run_insights
            
            # Testar imports
            from insights.flow_main import InsightsFlow
            from insights.crew import Insights
            
            print("‚úÖ Test Backward Compatibility: PASSOU")
            
        except Exception as e:
            print(f"‚ùå Test Backward Compatibility: FALHOU - {e}")
            self.fail(f"Falha na compatibilidade retroativa: {e}")

def run_etapa2_basic_test():
    """Teste b√°sico da Etapa 2"""
    print("üß™ EXECUTANDO TESTE B√ÅSICO DA ETAPA 2")
    print("=" * 50)
    
    try:
        # Configurar per√≠odo de teste
        data_fim = datetime.now().strftime('%Y-%m-%d')
        data_inicio = (datetime.now() - timedelta(days=14)).strftime('%Y-%m-%d')
        
        print(f"üìÖ Per√≠odo de teste: {data_inicio} a {data_fim}")
        
        # Testar cria√ß√£o do Flow com Etapa 2
        print("üîß Testando Flow com an√°lises paralelas...")
        flow = criar_flow_com_parametros(data_inicio, data_fim, "completo")
        print(f"‚úÖ Flow Etapa 2 criado: ID {flow.state.flow_id}")
        
        # Verificar m√©todos da Etapa 2
        print("üìä Verificando m√©todos paralelos...")
        parallel_methods = [
            'executar_analise_tendencias',
            'executar_analise_sazonalidade', 
            'executar_analise_segmentos',
            'executar_analise_projecoes',
            'gerar_relatorio_final'
        ]
        
        for method in parallel_methods:
            if hasattr(flow, method):
                print(f"‚úÖ {method}")
            else:
                raise Exception(f"M√©todo {method} n√£o encontrado")
        
        # Testar estado estruturado
        print("üóÇÔ∏è Verificando estado estruturado...")
        required_state_fields = [
            'analise_tendencias', 'analise_sazonalidade',
            'analise_segmentos', 'analise_projecoes'
        ]
        
        for field in required_state_fields:
            if hasattr(flow.state, field):
                print(f"‚úÖ Estado: {field}")
            else:
                raise Exception(f"Campo de estado {field} n√£o encontrado")
        
        print("=" * 50)
        print("üéâ TESTE B√ÅSICO DA ETAPA 2 CONCLU√çDO COM SUCESSO!")
        return True
        
    except Exception as e:
        print(f"‚ùå TESTE B√ÅSICO DA ETAPA 2 FALHOU: {e}")
        return False

def test_corrected_flow_execution():
    """Testar se o Flow corrigido executa e gera outputs"""
    print("üß™ TESTANDO FLOW CORRIGIDO COM GERA√á√ÉO DE OUTPUTS")
    print("=" * 60)
    
    try:
        from insights.flow_main import criar_flow_com_parametros
        from pathlib import Path
        import os
        
        # Limpar outputs antigos
        output_dir = Path("output")
        if output_dir.exists():
            for old_file in output_dir.glob("*flow_*"):
                try:
                    old_file.unlink()
                    print(f"üóëÔ∏è Removido arquivo antigo: {old_file.name}")
                except:
                    pass
        
        # Configurar per√≠odo de teste
        data_fim = datetime.now().strftime('%Y-%m-%d')
        data_inicio = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
        
        print(f"üìÖ Per√≠odo de teste: {data_inicio} a {data_fim}")
        
        # Criar flow
        flow = criar_flow_com_parametros(data_inicio, data_fim, "completo")
        print(f"‚úÖ Flow criado: ID {flow.state.flow_id}")
        
        # Simular execu√ß√£o das an√°lises paralelas
        flow.state.dados_extraidos = True
        flow.state.qualidade_dados = {"score_confiabilidade": 85.0, "total_registros": 15000}
        flow.state.pode_executar_analises_basicas = True
        
        # Testar File Generation Tool corrigida
        from insights.tools.file_generation_tool import FileGenerationTool
        file_tool = FileGenerationTool()
        
        # Teste de gera√ß√£o JSON
        resultado_json = file_tool._run(
            file_type="json",
            filename="teste_correcao.json",
            content='{"teste": "correcao_funcionando", "timestamp": "2025-01-27"}',
            output_path="output/teste_correcao.json"
        )
        print(f"‚úÖ Teste JSON: {resultado_json}")
        
        # Teste de gera√ß√£o CSV
        resultado_csv = file_tool._run(
            file_type="csv",
            filename="teste_correcao.csv",
            content="coluna1,coluna2\nvalor1,valor2\n",
            output_path="output/teste_correcao.csv"
        )
        print(f"‚úÖ Teste CSV: {resultado_csv}")
        
        # Teste de gera√ß√£o Markdown
        resultado_md = file_tool._run(
            file_type="markdown",
            filename="teste_correcao.md",
            content="# Teste de Corre√ß√£o\n\nEste √© um teste das corre√ß√µes aplicadas.\n",
            output_path="output/teste_correcao.md"
        )
        print(f"‚úÖ Teste Markdown: {resultado_md}")
        
        # Verificar se arquivos foram criados
        arquivos_gerados = []
        for arquivo in ["teste_correcao.json", "teste_correcao.csv", "teste_correcao.md"]:
            filepath = output_dir / arquivo
            if filepath.exists():
                arquivos_gerados.append(arquivo)
                print(f"üìÅ Arquivo criado: {arquivo} ({filepath.stat().st_size} bytes)")
        
        print(f"\nüìä RESULTADO DO TESTE:")
        print(f"‚úÖ Arquivos gerados: {len(arquivos_gerados)}/3")
        
        if len(arquivos_gerados) == 3:
            print("üéâ TODAS AS CORRE√á√ïES FUNCIONANDO!")
            return True
        else:
            print("‚ö†Ô∏è Algumas corre√ß√µes precisam de ajuste")
            return False
            
    except Exception as e:
        print(f"‚ùå Erro no teste de corre√ß√µes: {e}")
        return False

if __name__ == "__main__":
    print("üöÄ INICIANDO TESTES DA ETAPA 2 - AN√ÅLISES PARALELAS")
    print("=" * 70)
    
    # Executar teste de corre√ß√µes primeiro
    corrected_test_ok = test_corrected_flow_execution()
    print()
    
    # Executar teste b√°sico
    basic_test_ok = run_etapa2_basic_test()
    print()
    
    if basic_test_ok:
        print("üöÄ EXECUTANDO TESTES UNIT√ÅRIOS DA ETAPA 2")
        print("=" * 70)
        
        # Executar testes unit√°rios
        unittest.main(verbosity=2, exit=False)
        
        print("=" * 70)
        print("‚úÖ TODOS OS TESTES DA ETAPA 2 CONCLU√çDOS!")
        print()
        print("üéØ PR√ìXIMOS PASSOS:")
        print("   1. Execute: python src/insights/main.py --mode flow")
        print("   2. Teste: python src/insights/test_flow.py")
        print("   3. Compare performance: Etapa 1 vs Etapa 2")
        print("=" * 70)
    else:
        print("‚ùå TESTES B√ÅSICOS DA ETAPA 2 FALHARAM - Verificar implementa√ß√£o")
        sys.exit(1) 
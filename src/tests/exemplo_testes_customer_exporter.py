"""
EXEMPLO: Como Usar as Fun√ß√µes de Teste do CustomerDataExporter
==============================================================

Este exemplo demonstra como utilizar as novas funcionalidades de teste
implementadas no CustomerDataExporter.
"""

from src.insights.tools.customer_data_exporter import CustomerDataExporter

def demonstrar_testes_customer_exporter():
    """Demonstra como usar as fun√ß√µes de teste do CustomerDataExporter"""
    
    print("üéØ DEMONSTRA√á√ÉO: Testes do CustomerDataExporter")
    print("=" * 60)
    
    # Instanciar a ferramenta
    exporter = CustomerDataExporter()
    
    print("\nüìã TIPOS DE TESTE DISPON√çVEIS:")
    print("1. Teste Completo com Relat√≥rio (run_full_customer_test)")
    print("2. Teste JSON Estruturado (test_all_customer_components)")
    print("3. Teste de Componente Individual (usando _run)")
    
    # 1. TESTE COMPLETO COM RELAT√ìRIO MARKDOWN
    print("\n" + "="*60)
    print("1Ô∏è‚É£ EXECUTANDO TESTE COMPLETO COM RELAT√ìRIO")
    print("="*60)
    
    try:
        print("üìä Executando teste completo...")
        report_markdown = exporter.run_full_customer_test()
        
        print("‚úÖ Teste conclu√≠do com sucesso!")
        print(f"üìÑ Relat√≥rio gerado: {len(report_markdown):,} caracteres")
        
        # Salvar relat√≥rio com timestamp
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"exemplos_output/customer_test_report_{timestamp}.md"
        
        import os
        os.makedirs("exemplos_output", exist_ok=True)
        with open(report_file, "w", encoding="utf-8") as f:
            f.write(report_markdown)
        
        print(f"üíæ Relat√≥rio salvo em: {report_file}")
        
        # Exibir preview do relat√≥rio
        print("\nüìñ PREVIEW DO RELAT√ìRIO:")
        print("-" * 40)
        lines = report_markdown.split('\n')[:20]  # Primeiras 20 linhas
        for line in lines:
            print(line)
        print("...")
        
    except Exception as e:
        print(f"‚ùå Erro no teste completo: {str(e)}")
    
    # 2. TESTE JSON ESTRUTURADO
    print("\n" + "="*60)
    print("2Ô∏è‚É£ EXECUTANDO TESTE JSON ESTRUTURADO")
    print("="*60)
    
    try:
        print("üìä Executando teste com sa√≠da JSON...")
        json_result = exporter.test_all_customer_components()
        
        import json
        parsed_result = json.loads(json_result)
        
        print("‚úÖ Teste JSON conclu√≠do!")
        print(f"üìä Status: {parsed_result['metadata']['status']}")
        print(f"üî¢ Componentes testados: {len(parsed_result['results'])}")
        print(f"‚ùå Erros encontrados: {len(parsed_result['errors'])}")
        
        # Mostrar resumo dos resultados
        print("\nüìã RESUMO DOS RESULTADOS:")
        for component, result in parsed_result['results'].items():
            status = "‚úÖ" if result.get('success') else "‚ùå"
            time_taken = result.get('metrics', {}).get('processing_time', 0)
            print(f"  {status} {component}: {time_taken:.3f}s")
        
    except Exception as e:
        print(f"‚ùå Erro no teste JSON: {str(e)}")
    
    # 3. TESTE DE FUNCIONALIDADE ESPEC√çFICA
    print("\n" + "="*60)
    print("3Ô∏è‚É£ TESTE DE FUNCIONALIDADE ESPEC√çFICA")
    print("="*60)
    
    try:
        print("üéØ Testando funcionalidade espec√≠fica (an√°lise RFM + CLV)...")
        
        # Usar a fun√ß√£o _run com par√¢metros espec√≠ficos
        result = exporter._run(
            data_csv="data/vendas.csv",
            output_path="exemplos_output/customer_test_specific.csv",
            include_rfm_analysis=True,
            include_clv_calculation=True,
            include_geographic_analysis=False,  # Desabilitar para teste r√°pido
            include_behavioral_insights=False,
            clv_months=12  # CLV para 12 meses
        )
        
        print("‚úÖ Teste espec√≠fico conclu√≠do!")
        print("üìÑ Resultado:")
        print(result[:500] + "..." if len(result) > 500 else result)
        
    except Exception as e:
        print(f"‚ùå Erro no teste espec√≠fico: {str(e)}")
    
    # 4. AN√ÅLISE COMPARATIVA DE PERFORMANCE
    print("\n" + "="*60)
    print("4Ô∏è‚É£ AN√ÅLISE COMPARATIVA DE PERFORMANCE")
    print("="*60)
    
    try:
        import time
        
        print("‚è±Ô∏è Testando performance de diferentes configura√ß√µes...")
        
        configurations = [
            {
                "name": "An√°lise B√°sica (RFM + CLV)",
                "params": {
                    "include_rfm_analysis": True,
                    "include_clv_calculation": True,
                    "include_geographic_analysis": False,
                    "include_behavioral_insights": False
                }
            },
            {
                "name": "An√°lise Completa",
                "params": {
                    "include_rfm_analysis": True,
                    "include_clv_calculation": True,
                    "include_geographic_analysis": True,
                    "include_behavioral_insights": True
                }
            }
        ]
        
        performance_results = []
        
        for config in configurations:
            print(f"üß™ Testando: {config['name']}")
            start_time = time.time()
            
            try:
                result = exporter._run(
                    data_csv="data/vendas.csv",
                    output_path=f"exemplos_output/perf_test_{config['name'].lower().replace(' ', '_')}.csv",
                    **config['params']
                )
                execution_time = time.time() - start_time
                
                performance_results.append({
                    "config": config['name'],
                    "time": execution_time,
                    "success": True
                })
                print(f"  ‚úÖ Conclu√≠do em {execution_time:.2f}s")
                
            except Exception as e:
                execution_time = time.time() - start_time
                performance_results.append({
                    "config": config['name'],
                    "time": execution_time,
                    "success": False,
                    "error": str(e)
                })
                print(f"  ‚ùå Falhou em {execution_time:.2f}s: {str(e)}")
        
        # Exibir comparativo de performance
        print("\nüìä COMPARATIVO DE PERFORMANCE:")
        print("-" * 50)
        for result in performance_results:
            status = "‚úÖ" if result['success'] else "‚ùå"
            print(f"{status} {result['config']}: {result['time']:.2f}s")
            if not result['success']:
                print(f"   Erro: {result.get('error', 'Desconhecido')}")
        
    except Exception as e:
        print(f"‚ùå Erro na an√°lise de performance: {str(e)}")
    
    print("\n" + "="*60)
    print("üéØ DEMONSTRA√á√ÉO CONCLU√çDA!")
    print("="*60)
    print("üìÅ Arquivos gerados em: exemplos_output/")
    print("üìä Relat√≥rios de teste dispon√≠veis")
    print("üîç Use os testes para validar modifica√ß√µes na classe")

if __name__ == "__main__":
    demonstrar_testes_customer_exporter() 
from crewai import Agent, Crew, Process, Task, LLM
from crewai.project import CrewBase, agent, crew, task, before_kickoff
from crewai.agents.agent_builder.base_agent import BaseAgent
from crewai_tools import FileReadTool
from typing import List
from dotenv import load_dotenv
import os
import logging
import time
from datetime import datetime
from pathlib import Path

# =============== IMPORTA√á√ïES OTIMIZADAS DE FERRAMENTAS ===============

# Ferramentas b√°sicas
from insights.tools.sql_query_tool import SQLServerQueryTool
from insights.tools.kpi_calculator_tool import KPICalculatorTool
from insights.tools.prophet_tool import ProphetForecastTool
from insights.tools.statistical_analysis_tool import StatisticalAnalysisTool
from insights.tools.business_intelligence_tool import BusinessIntelligenceTool
from insights.tools.duckduck_tool import DuckDuckGoSearchTool

# Ferramentas avan√ßadas
from insights.tools.advanced.customer_insights_engine import CustomerInsightsEngine
from insights.tools.advanced.recommendation_engine import RecommendationEngine
from insights.tools.advanced.advanced_analytics_engine_tool import AdvancedAnalyticsEngineTool
from insights.tools.advanced.risk_assessment_tool import RiskAssessmentTool
from insights.tools.advanced.competitive_intelligence_tool import CompetitiveIntelligenceTool

load_dotenv()

# =============== CONFIGURA√á√ÉO AVAN√áADA DE LOGGING ===============

def setup_crew_file_logging():
    """
    Configura logging em tempo real para arquivo com rota√ß√£o por execu√ß√£o
    """
    # Criar timestamp para nome √∫nico do arquivo
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Garantir que a pasta logs existe
    logs_dir = Path("logs/crew_executions")
    logs_dir.mkdir(parents=True, exist_ok=True)
    
    # Caminho do arquivo de log
    log_file = logs_dir / f"crew_execution_{timestamp}.log"
    
    # Configurar logger espec√≠fico para o crew
    crew_logger = logging.getLogger('crew_insights')
    crew_logger.setLevel(logging.DEBUG)
    
    # Remover handlers existentes para evitar duplica√ß√£o
    for handler in crew_logger.handlers[:]:
        crew_logger.removeHandler(handler)
    
    # Handler para arquivo com flush imediato
    file_handler = logging.FileHandler(log_file, mode='w', encoding='utf-8')
    file_handler.setLevel(logging.DEBUG)
    
    # Handler para console (manter visualiza√ß√£o)
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    
    # Formata√ß√£o rica para arquivo
    file_formatter = logging.Formatter(
        '%(asctime)s | %(levelname)8s | %(name)s | %(funcName)s:%(lineno)d | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # Formata√ß√£o simples para console
    console_formatter = logging.Formatter(
        '%(asctime)s - %(process)d - %(filename)s-%(funcName)s:%(lineno)d - %(levelname)s: %(message)s'
    )
    
    file_handler.setFormatter(file_formatter)
    console_handler.setFormatter(console_formatter)
    
    # Adicionar handlers
    crew_logger.addHandler(file_handler)
    crew_logger.addHandler(console_handler)
    
    # Garantir que n√£o propague para o logger raiz
    crew_logger.propagate = False
    
    # Log inicial de teste
    crew_logger.info("=" * 80)
    crew_logger.info("üöÄ INSIGHTS-AI CREW - LOGGING INICIADO")
    crew_logger.info(f"üìÅ Arquivo de log: {log_file}")
    crew_logger.info(f"üïí Execu√ß√£o iniciada em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    crew_logger.info("=" * 80)
    
    return crew_logger, str(log_file)

# Configurar logging espec√≠fico para o crew
crew_logger = logging.getLogger('crew_insights')
crew_logger.setLevel(logging.DEBUG)

OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")

llm = LLM(
    model="openrouter/deepseek/deepseek-r1",
    base_url="https://openrouter.ai/api/v1",
    api_key=OPENROUTER_API_KEY
)

# =============== INSTANCIA√á√ÉO COMPLETA DE FERRAMENTAS ===============

# Ferramentas b√°sicas
file_tool = FileReadTool()
sql_tool = SQLServerQueryTool()
search_tool = DuckDuckGoSearchTool()

# Ferramentas de an√°lise
kpi_tool = KPICalculatorTool()
prophet_tool = ProphetForecastTool()
stats_tool = StatisticalAnalysisTool()
bi_tool = BusinessIntelligenceTool()

# Ferramentas avan√ßadas de IA/ML
customer_engine = CustomerInsightsEngine()
recommendation_engine = RecommendationEngine()
analytics_engine = AdvancedAnalyticsEngineTool()
risk_tool = RiskAssessmentTool()
competitive_tool = CompetitiveIntelligenceTool()

@CrewBase
class Insights():
    """
    Crew otimizada com distribui√ß√£o inteligente de ferramentas:
    - Valida√ß√£o autom√°tica de ferramentas
    - Rate limiting inteligente  
    - Monitoramento de performance
    - Fallbacks para ferramentas indispon√≠veis
    - Distribui√ß√£o especializada por agente
    """

    def __init__(self):
        super().__init__()
        
        # =============== CONFIGURAR LOGGING EM ARQUIVO ===============
        try:
            global crew_logger
            crew_logger, self.log_file_path = setup_crew_file_logging()
            crew_logger.info("‚úÖ Sistema de logging em arquivo configurado com sucesso")
        except Exception as e:
            print(f"‚ö†Ô∏è WARNING: Erro ao configurar logging em arquivo: {e}")
            # Continuar com logging apenas no console
            self.log_file_path = None
        
        # S√≥ validar ferramentas se em modo debug
        if os.getenv("INSIGHTS_DEBUG", "false").lower() == "true":
            self.tools_status = validate_tools_setup()
        else:
            self.tools_status = validate_tools_setup_quiet()
        self.task_start_times = {}
        self.setup_logging_callbacks()
        
        # Log de informa√ß√µes do sistema
        self._log_system_info()

    agents: List[BaseAgent]
    tasks: List[Task]
    
    @before_kickoff
    def before_kickoff(self, inputs):
        """Before kickoff otimizado com valida√ß√µes e inputs de data"""
        start_time = time.time()
        
        # =============== LOG METADADOS DA EXECU√á√ÉO ===============
        crew_logger.info("üöÄ INICIANDO INSIGHTS-AI OTIMIZADO")
        crew_logger.info("=" * 60)
        crew_logger.info(f"üìÖ Data/Hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        crew_logger.info(f"üìã Inputs recebidos: {inputs}")
        crew_logger.info(f"üìÅ Log sendo salvo em: {getattr(self, 'log_file_path', 'APENAS CONSOLE')}")
        crew_logger.info("=" * 60)
        
        # Validar e exibir inputs de data
        data_inicio = inputs.get('data_inicio')
        data_fim = inputs.get('data_fim')
        
        if data_inicio and data_fim:
            crew_logger.info(f"üìÖ Per√≠odo de an√°lise: {data_inicio} at√© {data_fim}")
            
            # Validar formato das datas
            try:
                datetime.strptime(data_inicio, '%Y-%m-%d')
                datetime.strptime(data_fim, '%Y-%m-%d')
                crew_logger.info("‚úÖ Formato de datas validado com sucesso")
            except ValueError as e:
                crew_logger.warning(f"‚ö†Ô∏è WARNING: Formato de data inv√°lido! Use YYYY-MM-DD. Erro: {e}")
        else:
            crew_logger.warning("‚ö†Ô∏è WARNING: Inputs de data n√£o fornecidos! Usando dados padr√£o.")
        
        # Validar ferramentas cr√≠ticas com mais detalhes
        crew_logger.info("üîß VALIDANDO FERRAMENTAS CR√çTICAS:")
        critical_tools = ['sql_tool', 'prophet_tool', 'stats_tool', 'bi_tool']
        tool_status = {}
        
        for tool_name in critical_tools:
            tool_obj = globals().get(tool_name)
            if tool_obj is None:
                crew_logger.error(f"   ‚ùå {tool_name} N√ÉO ENCONTRADA!")
                tool_status[tool_name] = "‚ùå FALHA"
            else:
                crew_logger.info(f"   ‚úÖ {tool_name} carregada - Tipo: {type(tool_obj).__name__}")
                tool_status[tool_name] = "‚úÖ OK"
        
        # Resumo do status das ferramentas
        working_tools = sum(1 for status in tool_status.values() if "‚úÖ" in status)
        crew_logger.info(f"üìä Status geral: {working_tools}/{len(critical_tools)} ferramentas cr√≠ticas funcionando")
        
        # Executar SQL extraction com as datas fornecidas (se dispon√≠veis)
        crew_logger.info("üìä PREPARANDO EXTRA√á√ÉO DE DADOS:")
        try:
            if data_inicio and data_fim:
                crew_logger.info(f"   üîÑ Modo: Extra√ß√£o com filtro temporal {data_inicio} a {data_fim}")
                crew_logger.info("   üìã Dados ser√£o extra√≠dos pelo agente usando os inputs fornecidos")
            else:
                crew_logger.info("   üîÑ Modo: Extra√ß√£o padr√£o (sem filtro temporal)")
                crew_logger.info("   ‚ö†Ô∏è Executando extra√ß√£o padr√£o...")
                sql_tool._execute_query_and_save_to_csv()
                crew_logger.info("   ‚úÖ Dados extra√≠dos com sucesso do SQL Server (per√≠odo padr√£o)")
        except Exception as e:
            crew_logger.error(f"   ‚ùå ERRO na extra√ß√£o SQL: {e}")
            crew_logger.info("   üîÑ Tentando usar dados existentes como fallback...")
        
        setup_time = time.time() - start_time
        crew_logger.info("=" * 60)
        crew_logger.info(f"‚è±Ô∏è SETUP CONCLU√çDO em {setup_time:.2f} segundos")
        crew_logger.info("üöÄ INICIANDO EXECU√á√ÉO DO CREW...")
        crew_logger.info("=" * 60)
        
        # For√ßar flush para garantir que tudo seja escrito
        self._flush_logs()
        
        return inputs
    
    def _log_system_info(self):
        """Log informa√ß√µes do sistema e ambiente para debug"""
        try:
            import platform
            import sys
            
            crew_logger.info("üñ•Ô∏è INFORMA√á√ïES DO SISTEMA:")
            crew_logger.info(f"   ‚Ä¢ OS: {platform.system()} {platform.release()}")
            crew_logger.info(f"   ‚Ä¢ Python: {sys.version.split()[0]}")
            crew_logger.info(f"   ‚Ä¢ Working Directory: {os.getcwd()}")
            crew_logger.info(f"   ‚Ä¢ Process ID: {os.getpid()}")
            
            # Log vari√°veis de ambiente relevantes (sem expor segredos)
            env_vars = ['INSIGHTS_DEBUG', 'OPENROUTER_API_KEY']
            crew_logger.info("üîë VARI√ÅVEIS DE AMBIENTE:")
            for var in env_vars:
                value = os.getenv(var)
                if value:
                    if 'API_KEY' in var or 'TOKEN' in var:
                        masked_value = f"{value[:8]}...{value[-4:]}" if len(value) > 12 else "***"
                        crew_logger.info(f"   ‚Ä¢ {var}: {masked_value}")
                    else:
                        crew_logger.info(f"   ‚Ä¢ {var}: {value}")
                else:
                    crew_logger.warning(f"   ‚Ä¢ {var}: N√ÉO DEFINIDA")
            
            crew_logger.info("-" * 50)
            
        except Exception as e:
            crew_logger.error(f"‚ùå Erro ao capturar informa√ß√µes do sistema: {e}")

    def setup_logging_callbacks(self):
        """Configurar callbacks de logging para monitoramento detalhado"""
        crew_logger.info("üîß Configurando callbacks de monitoramento...")
        
        # Log da configura√ß√£o dos handlers ativos
        active_handlers = [type(h).__name__ for h in crew_logger.handlers]
        crew_logger.info(f"   ‚Ä¢ Handlers ativos: {active_handlers}")
        
        if hasattr(self, 'log_file_path') and self.log_file_path:
            crew_logger.info(f"   ‚Ä¢ Arquivo de log: {self.log_file_path}")
        
        # For√ßar flush dos handlers de arquivo
        for handler in crew_logger.handlers:
            if hasattr(handler, 'flush'):
                handler.flush()
    
    def log_task_start(self, task_name: str):
        """Log in√≠cio de task com timestamp"""
        self.task_start_times[task_name] = time.time()
        crew_logger.info(f"üöÄ INICIANDO TASK: {task_name}")
        crew_logger.info(f"‚è∞ Timestamp: {datetime.now().strftime('%H:%M:%S')}")
        self._flush_logs()
    
    def log_task_progress(self, task_name: str, message: str):
        """Log progresso da task"""
        elapsed = time.time() - self.task_start_times.get(task_name, time.time())
        crew_logger.info(f"üîÑ [{task_name}] {message} (elapsed: {elapsed:.1f}s)")
        self._flush_logs()
    
    def log_task_end(self, task_name: str):
        """Log fim de task com tempo total"""
        elapsed = time.time() - self.task_start_times.get(task_name, time.time())
        crew_logger.info(f"‚úÖ CONCLU√çDA: {task_name} em {elapsed:.2f} segundos")
        self._flush_logs()
        
    def log_agent_action(self, agent_name: str, action: str, details: str = ""):
        """Log a√ß√µes dos agentes"""
        crew_logger.info(f"üß† [{agent_name}] {action} {details}")
        self._flush_logs()
    
    def log_tool_usage(self, agent_name: str, tool_name: str, status: str = "chamada"):
        """Log uso de ferramentas"""
        crew_logger.info(f"üîß [{agent_name}] Ferramenta {tool_name} - {status}")
        self._flush_logs()

    def _flush_logs(self):
        """For√ßa o flush de todos os handlers de log para escrita imediata"""
        try:
            for handler in crew_logger.handlers:
                if hasattr(handler, 'flush'):
                    handler.flush()
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao fazer flush dos logs: {e}")

    def _log_execution_summary(self):
        """Log resumo final da execu√ß√£o"""
        try:
            crew_logger.info("=" * 80)
            crew_logger.info("üìä RESUMO FINAL DA EXECU√á√ÉO")
            crew_logger.info("=" * 80)
            
            # Tempo total de execu√ß√£o
            if hasattr(self, 'execution_start_time'):
                total_time = time.time() - self.execution_start_time
                crew_logger.info(f"‚è±Ô∏è Tempo total de execu√ß√£o: {total_time:.2f} segundos")
            
            # Status das tasks
            if hasattr(self, 'task_start_times') and self.task_start_times:
                crew_logger.info(f"üìã Tasks executadas: {len(self.task_start_times)}")
                for task_name, start_time in self.task_start_times.items():
                    elapsed = time.time() - start_time
                    crew_logger.info(f"   ‚Ä¢ {task_name}: {elapsed:.2f}s")
            
            crew_logger.info(f"üìÅ Log completo salvo em: {getattr(self, 'log_file_path', 'APENAS CONSOLE')}")
            crew_logger.info("‚úÖ EXECU√á√ÉO FINALIZADA COM SUCESSO")
            crew_logger.info("=" * 80)
            
            self._flush_logs()
            
        except Exception as e:
            crew_logger.error(f"‚ùå Erro ao gerar resumo final: {e}")
    
    # =============== AGENTES OTIMIZADOS COM DISTRIBUI√á√ÉO ESPECIALIZADA ===============
    
    @agent
    def engenheiro_dados(self) -> Agent:
        """
        üîß ESPECIALISTA EM DADOS E ETL
        Ferramentas: SQL + Analytics Engine + File Tool
        Foco: Extra√ß√£o, transforma√ß√£o e valida√ß√£o de dados
        """
        crew_logger.info("üîß Inicializando Engenheiro de Dados...")
        return Agent(
            config=self.agents_config['engenheiro_dados'],
            verbose=True,
            llm=llm,
            tools=[
                # file_tool,                # ‚úÖ Leitura de arquivos
                sql_tool,                 # ‚úÖ Acesso direto SQL Server
                # analytics_engine          # ‚úÖ ETL avan√ßado e prepara√ß√£o
            ]
        )

    @agent
    def analista_tendencias(self) -> Agent:
        """
        üìà ESPECIALISTA EM PADR√ïES E PESQUISA
        Ferramentas: Statistical Analysis + DuckDuckGo + BI Dashboard
        Foco: An√°lise de correla√ß√µes, tend√™ncias e contexto externo
        """
        return Agent(
            config=self.agents_config['analista_tendencias'],
            verbose=True,
            llm=llm,
            tools=[
                file_tool,                # ‚úÖ Leitura de dados
                stats_tool,               # ‚úÖ An√°lise estat√≠stica avan√ßada
                search_tool,              # ‚úÖ NOVO: Pesquisa de contexto externo
                bi_tool                   # ‚úÖ Visualiza√ß√µes e dashboards
            ],
            respect_context_window=True
        )

    @agent
    def especialista_sazonalidade(self) -> Agent:
        """
        üåä EXPERT EM SAZONALIDADE E CICLOS
        Ferramentas: Statistical Analysis + Analytics Engine + BI Dashboard
        Foco: Decomposi√ß√£o sazonal, modelagem temporal e padr√µes c√≠clicos
        """
        return Agent(
            config=self.agents_config['especialista_sazonalidade'],
            verbose=True,
            llm=llm,
            tools=[
                file_tool,                # ‚úÖ Leitura de dados
                stats_tool,               # ‚úÖ Decomposi√ß√£o sazonal STL
                analytics_engine,         # ‚úÖ Modelagem temporal avan√ßada
                bi_tool                   # ‚úÖ Visualiza√ß√µes sazonais
            ],
            respect_context_window=True
        )
        
    @agent
    def especialista_projecoes(self) -> Agent:
        """
        üîÆ FORECASTER PROFISSIONAL
        Ferramentas: Prophet + Statistical Analysis + BI Dashboard
        Foco: Previs√µes precisas, valida√ß√£o de modelos e cen√°rios
        """
        return Agent(
            config=self.agents_config['especialista_projecoes'],
            verbose=True,
            llm=llm,
            tools=[
                file_tool,                # ‚úÖ Leitura de dados
                prophet_tool,             # ‚úÖ CR√çTICO: Prophet forecasting
                stats_tool,               # ‚úÖ Valida√ß√£o estat√≠stica de modelos
                bi_tool                   # ‚úÖ Gr√°ficos de proje√ß√£o profissionais
            ],
            respect_context_window=True
        )
        
    @agent
    def analista_segmentos(self) -> Agent:
        """
        üë• ESPECIALISTA EM CATEGORIAS E CLIENTES
        Ferramentas: KPI Calculator + Customer Insights + BI Dashboard
        Foco: Segmenta√ß√£o, an√°lise por categoria e comportamento do cliente
        """
        return Agent(
            config=self.agents_config['analista_segmentos'],
            verbose=True,
            llm=llm,
            tools=[
                file_tool,                # ‚úÖ Leitura de dados
                kpi_tool,                 # ‚úÖ KPIs especializados por categoria
                customer_engine,          # ‚úÖ Segmenta√ß√£o autom√°tica IA
                bi_tool                   # ‚úÖ Dashboards comparativos
            ],
            respect_context_window=True
        )

    @agent
    def analista_inventario(self) -> Agent:
        """
        üì¶ OTIMIZADOR DE ESTOQUE INTELIGENTE
        Ferramentas: KPI Calculator + Recommendation Engine + Risk Assessment + BI Dashboard
        Foco: Otimiza√ß√£o de invent√°rio, gest√£o de riscos e recomenda√ß√µes autom√°ticas
        """
        return Agent(
            config=self.agents_config['analista_inventario'],
            verbose=True,
            llm=llm,
            tools=[
                file_tool,                # ‚úÖ Leitura de dados
                kpi_tool,                 # ‚úÖ KPIs de estoque especializados
                recommendation_engine,    # ‚úÖ Recomenda√ß√µes ML para estoque
                risk_tool,                # ‚úÖ Avalia√ß√£o de riscos de invent√°rio
                bi_tool                   # ‚úÖ Dashboards operacionais
            ],
            respect_context_window=True
        )

    @agent  
    def diretor_insights(self) -> Agent:
        """
        üéØ EXECUTIVO C-LEVEL COM ARSENAL ESTRAT√âGICO
        Ferramentas: BI Dashboard + Recommendation Engine + Competitive Intelligence + KPI Calculator
        Foco: S√≠ntese estrat√©gica, benchmarking competitivo e decis√µes executivas
        """
        return Agent(
            config=self.agents_config['diretor_insights'],
            verbose=True,
            llm=llm,
            tools=[
                file_tool,                      # ‚úÖ Leitura de dados
                kpi_tool,                       # ‚úÖ KPIs executivos
                bi_tool,                        # ‚úÖ Dashboards executivos
                recommendation_engine,          # ‚úÖ Recomenda√ß√µes estrat√©gicas
                competitive_tool,               # ‚úÖ Intelig√™ncia competitiva
            ],
            respect_context_window=True
        )

    # =============== TASKS ===============
    
    @task
    def engenheiro_dados_task(self) -> Task:
        crew_logger.info("üìã Configurando Task: Engenheiro de Dados")
        return Task(
            config=self.tasks_config['engenheiro_dados_task'],
            # Garantir que os inputs de data sejam passados para a task
            # context_variables=['data_inicio', 'data_fim'],
            callback=lambda output: crew_logger.info(f"‚úÖ [Engenheiro] Task conclu√≠da: {len(str(output))} chars")
        )
    
    @task
    def analista_tendencias_task(self) -> Task:
        return Task(
            config=self.tasks_config['analista_tendencias_task'],
            context=[self.engenheiro_dados_task()]
        )
    
    @task
    def especialista_sazonalidade_task(self) -> Task:
        return Task(
            config=self.tasks_config['especialista_sazonalidade_task'],
            context=[self.engenheiro_dados_task()]
        )
    
    @task
    def especialista_projecoes_task(self) -> Task:
        return Task(
            config=self.tasks_config['especialista_projecoes_task'],
            context=[self.engenheiro_dados_task(), self.especialista_sazonalidade_task()]
        )
    
    @task
    def analista_segmentos_task(self) -> Task:
        return Task(
            config=self.tasks_config['analista_segmentos_task'],
            context=[self.engenheiro_dados_task()]
        )

    @task
    def analise_inventario_task(self) -> Task:
        return Task(
            config=self.tasks_config['analise_inventario_task'],
            context=[self.engenheiro_dados_task()]
        )
        
    @task
    def relatorio_executivo_completo_task(self) -> Task:
        """
        TASK FINAL OTIMIZADA - S√≠ntese estrat√©gica com todas as ferramentas
        """
        return Task(
            config=self.tasks_config['relatorio_executivo_completo_task'],
            context=[
                self.engenheiro_dados_task(), 
                self.analista_tendencias_task(), 
                self.especialista_sazonalidade_task(), 
                self.especialista_projecoes_task(), 
                self.analista_segmentos_task(), 
                self.analise_inventario_task()
            ],
            output_file='reports/relatorio_executivo_completo.md'
        )

    @crew
    def crew(self) -> Crew:
        """Creates the OPTIMIZED Insights crew with enhanced configuration"""
        crew_logger.info("üöÄ Configurando Crew com logging avan√ßado...")
        
        def task_callback(task_output):
            """Callback chamado quando cada task termina"""
            try:
                crew_logger.info(f"‚úÖ Task conclu√≠da: {task_output.description[:100]}...")
                crew_logger.info(f"üìä Output type: {type(task_output)}")
                crew_logger.info(f"üìè Output length: {len(str(task_output))} chars")
                self._flush_logs()
            except Exception as e:
                crew_logger.error(f"‚ùå Erro no callback de task: {e}")
            
        def agent_callback(agent_output):
            """Callback chamado para cada a√ß√£o do agente"""  
            try:
                crew_logger.info(f"üß† Agente executando: {str(agent_output)[:200]}...")
                self._flush_logs()
            except Exception as e:
                crew_logger.error(f"‚ùå Erro no callback de agente: {e}")
            
        return Crew(
            agents=self.agents,
            tasks=self.tasks,
            process=Process.sequential,
            verbose=True,             # ‚úÖ Boolean, n√£o inteiro
            memory=False,
            # planning=True,
            max_rpm=20,              # ‚úÖ Reduzido para mais estabilidade 
            task_callback=task_callback,
            # embedder={               # ‚úÖ Embedding para mem√≥ria otimizada
            #     "provider": "ollama",
            #     "config": {
            #         "model": "nomic-embed-text",
            #         "base_url": "https://ollama.capta.com.br"
            #     }
            # }
        )


# =============== VALIDA√á√ÉO AVAN√áADA DE FERRAMENTAS ===============

def validate_tools_setup_quiet():
    """Valida√ß√£o silenciosa das ferramentas - s√≥ reporta problemas cr√≠ticos"""
    
    tools_status = {
        "B√°sicas": {
            "FileReadTool": _validate_tool(file_tool, "file_tool"),
            "SQLServerQueryTool": _validate_tool(sql_tool, "sql_tool"),
            "DuckDuckGoSearchTool": _validate_tool(search_tool, "search_tool"),
            "KPICalculatorTool": _validate_tool(kpi_tool, "kpi_tool"),
            "ProphetForecastTool": _validate_tool(prophet_tool, "prophet_tool"),
            "StatisticalAnalysisTool": _validate_tool(stats_tool, "stats_tool"),
            "BusinessIntelligenceTool": _validate_tool(bi_tool, "bi_tool"),
        },
        "Avan√ßadas": {
            "CustomerInsightsEngine": _validate_tool(customer_engine, "customer_engine"),
            "RecommendationEngine": _validate_tool(recommendation_engine, "recommendation_engine"),
            "AdvancedAnalyticsEngine": _validate_tool(analytics_engine, "analytics_engine"),
            "RiskAssessmentTool": _validate_tool(risk_tool, "risk_tool"),
            "CompetitiveIntelligenceTool": _validate_tool(competitive_tool, "competitive_tool")
        }
    }
    
    # Contar ferramentas e identificar problemas cr√≠ticos
    total_tools = 0
    working_tools = 0
    critical_errors = []
    
    for category, tools in tools_status.items():
        for tool_name, status in tools.items():
            total_tools += 1
            if status['available']:
                working_tools += 1
            else:
                critical_errors.append(f"{tool_name}: {status.get('error', 'N√£o dispon√≠vel')}")
    
    success_rate = (working_tools / total_tools) * 100
    
    # S√≥ reportar se houver problemas cr√≠ticos ou taxa muito baixa
    if success_rate < 75:
        crew_logger.warning(f"‚ö†Ô∏è Taxa de sucesso das ferramentas baixa: {success_rate:.1f}%")
        for error in critical_errors[:3]:  # S√≥ os 3 primeiros erros
            crew_logger.warning(f"‚ùå {error}")
    else:
        crew_logger.info(f"‚úÖ Ferramentas validadas: {working_tools}/{total_tools} funcionando")
    
    return tools_status

def validate_tools_setup():
    """Valida√ß√£o completa e detalhada das ferramentas (modo debug)"""
    
    tools_status = {
        "B√°sicas": {
            "FileReadTool": _validate_tool(file_tool, "file_tool"),
            "SQLServerQueryTool": _validate_tool(sql_tool, "sql_tool"),
            "DuckDuckGoSearchTool": _validate_tool(search_tool, "search_tool"),
            "KPICalculatorTool": _validate_tool(kpi_tool, "kpi_tool"),
            "ProphetForecastTool": _validate_tool(prophet_tool, "prophet_tool"),
            "StatisticalAnalysisTool": _validate_tool(stats_tool, "stats_tool"),
            "BusinessIntelligenceTool": _validate_tool(bi_tool, "bi_tool"),
        },
        "Avan√ßadas": {
            "CustomerInsightsEngine": _validate_tool(customer_engine, "customer_engine"),
            "RecommendationEngine": _validate_tool(recommendation_engine, "recommendation_engine"),
            "AdvancedAnalyticsEngine": _validate_tool(analytics_engine, "analytics_engine"),
            "RiskAssessmentTool": _validate_tool(risk_tool, "risk_tool"),
            "CompetitiveIntelligenceTool": _validate_tool(competitive_tool, "competitive_tool")
        }
    }
    
    crew_logger.info("üîß VALIDA√á√ÉO COMPLETA DE FERRAMENTAS:")
    crew_logger.info("=" * 50)
    
    total_tools = 0
    working_tools = 0
    
    for category, tools in tools_status.items():
        crew_logger.info(f"\nüìÇ {category}:")
        for tool_name, status in tools.items():
            total_tools += 1
            status_icon = "‚úÖ" if status['available'] else "‚ùå"
            crew_logger.info(f"  {status_icon} {tool_name}")
            
            if status['available']:
                working_tools += 1
                if status.get('methods'):
                    crew_logger.debug(f"      M√©todos: {', '.join(status['methods'][:3])}...")
            else:
                crew_logger.warning(f"      Erro: {status.get('error', 'N√£o dispon√≠vel')}")
    
    success_rate = (working_tools / total_tools) * 100
    crew_logger.info(f"\nüìä RESUMO:")
    crew_logger.info(f"  ‚úÖ Ferramentas funcionando: {working_tools}/{total_tools} ({success_rate:.1f}%)")
    
    if success_rate >= 90:
        crew_logger.info(f"  üéâ EXCELENTE! Sistema totalmente operacional")
    elif success_rate >= 75:
        crew_logger.info(f"  ‚úÖ BOM! Maioria das ferramentas funcionando")
    else:
        crew_logger.warning(f"  ‚ö†Ô∏è ATEN√á√ÉO! Muitas ferramentas com problemas")
    
    return tools_status

def _validate_tool(tool_instance, tool_name: str) -> dict:
    """Validar uma ferramenta espec√≠fica"""
    try:
        if tool_instance is None:
            return {'available': False, 'error': 'Inst√¢ncia n√£o criada'}
        
        # Verificar se tem m√©todo _run (padr√£o CrewAI)
        has_run = hasattr(tool_instance, '_run')
        
        # Listar m√©todos dispon√≠veis
        methods = [method for method in dir(tool_instance) 
                  if not method.startswith('_') and callable(getattr(tool_instance, method))]
        
        return {
            'available': True,
            'has_run_method': has_run,
            'methods': methods[:5],  # Primeiros 5 m√©todos
            'class_name': tool_instance.__class__.__name__
        }
        
    except Exception as e:
        return {'available': False, 'error': str(e)}

def get_tools_by_agent():
    """Retornar mapeamento de ferramentas por agente para debugging"""
    return {
        "engenheiro_dados": ["FileReadTool", "SQLServerQueryTool", "AdvancedAnalyticsEngine"],
        "analista_tendencias": ["FileReadTool", "StatisticalAnalysisTool", "DuckDuckGoSearchTool", "BusinessIntelligenceTool"],
        "especialista_sazonalidade": ["FileReadTool", "StatisticalAnalysisTool", "AdvancedAnalyticsEngine", "BusinessIntelligenceTool"],
        "especialista_projecoes": ["FileReadTool", "ProphetForecastTool", "StatisticalAnalysisTool", "BusinessIntelligenceTool"],
        "analista_segmentos": ["FileReadTool", "KPICalculatorTool", "CustomerInsightsEngine", "BusinessIntelligenceTool"],
        "analista_inventario": ["FileReadTool", "KPICalculatorTool", "RecommendationEngine", "RiskAssessmentTool", "BusinessIntelligenceTool"],
        "diretor_insights": ["FileReadTool", "KPICalculatorTool", "BusinessIntelligenceTool", "RecommendationEngine", "CompetitiveIntelligenceTool"]
    }


if __name__ == "__main__":
    # Configurar logging para execu√ß√£o direta
    logging.basicConfig(level=logging.INFO)
    
    # Validar setup ao executar diretamente
    crew_logger.info("üöÄ INSIGHTS-AI CREW OTIMIZADA")
    crew_logger.info("=" * 50)
    
    tools_status = validate_tools_setup()
    
    crew_logger.info(f"\nüéØ DISTRIBUI√á√ÉO DE FERRAMENTAS POR AGENTE:")
    crew_logger.info("=" * 50)
    
    agent_tools = get_tools_by_agent()
    for agent, tools in agent_tools.items():
        crew_logger.info(f"\nüë§ {agent.replace('_', ' ').title()}:")
        for tool in tools:
            crew_logger.info(f"  üîß {tool}")
    
    crew_logger.info(f"\nüöÄ Crew otimizada pronta para uso!")
    crew_logger.info(f"üìä Ferramentas distribu√≠das por especializa√ß√£o")
    crew_logger.info(f"üéØ Capacidade anal√≠tica maximizada")
    crew_logger.info(f"‚ö° Performance e rate limiting otimizados")

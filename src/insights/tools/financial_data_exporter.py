from crewai.tools import BaseTool
from typing import Type, Optional, Dict, Any, List
from pydantic import BaseModel, Field
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
import warnings
import json
import time
import traceback
import sys

# Importar mÃ³dulos compartilhados consolidados
try:
    # Imports relativos (quando usado como mÃ³dulo)
    from .shared.data_preparation import DataPreparationMixin
    from .shared.business_mixins import JewelryBusinessAnalysisMixin, JewelryRFMAnalysisMixin
except ImportError:
    # Imports absolutos (quando executado diretamente)
    try:
        from insights.tools.shared.data_preparation import DataPreparationMixin
        from insights.tools.shared.business_mixins import JewelryBusinessAnalysisMixin, JewelryRFMAnalysisMixin
    except ImportError:
        # Se nÃ£o conseguir importar, usar versÃ£o local ou criar stubs
        print("âš ï¸ ImportaÃ§Ãµes locais nÃ£o encontradas, usando implementaÃ§Ã£o bÃ¡sica...")
        
        class DataPreparationMixin:
            """Stub bÃ¡sico para DataPreparationMixin"""
            pass
        
        class JewelryBusinessAnalysisMixin:
            """Stub bÃ¡sico para JewelryBusinessAnalysisMixin"""
            pass
            
        class JewelryRFMAnalysisMixin:
            """Stub bÃ¡sico para JewelryRFMAnalysisMixin"""
            pass

warnings.filterwarnings('ignore')

class FinancialDataExporterInput(BaseModel):
    """Schema para exportaÃ§Ã£o de dados financeiros."""
    
    data_csv: str = Field(
        default="data/vendas.csv", 
        description="Caminho para arquivo CSV de vendas"
    )
    
    output_path: str = Field(
        default="assets/data/analise_financeira_dados_completos.csv",
        description="Caminho de saÃ­da para o arquivo CSV financeiro exportado"
    )
    
    # Novos parÃ¢metros de perÃ­odo
    current_year: Optional[int] = Field(
        default=None,
        description="Ano especÃ­fico para anÃ¡lise (ex: 2024). Se None, usa ano atual"
    )
    
    last_x_days: Optional[int] = Field(
        default=None,
        description="Ãšltimos X dias para anÃ¡lise (ex: 90). Se None, usa ano completo"
    )
    
    period_start_date: Optional[str] = Field(
        default=None,
        description="Data inÃ­cio perÃ­odo customizado (YYYY-MM-DD). Opcional"
    )
    
    period_end_date: Optional[str] = Field(
        default=None,
        description="Data fim perÃ­odo customizado (YYYY-MM-DD). Opcional"
    )
    
    include_kpi_analysis: bool = Field(
        default=True,
        description="Incluir anÃ¡lise de KPIs financeiros crÃ­ticos"
    )
    
    include_margin_analysis: bool = Field(
        default=True,
        description="Incluir anÃ¡lise de margens e rentabilidade"
    )
    
    include_trend_analysis: bool = Field(
        default=True,
        description="Incluir anÃ¡lise de tendÃªncias e sazonalidade"
    )
    
    include_projections: bool = Field(
        default=True,
        description="Incluir projeÃ§Ãµes financeiras (30/60/90 dias)"
    )
    
    group_by_period: str = Field(
        default="monthly",
        description="PerÃ­odo de agrupamento: daily, weekly, monthly, quarterly"
    )

class FinancialDataExporter(BaseTool, DataPreparationMixin, JewelryBusinessAnalysisMixin, JewelryRFMAnalysisMixin):
    """
    Ferramenta especializada para exportar dados completos de anÃ¡lise financeira.
    
    COMPORTAMENTO PADRÃƒO: YTD (Year-to-Date) - analisa do inÃ­cio do ano atÃ© hoje.
    
    Esta ferramenta gera um CSV abrangente com:
    - KPIs financeiros crÃ­ticos (baseados no perÃ­odo filtrado)
    - MÃ©tricas de margens e rentabilidade
    - AnÃ¡lise de tendÃªncias e sazonalidade
    - ProjeÃ§Ãµes financeiras (usando Ãºltimos 2 anos)
    - Insights e oportunidades estratÃ©gicas
    - ComparaÃ§Ã£o YoY inteligente (perÃ­odo atual vs mesmo perÃ­odo ano anterior)
    
    FILTROS DE PERÃODO (por prioridade):
    1. PerÃ­odo customizado: period_start_date + period_end_date
    2. Ãšltimos X dias: last_x_days
    3. Ano especÃ­fico: current_year
    4. YTD (padrÃ£o): sem parÃ¢metros = inÃ­cio do ano atÃ© hoje
    """
    
    name: str = "Financial Data Exporter"
    description: str = """
    Exporta dados completos de anÃ¡lise financeira em formato CSV para anÃ¡lise avanÃ§ada.
    
    PADRÃƒO: YTD (Year-to-Date) - analisa do inÃ­cio do ano atÃ© hoje, comparando com YTD do ano anterior.
    
    Inclui KPIs financeiros, anÃ¡lise de margens, tendÃªncias sazonais, 
    projeÃ§Ãµes e insights estratÃ©gicos por perÃ­odo filtrado.
    
    Use esta ferramenta quando precisar de dados estruturados financeiros para:
    - RelatÃ³rios executivos e board (YTD vs YTD anterior)
    - AnÃ¡lise de performance financeira por perÃ­odo especÃ­fico
    - Planejamento orÃ§amentÃ¡rio baseado em projeÃ§Ã£o anual
    - Dashboards de BI (Power BI, Tableau)
    - AnÃ¡lises de rentabilidade por categoria
    - ProjeÃ§Ãµes e forecasting (baseado em Ãºltimos 2 anos)
    
    FILTROS DISPONÃVEIS:
    â€¢ Sem parÃ¢metros: YTD (inÃ­cio do ano atÃ© hoje) 
    â€¢ current_year: Ano especÃ­fico completo
    â€¢ last_x_days: Ãšltimos X dias
    â€¢ period_start_date + period_end_date: PerÃ­odo customizado
    """
    args_schema: Type[BaseModel] = FinancialDataExporterInput

    def _run(self, data_csv: str = "data/vendas.csv", 
             output_path: str = "assets/data/analise_financeira_dados_completos.csv",
             current_year: Optional[int] = None,
             last_x_days: Optional[int] = None,
             period_start_date: Optional[str] = None,
             period_end_date: Optional[str] = None,
             include_kpi_analysis: bool = True,
             include_margin_analysis: bool = True,
             include_trend_analysis: bool = True,
             include_projections: bool = True,
             group_by_period: str = "monthly") -> str:
        
        try:
            print("ğŸš€ Iniciando exportaÃ§Ã£o de dados financeiros...")
            
            # 1. Carregar e preparar dados completos
            print("ğŸ“Š Carregando dados de vendas para anÃ¡lise financeira...")
            df_complete = self._load_and_prepare_data(data_csv)
            
            if df_complete.empty:
                return "âŒ Erro: Dados de vendas nÃ£o encontrados ou invÃ¡lidos"
            
            print(f"âœ… Dados completos carregados: {len(df_complete):,} registros")
            
            # 2. Filtrar dados por perÃ­odo especificado
            print("ğŸ” Aplicando filtros de perÃ­odo...")
            df_filtered, period_info = self._filter_data_by_period(
                df_complete, current_year, last_x_days, period_start_date, period_end_date
            )
            
            if df_filtered.empty:
                return f"âŒ Erro: Nenhum dado encontrado para o perÃ­odo especificado: {period_info['description']}"
            
            print(f"âœ… Dados filtrados: {len(df_filtered):,} registros ({period_info['description']})")
            
            # 3. Agregar dados por perÃ­odo (usando dados filtrados)
            print(f"ğŸ“… Agregando dados por perÃ­odo ({group_by_period})...")
            financial_data = self._aggregate_financial_data(df_filtered, group_by_period)
            
            # 4. AnÃ¡lise de KPIs (usando lÃ³gica hÃ­brida: filtrado + comparaÃ§Ã£o histÃ³rica)
            if include_kpi_analysis:
                print("ğŸ’° Calculando KPIs financeiros crÃ­ticos...")
                financial_data = self._add_enhanced_kpi_analysis(df_complete, df_filtered, financial_data, period_info)
            
            # 5. AnÃ¡lise de margens (usando dados filtrados)
            if include_margin_analysis:
                print("ğŸ“Š Analisando margens e rentabilidade...")
                financial_data = self._add_margin_analysis(df_filtered, financial_data)
            
            # 6. AnÃ¡lise de tendÃªncias (usando dados filtrados para tendÃªncia, completos para sazonalidade)
            if include_trend_analysis:
                print("ğŸ“ˆ Analisando tendÃªncias e sazonalidade...")
                financial_data = self._add_enhanced_trend_analysis(df_complete, df_filtered, financial_data)
            
            # 7. ProjeÃ§Ãµes financeiras (usando Ãºltimos 2 anos)
            if include_projections:
                print("ğŸ”® Gerando projeÃ§Ãµes financeiras...")
                financial_data = self._add_enhanced_financial_projections(df_complete, df_filtered, financial_data)
            
            # 8. Insights e oportunidades (usando dados filtrados)
            print("ğŸ’¡ Identificando insights e oportunidades...")
            financial_data = self._add_strategic_insights(df_filtered, financial_data)
            
            # 9. Scores de saÃºde financeira (usando dados filtrados)
            print("ğŸ“Š Calculando scores de saÃºde financeira...")
            financial_data = self._add_financial_health_scores(financial_data)
            
            # 10. Adicionar informaÃ§Ãµes do perÃ­odo aos dados
            for col, value in period_info.items():
                if col != 'description':
                    financial_data[f'Periodo_Info_{col}'] = value
            
            # 11. Exportar CSV
            print("ğŸ’¾ Exportando arquivo CSV financeiro...")
            success = self._export_to_csv(financial_data, output_path)
            
            if success:
                return self._generate_enhanced_export_summary(financial_data, output_path, df_complete, df_filtered, period_info)
            else:
                return "âŒ Erro na exportaÃ§Ã£o do arquivo CSV"
                
        except Exception as e:
            return f"âŒ Erro na exportaÃ§Ã£o de dados financeiros: {str(e)}"

    def _filter_data_by_period(self, df: pd.DataFrame, current_year: Optional[int] = None,
                              last_x_days: Optional[int] = None, 
                              period_start_date: Optional[str] = None,
                              period_end_date: Optional[str] = None) -> tuple:
        """
        Filtrar dados por perÃ­odo especificado com prioridade:
        1. PerÃ­odo customizado (start_date + end_date)
        2. Ãšltimos X dias
        3. Ano especÃ­fico
        4. Ano atual (padrÃ£o)
        """
        
        max_date = df['Data'].max()
        min_date = df['Data'].min()
        
        # Prioridade 1: PerÃ­odo customizado
        if period_start_date and period_end_date:
            start_date = pd.to_datetime(period_start_date)
            end_date = pd.to_datetime(period_end_date)
            filtered_df = df[(df['Data'] >= start_date) & (df['Data'] <= end_date)]
            
            period_info = {
                'type': 'custom',
                'start_date': start_date,
                'end_date': end_date,
                'description': f"PerÃ­odo customizado: {start_date.strftime('%Y-%m-%d')} a {end_date.strftime('%Y-%m-%d')}",
                'days_count': (end_date - start_date).days + 1
            }
            
        # Prioridade 2: Ãšltimos X dias
        elif last_x_days:
            start_date = max_date - timedelta(days=last_x_days - 1)
            filtered_df = df[df['Data'] >= start_date]
            
            period_info = {
                'type': 'last_days',
                'start_date': start_date,
                'end_date': max_date,
                'description': f"Ãšltimos {last_x_days} dias ({start_date.strftime('%Y-%m-%d')} a {max_date.strftime('%Y-%m-%d')})",
                'days_count': last_x_days
            }
            
        # Prioridade 3: Ano especÃ­fico
        elif current_year:
            start_date = pd.to_datetime(f"{current_year}-01-01")
            end_date = pd.to_datetime(f"{current_year}-12-31")
            filtered_df = df[(df['Data'] >= start_date) & (df['Data'] <= end_date)]
            
            period_info = {
                'type': 'year',
                'start_date': start_date,
                'end_date': end_date,
                'description': f"Ano {current_year}",
                'year': current_year,
                'days_count': (end_date - start_date).days + 1
            }
            
        # Prioridade 4: YTD (Year-to-Date) - PADRÃƒO
        else:
            current_year = max_date.year
            start_date = pd.to_datetime(f"{current_year}-01-01")
            end_date = max_date  # AtÃ© a data mais recente disponÃ­vel (YTD)
            filtered_df = df[(df['Data'] >= start_date) & (df['Data'] <= end_date)]
            
            period_info = {
                'type': 'ytd',  # Year-to-Date como padrÃ£o
                'start_date': start_date,
                'end_date': end_date,
                'description': f"YTD {current_year} (Jan-{end_date.strftime('%b')})",
                'year': current_year,
                'days_count': (end_date - start_date).days + 1,
                'ytd_progress': end_date.timetuple().tm_yday / 365.0
            }
        
        return filtered_df, period_info

    def _get_comparison_period(self, df_complete: pd.DataFrame, period_info: dict) -> pd.DataFrame:
        """
        Obter perÃ­odo de comparaÃ§Ã£o equivalente do ano anterior.
        """
        
        if period_info['type'] in ['custom', 'last_days']:
            # Para perÃ­odos customizados, comparar com mesmo perÃ­odo do ano anterior
            start_comp = period_info['start_date'] - timedelta(days=365)
            end_comp = period_info['end_date'] - timedelta(days=365)
            
        elif period_info['type'] in ['year', 'current_year', 'ytd']:
            # Para anos, comparar com ano anterior completo
            year = period_info.get('year', period_info['start_date'].year)
            start_comp = pd.to_datetime(f"{year-1}-01-01")
            
            if period_info['type'] in ['current_year', 'ytd']:
                # Se for ano atual ou YTD, comparar atÃ© a mesma data do ano anterior
                end_comp = period_info['end_date'] - timedelta(days=365)
            else:
                # Se for ano completo, comparar ano anterior completo
                end_comp = pd.to_datetime(f"{year-1}-12-31")
        
        comparison_df = df_complete[
            (df_complete['Data'] >= start_comp) & 
            (df_complete['Data'] <= end_comp)
        ]
        
        return comparison_df

    def _add_enhanced_kpi_analysis(self, df_complete: pd.DataFrame, df_filtered: pd.DataFrame, 
                                  financial_data: pd.DataFrame, period_info: dict) -> pd.DataFrame:
        """
        AnÃ¡lise de KPIs melhorada com comparaÃ§Ã£o YoY inteligente.
        """
        
        # Crescimento perÃ­odo anterior (sequencial)
        financial_data = financial_data.sort_values('Periodo')
        
        # VariaÃ§Ãµes sequenciais (usando dados filtrados)
        financial_data['Receita_Variacao_Pct'] = (
            financial_data['Receita_Total'].pct_change() * 100
        ).round(2)
        
        financial_data['Transacoes_Variacao_Pct'] = (
            financial_data['Num_Transacoes'].pct_change() * 100
        ).round(2)
        
        financial_data['Ticket_Variacao_Pct'] = (
            financial_data['Ticket_Medio'].pct_change() * 100
        ).round(2)
        
        # MÃ©tricas do perÃ­odo atual (filtrado)
        current_receita = df_filtered['Total_Liquido'].sum()
        current_transacoes = len(df_filtered)
        current_ticket = current_receita / current_transacoes if current_transacoes > 0 else 0
        
        # ComparaÃ§Ã£o com perÃ­odo equivalente do ano anterior
        comparison_df = self._get_comparison_period(df_complete, period_info)
        
        if not comparison_df.empty:
            previous_receita = comparison_df['Total_Liquido'].sum()
            previous_transacoes = len(comparison_df)
            previous_ticket = previous_receita / previous_transacoes if previous_transacoes > 0 else 0
            
            # Crescimento YoY
            yoy_receita_growth = ((current_receita - previous_receita) / previous_receita * 100) if previous_receita > 0 else 0
            yoy_transacoes_growth = ((current_transacoes - previous_transacoes) / previous_transacoes * 100) if previous_transacoes > 0 else 0
            yoy_ticket_growth = ((current_ticket - previous_ticket) / previous_ticket * 100) if previous_ticket > 0 else 0
            
        else:
            previous_receita = 0
            previous_transacoes = 0
            previous_ticket = 0
            yoy_receita_growth = 0
            yoy_transacoes_growth = 0
            yoy_ticket_growth = 0
        
        # Adicionar mÃ©tricas YoY aos dados
        financial_data['Receita_Periodo_Atual'] = current_receita
        financial_data['Receita_Periodo_Anterior'] = previous_receita
        financial_data['YoY_Receita_Growth_Pct'] = round(yoy_receita_growth, 2)
        financial_data['YoY_Transacoes_Growth_Pct'] = round(yoy_transacoes_growth, 2)
        financial_data['YoY_Ticket_Growth_Pct'] = round(yoy_ticket_growth, 2)
        
        # ProjeÃ§Ã£o anual baseada no perÃ­odo atual
        if period_info['type'] in ['current_year', 'ytd']:
            # Para YTD, usar progresso do ano para extrapolar
            if 'ytd_progress' in period_info:
                progress_year = period_info['ytd_progress']
            else:
                day_of_year = period_info['end_date'].timetuple().tm_yday
                progress_year = day_of_year / 365.0
            
            projecao_anual = (current_receita / progress_year) if progress_year > 0 else 0
        else:
            # Para outros perÃ­odos, extrapolar baseado na duraÃ§Ã£o
            days_in_year = 365
            days_in_period = period_info['days_count']
            projecao_anual = (current_receita / days_in_period * days_in_year) if days_in_period > 0 else 0
        
        financial_data['Projecao_Anual'] = round(projecao_anual, 2)
        
        # Confiabilidade baseada na disponibilidade de dados histÃ³ricos
        years_of_data = (df_complete['Data'].max().year - df_complete['Data'].min().year) + 1
        has_comparison_data = not comparison_df.empty
        
        def get_confidence_level(years, has_comparison):
            if not has_comparison:
                return 'Baixa'
            elif years >= 3:
                return 'Alta'
            elif years >= 2:
                return 'MÃ©dia'
            else:
                return 'Baixa'
        
        financial_data['Confiabilidade_Comparacao'] = get_confidence_level(years_of_data, has_comparison_data)
        
        # InformaÃ§Ãµes do perÃ­odo
        financial_data['Periodo_Analisado'] = period_info['description']
        financial_data['Dias_No_Periodo'] = period_info['days_count']
        
        return financial_data

    def _add_enhanced_trend_analysis(self, df_complete: pd.DataFrame, df_filtered: pd.DataFrame, 
                                   financial_data: pd.DataFrame) -> pd.DataFrame:
        """
        AnÃ¡lise de tendÃªncias melhorada usando dados completos para sazonalidade 
        e dados filtrados para tendÃªncia atual.
        """
        
        # TendÃªncia de crescimento usando dados filtrados
        financial_data = financial_data.sort_values('Periodo').reset_index(drop=True)
        
        if len(financial_data) > 1:
            x = np.arange(len(financial_data))
            y = financial_data['Receita_Total'].values
            
            # Coeficiente de tendÃªncia
            trend_coef = np.polyfit(x, y, 1)[0]
            financial_data['Tendencia_Crescimento'] = trend_coef
            
            # Classificar tendÃªncia
            if trend_coef > 1000:
                financial_data['Classificacao_Tendencia'] = 'Crescimento_Forte'
            elif trend_coef > 0:
                financial_data['Classificacao_Tendencia'] = 'Crescimento_Moderado'
            elif trend_coef > -1000:
                financial_data['Classificacao_Tendencia'] = 'Estavel'
            else:
                financial_data['Classificacao_Tendencia'] = 'Declinio'
        else:
            financial_data['Tendencia_Crescimento'] = 0
            financial_data['Classificacao_Tendencia'] = 'Insuficiente'
        
        # AnÃ¡lise sazonal usando dados completos (histÃ³rico robusto)
        monthly_avg = df_complete.groupby(df_complete['Data'].dt.month)['Total_Liquido'].mean()
        overall_avg = df_complete['Total_Liquido'].mean()
        
        def get_seasonal_index(periodo):
            try:
                # Extrair mÃªs do perÃ­odo
                if '-' in str(periodo):
                    month = int(str(periodo).split('-')[1])
                else:
                    month = df_filtered['Data'].dt.month.mode()[0]  # MÃªs mais comum no perÃ­odo filtrado
                
                return monthly_avg.get(month, overall_avg) / overall_avg
            except:
                return 1.0
        
        financial_data['Indice_Sazonal'] = financial_data['Periodo'].apply(get_seasonal_index).round(3)
        
        # Classificar sazonalidade
        def classify_seasonality(index):
            if index > 1.3:
                return 'Pico_Alto'
            elif index > 1.1:
                return 'Pico_Moderado'
            elif index < 0.7:
                return 'Vale_Alto'
            elif index < 0.9:
                return 'Vale_Moderado'
            else:
                return 'Normal'
        
        financial_data['Classificacao_Sazonal'] = financial_data['Indice_Sazonal'].apply(classify_seasonality)
        
        # CorrelaÃ§Ã£o preÃ§o vs volume usando dados filtrados
        if 'Quantidade' in financial_data.columns:
            correlation = financial_data['Ticket_Medio'].corr(financial_data['Quantidade'])
            financial_data['Correlacao_Preco_Volume'] = correlation
        else:
            financial_data['Correlacao_Preco_Volume'] = -0.72  # Conforme relatÃ³rio padrÃ£o
        
        return financial_data

    def _add_enhanced_financial_projections(self, df_complete: pd.DataFrame, df_filtered: pd.DataFrame, 
                                          financial_data: pd.DataFrame) -> pd.DataFrame:
        """
        ProjeÃ§Ãµes financeiras melhoradas usando Ãºltimos 2 anos completos.
        """
        
        # Obter dados dos Ãºltimos 2 anos completos para projeÃ§Ãµes
        max_date = df_complete['Data'].max()
        two_years_ago = max_date - timedelta(days=730)  # Aproximadamente 2 anos
        
        projection_data = df_complete[df_complete['Data'] >= two_years_ago]
        
        if len(projection_data) > 0:
            # Agregar por mÃªs para anÃ¡lise de tendÃªncia
            monthly_projection = projection_data.groupby(
                projection_data['Data'].dt.to_period('M')
            )['Total_Liquido'].sum()
            
            # Calcular tendÃªncia mensal dos Ãºltimos 2 anos
            if len(monthly_projection) > 3:
                x = np.arange(len(monthly_projection))
                y = monthly_projection.values
                trend_coef = np.polyfit(x, y, 1)[0]
                avg_monthly = monthly_projection.mean()
            else:
                trend_coef = 0
                avg_monthly = df_filtered['Total_Liquido'].mean() * 30  # Estimativa mensal
            
            # Calcular sazonalidade dos Ãºltimos 2 anos
            seasonal_factors = projection_data.groupby(
                projection_data['Data'].dt.month
            )['Total_Liquido'].sum() / projection_data.groupby(
                projection_data['Data'].dt.month
            )['Total_Liquido'].sum().mean()
            
            # Usar perÃ­odo atual para determinar sazonalidade futura
            current_month = max_date.month
            next_month = (current_month % 12) + 1
            next_next_month = ((current_month + 1) % 12) + 1
            
            seasonal_30d = seasonal_factors.get(next_month, 1.0)
            seasonal_60d = seasonal_factors.get(next_next_month, 1.0)
            seasonal_90d = seasonal_factors.get((current_month + 2) % 12 + 1, 1.0)
            
            # Base para projeÃ§Ã£o (mÃ©dia mensal ajustada)
            base_monthly = avg_monthly + (trend_coef * len(monthly_projection))
            base_daily = base_monthly / 30
            
            # CenÃ¡rios de projeÃ§Ã£o
            # Conservador: -5% da base + sazonalidade
            financial_data['Projecao_30d_Conservador'] = (base_daily * 30 * 0.95 * seasonal_30d).round(2)
            financial_data['Projecao_60d_Conservador'] = (base_daily * 60 * 0.95 * ((seasonal_30d + seasonal_60d) / 2)).round(2)
            financial_data['Projecao_90d_Conservador'] = (base_daily * 90 * 0.95 * ((seasonal_30d + seasonal_60d + seasonal_90d) / 3)).round(2)
            
            # Realista: base + sazonalidade
            financial_data['Projecao_30d_Realista'] = (base_daily * 30 * seasonal_30d).round(2)
            financial_data['Projecao_60d_Realista'] = (base_daily * 60 * ((seasonal_30d + seasonal_60d) / 2)).round(2)
            financial_data['Projecao_90d_Realista'] = (base_daily * 90 * ((seasonal_30d + seasonal_60d + seasonal_90d) / 3)).round(2)
            
            # Otimista: +10% da base + sazonalidade
            financial_data['Projecao_30d_Otimista'] = (base_daily * 30 * 1.10 * seasonal_30d).round(2)
            financial_data['Projecao_60d_Otimista'] = (base_daily * 60 * 1.10 * ((seasonal_30d + seasonal_60d) / 2)).round(2)
            financial_data['Projecao_90d_Otimista'] = (base_daily * 90 * 1.10 * ((seasonal_30d + seasonal_60d + seasonal_90d) / 3)).round(2)
            
            # Confiabilidade baseada na quantidade de dados histÃ³ricos
            months_of_data = len(monthly_projection)
            if months_of_data >= 24:
                confidence = 95.0
            elif months_of_data >= 18:
                confidence = 85.0
            elif months_of_data >= 12:
                confidence = 75.0
            else:
                confidence = 60.0
                
            financial_data['Confiabilidade_Modelo_Pct'] = confidence
            
        else:
            # Fallback quando nÃ£o hÃ¡ dados suficientes
            for scenario in ['Conservador', 'Realista', 'Otimista']:
                for period in ['30d', '60d', '90d']:
                    financial_data[f'Projecao_{period}_{scenario}'] = 0
            
            financial_data['Confiabilidade_Modelo_Pct'] = 0.0
        
        return financial_data

    def _add_margin_analysis(self, df: pd.DataFrame, financial_data: pd.DataFrame) -> pd.DataFrame:
        """Adicionar anÃ¡lise de margens e rentabilidade."""
        
        # Margem bruta estimada (assumindo 62.4% conforme relatÃ³rio)
        estimated_gross_margin = 0.624
        
        financial_data['Margem_Bruta_Estimada'] = (
            financial_data['Receita_Total'] * estimated_gross_margin
        ).round(2)
        
        financial_data['Margem_Bruta_Pct'] = estimated_gross_margin * 100
        
        # Se temos dados reais de margem
        if 'Margem_Total' in financial_data.columns:
            financial_data['Margem_Real_Pct'] = (
                financial_data['Margem_Total'] / financial_data['Receita_Total'] * 100
            ).fillna(estimated_gross_margin * 100).round(2)
        else:
            financial_data['Margem_Real_Pct'] = financial_data['Margem_Bruta_Pct']
        
        # Impacto de descontos
        if 'Desconto_Total' in financial_data.columns:
            financial_data['Impacto_Desconto_Pct'] = (
                financial_data['Desconto_Total'] / financial_data['Receita_Total'] * 100
            ).fillna(0).round(2)
            
            financial_data['Margem_Liquida_Pct'] = (
                financial_data['Margem_Real_Pct'] - financial_data['Impacto_Desconto_Pct']
            ).round(2)
        else:
            # Assumir 22pp de impacto conforme relatÃ³rio
            financial_data['Impacto_Desconto_Pct'] = 22.0
            financial_data['Margem_Liquida_Pct'] = (
                financial_data['Margem_Real_Pct'] - 22.0
            ).round(2)
        
        # Margem lÃ­quida estimada (18.7% conforme relatÃ³rio)
        financial_data['Margem_Liquida_Final_Pct'] = 18.7
        financial_data['Margem_Liquida_Final'] = (
            financial_data['Receita_Total'] * 0.187
        ).round(2)
        
        # ROI por perÃ­odo
        # Assumindo custo operacional = receita - margem lÃ­quida
        financial_data['Custo_Operacional_Estimado'] = (
            financial_data['Receita_Total'] - financial_data['Margem_Liquida_Final']
        ).round(2)
        
        financial_data['ROI_Periodo_Pct'] = (
            financial_data['Margem_Liquida_Final'] / 
            financial_data['Custo_Operacional_Estimado'] * 100
        ).fillna(0).round(2)
        
        return financial_data

    def _add_strategic_insights(self, df: pd.DataFrame, financial_data: pd.DataFrame) -> pd.DataFrame:
        """Adicionar insights e oportunidades estratÃ©gicas."""
        
        # AnÃ¡lise por categoria (se disponÃ­vel)
        if 'Grupo_Produto' in df.columns:
            category_performance = df.groupby('Grupo_Produto')['Total_Liquido'].sum().sort_values(ascending=False)
            top_category = category_performance.index[0] if len(category_performance) > 0 else 'N/A'
            
            financial_data['Categoria_Top_Performance'] = top_category
            financial_data['Receita_Top_Categoria'] = category_performance.iloc[0] if len(category_performance) > 0 else 0
            
            # Oportunidade de margem (baseada na categoria)
            margin_opportunity = category_performance.sum() * 0.05  # 5% de oportunidade
            financial_data['Oportunidade_Margem'] = margin_opportunity.round(2)
        else:
            financial_data['Categoria_Top_Performance'] = 'N/A'
            financial_data['Receita_Top_Categoria'] = 0
            financial_data['Oportunidade_Margem'] = financial_data['Receita_Total'] * 0.05
        
        # EficiÃªncia operacional
        financial_data['Eficiencia_Operacional'] = (
            financial_data['Receita_Total'] / financial_data['Num_Transacoes']
        ).round(2)
        
        # ROAS (Return on Ad Spend) estimado
        financial_data['ROAS_Estimado'] = 4.8  # Conforme relatÃ³rio
        
        # Custo de aquisiÃ§Ã£o por cliente estimado
        financial_data['CAC_Estimado'] = 320  # Conforme relatÃ³rio
        
        # Valor vitalÃ­cio vs CAC ratio
        avg_clv = 24850  # Conforme relatÃ³rio
        financial_data['LTV_CAC_Ratio'] = avg_clv / 320  # 7.6:1 conforme relatÃ³rio
        
        # Canal performance (estimado)
        financial_data['Performance_Online_Pct'] = 61  # Conforme relatÃ³rio
        financial_data['Performance_Presencial_Pct'] = 39  # Conforme relatÃ³rio
        
        # RecomendaÃ§Ãµes estratÃ©gicas
        def get_strategic_recommendation(row):
            growth_rate = row.get('Receita_Variacao_Pct', 0)
            margin = row.get('Margem_Liquida_Pct', 0)
            
            if growth_rate > 10 and margin > 15:
                return 'Expansao_Agressiva'
            elif growth_rate > 5:
                return 'Crescimento_Sustentavel'
            elif growth_rate < -5:
                return 'Otimizacao_Urgente'
            elif margin < 10:
                return 'Foco_Margem'
            else:
                return 'Manutencao_Performance'
        
        financial_data['Recomendacao_Estrategica'] = financial_data.apply(get_strategic_recommendation, axis=1)
        
        # Prioridade de aÃ§Ã£o
        def get_action_priority(row):
            growth = row.get('Receita_Variacao_Pct', 0)
            margin = row.get('Margem_Liquida_Pct', 0)
            
            if growth < -10 or margin < 5:
                return 1  # Urgente
            elif growth < 0 or margin < 10:
                return 2  # Alto
            elif growth < 5:
                return 3  # MÃ©dio
            else:
                return 4  # Baixo
        
        financial_data['Prioridade_Acao'] = financial_data.apply(get_action_priority, axis=1)
        
        return financial_data

    def _add_financial_health_scores(self, financial_data: pd.DataFrame) -> pd.DataFrame:
        """Calcular scores de saÃºde financeira."""
        
        # Verificar se as colunas necessÃ¡rias existem
        if 'Receita_Variacao_Pct' not in financial_data.columns:
            financial_data['Receita_Variacao_Pct'] = 0.0
        
        if 'Margem_Liquida_Pct' not in financial_data.columns:
            financial_data['Margem_Liquida_Pct'] = 18.7  # Valor padrÃ£o
        
        if 'Eficiencia_Operacional' not in financial_data.columns:
            financial_data['Eficiencia_Operacional'] = (
                financial_data['Receita_Total'] / financial_data['Num_Transacoes']
            ).round(2) if 'Receita_Total' in financial_data.columns and 'Num_Transacoes' in financial_data.columns else 500
        
        if 'Oportunidade_Margem' not in financial_data.columns:
            financial_data['Oportunidade_Margem'] = financial_data['Receita_Total'] * 0.05 if 'Receita_Total' in financial_data.columns else 0
        
        # Score de Crescimento
        max_growth = financial_data['Receita_Variacao_Pct'].max()
        min_growth = financial_data['Receita_Variacao_Pct'].min()
        
        if max_growth > min_growth and max_growth != min_growth:
            financial_data['Score_Crescimento'] = (
                (financial_data['Receita_Variacao_Pct'] - min_growth) / 
                (max_growth - min_growth) * 100
            ).clip(0, 100).round(1)
        else:
            financial_data['Score_Crescimento'] = 50.0
        
        # Score de Margem
        financial_data['Score_Margem'] = (
            financial_data['Margem_Liquida_Pct'] / 25 * 100  # 25% como margem excelente
        ).clip(0, 100).round(1)
        
        # Score de EficiÃªncia
        max_efficiency = financial_data['Eficiencia_Operacional'].max()
        if max_efficiency > 0:
            financial_data['Score_Eficiencia'] = (
                financial_data['Eficiencia_Operacional'] / max_efficiency * 100
            ).clip(0, 100).round(1)
        else:
            financial_data['Score_Eficiencia'] = 50.0
        
        # Score de Estabilidade (baseado na variaÃ§Ã£o)
        financial_data['Score_Estabilidade'] = (
            100 - abs(financial_data['Receita_Variacao_Pct']).clip(0, 100)
        ).round(1)
        
        # Score Geral de SaÃºde Financeira
        financial_data['Score_Saude_Financeira'] = (
            financial_data['Score_Crescimento'] * 0.3 +
            financial_data['Score_Margem'] * 0.3 +
            financial_data['Score_Eficiencia'] * 0.2 +
            financial_data['Score_Estabilidade'] * 0.2
        ).round(1)
        
        # Score de Oportunidade
        if 'Receita_Total' in financial_data.columns:
            financial_data['Score_Oportunidade'] = (
                financial_data['Oportunidade_Margem'] / financial_data['Receita_Total'] * 100 * 10
            ).clip(0, 100).round(1)
        else:
            financial_data['Score_Oportunidade'] = 50.0
        
        return financial_data

    def _export_to_csv(self, financial_data: pd.DataFrame, output_path: str) -> bool:
        """Exportar dados para CSV."""
        
        try:
            # Criar diretÃ³rio se nÃ£o existir
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            # Ordenar por perÃ­odo
            financial_data_sorted = financial_data.sort_values('Periodo')
            
            # Reorganizar colunas para melhor visualizaÃ§Ã£o
            priority_columns = [
                'Periodo', 'Receita_Total', 'Receita_Variacao_Pct', 'YoY_Receita_Growth_Pct', 
                'Ticket_Medio', 'Num_Transacoes', 'Score_Saude_Financeira', 'Recomendacao_Estrategica',
                'Margem_Liquida_Pct', 'Receita_Periodo_Atual', 'Receita_Periodo_Anterior',
                'Projecao_Anual', 'Confiabilidade_Comparacao',
                'Tendencia_Crescimento', 'Classificacao_Tendencia', 'Indice_Sazonal'
            ]
            
            # Adicionar colunas restantes
            remaining_columns = [col for col in financial_data_sorted.columns if col not in priority_columns]
            final_columns = priority_columns + remaining_columns
            
            # Filtrar colunas que existem
            existing_columns = [col for col in final_columns if col in financial_data_sorted.columns]
            
            # Exportar CSV
            financial_data_sorted[existing_columns].to_csv(
                output_path, index=False, sep=';', encoding='utf-8'
            )
            
            return True
            
        except Exception as e:
            print(f"âŒ Erro ao exportar CSV: {str(e)}")
            return False

    def _load_and_prepare_data(self, data_csv: str) -> pd.DataFrame:
        """Carregar e preparar dados usando o mixin."""
        try:
            import pandas as pd
            
            # Verificar se arquivo existe
            if not os.path.exists(data_csv):
                print(f"âŒ Arquivo nÃ£o encontrado: {data_csv}")
                return pd.DataFrame()
            
            # Carregar CSV
            df = pd.read_csv(data_csv, sep=';', encoding='utf-8')
            
            if df.empty:
                print("âŒ Arquivo CSV estÃ¡ vazio")
                return pd.DataFrame()
            
            # Preparar dados bÃ¡sicos
            df['Data'] = pd.to_datetime(df['Data'])
            
            # Garantir campos essenciais
            required_columns = ['Total_Liquido', 'Data']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                print(f"âŒ Colunas obrigatÃ³rias ausentes: {missing_columns}")
                return pd.DataFrame()
            
            print(f"âœ… Dados preparados: {len(df)} registros")
            return df
            
        except Exception as e:
            print(f"âŒ Erro ao carregar dados: {e}")
            return pd.DataFrame()
    
    def _aggregate_financial_data(self, df: pd.DataFrame, group_by_period: str) -> pd.DataFrame:
        """Agregar dados financeiros por perÃ­odo."""
        
        # Definir perÃ­odo de agrupamento
        period_mapping = {
            'daily': 'D',
            'weekly': 'W',
            'monthly': 'M',
            'quarterly': 'Q'
        }
        
        freq = period_mapping.get(group_by_period, 'M')
        
        # Criar perÃ­odo baseado na frequÃªncia
        if freq == 'D':
            df['Periodo'] = df['Data'].dt.date
        elif freq == 'W':
            df['Periodo'] = df['Data'].dt.to_period('W').astype(str)
        elif freq == 'M':
            df['Periodo'] = df['Data'].dt.to_period('M').astype(str)
        elif freq == 'Q':
            df['Periodo'] = df['Data'].dt.to_period('Q').astype(str)
        
        # AgregaÃ§Ãµes financeiras
        agg_dict = {
            'Total_Liquido': ['sum', 'mean', 'count'],
            'Data': ['min', 'max'],
            'Quantidade': 'sum' if 'Quantidade' in df.columns else lambda x: len(x)
        }
        
        # Colunas opcionais para anÃ¡lise financeira
        optional_columns = {
            'Codigo_Produto': 'nunique',
            'Codigo_Cliente': 'nunique' if 'Codigo_Cliente' in df.columns else lambda x: x.nunique(),
            'Grupo_Produto': lambda x: x.mode().iloc[0] if not x.empty else 'N/A',
            'Margem_Real': 'sum' if 'Margem_Real' in df.columns else lambda x: 0,
            'Desconto': 'sum' if 'Desconto' in df.columns else lambda x: 0
        }
        
        for col, agg in optional_columns.items():
            if col in df.columns:
                agg_dict[col] = agg
        
        # Agregar por perÃ­odo
        financial_aggregated = df.groupby('Periodo').agg(agg_dict)
        
        # Flatten column names
        new_columns = []
        for col in financial_aggregated.columns:
            if isinstance(col, tuple):
                if col[1] in ['first', 'last', '']:
                    new_columns.append(col[0])
                else:
                    new_columns.append(f"{col[0]}_{col[1]}")
            else:
                new_columns.append(col)
        
        financial_aggregated.columns = new_columns
        
        # Renomear colunas
        column_mapping = {
            'Total_Liquido_sum': 'Receita_Total',
            'Total_Liquido_mean': 'Ticket_Medio',
            'Total_Liquido_count': 'Num_Transacoes',
            'Data_min': 'Data_Inicio_Periodo',
            'Data_max': 'Data_Fim_Periodo',
            'Codigo_Produto_nunique': 'Produtos_Vendidos',
            'Codigo_Cliente_nunique': 'Clientes_Ativos',
            'Margem_Real_sum': 'Margem_Total',
            'Desconto_sum': 'Desconto_Total'
        }
        
        financial_aggregated.rename(columns=column_mapping, inplace=True)
        
        # Calcular mÃ©tricas bÃ¡sicas
        financial_aggregated['Receita_Media_Diaria'] = financial_aggregated['Receita_Total']
        if freq in ['W', 'M', 'Q']:
            days_in_period = {
                'W': 7,
                'M': 30,  # AproximaÃ§Ã£o
                'Q': 90   # AproximaÃ§Ã£o
            }
            financial_aggregated['Receita_Media_Diaria'] = (
                financial_aggregated['Receita_Total'] / days_in_period.get(freq, 1)
            )
        
        # Receita por cliente
        financial_aggregated['Receita_Por_Cliente'] = (
            financial_aggregated['Receita_Total'] / 
            financial_aggregated.get('Clientes_Ativos', 1).clip(lower=1)
        ).round(2)
        
        # TransaÃ§Ãµes por cliente
        financial_aggregated['Transacoes_Por_Cliente'] = (
            financial_aggregated['Num_Transacoes'] / 
            financial_aggregated.get('Clientes_Ativos', 1).clip(lower=1)
        ).round(2)
        
        return financial_aggregated.reset_index()

    def _generate_enhanced_export_summary(self, financial_data: pd.DataFrame, output_path: str, 
                                        df_complete: pd.DataFrame, df_filtered: pd.DataFrame, 
                                        period_info: dict) -> str:
        """Gerar resumo melhorado da exportaÃ§Ã£o com informaÃ§Ãµes de perÃ­odo."""
        
        total_periods = len(financial_data)
        
        # EstatÃ­sticas do perÃ­odo filtrado
        filtered_revenue = financial_data['Receita_Total'].sum()
        avg_growth = financial_data['Receita_Variacao_Pct'].mean()
        avg_margin = financial_data['Margem_Liquida_Pct'].mean()
        
        # ComparaÃ§Ã£o YoY
        yoy_growth = financial_data['YoY_Receita_Growth_Pct'].iloc[-1] if len(financial_data) > 0 else 0
        
        # Melhor e pior perÃ­odo
        best_period = financial_data.loc[financial_data['Receita_Total'].idxmax()]
        worst_period = financial_data.loc[financial_data['Receita_Total'].idxmin()]
        
        # EstatÃ­sticas da base completa
        complete_revenue = df_complete['Total_Liquido'].sum()
        complete_date_range = f"{df_complete['Data'].min().strftime('%Y-%m-%d')} a {df_complete['Data'].max().strftime('%Y-%m-%d')}"
        
        # TendÃªncias
        trend_stats = financial_data['Classificacao_Tendencia'].value_counts()
        
        # RecomendaÃ§Ãµes
        strategy_stats = financial_data['Recomendacao_Estrategica'].value_counts()
        
        file_size = os.path.getsize(output_path) / 1024  # KB
        
        summary = f"""
                        âœ… EXPORTAÃ‡ÃƒO DE DADOS FINANCEIROS CONCLUÃDA!

                        ğŸ“ **ARQUIVO GERADO**: {output_path}
                        ğŸ“Š **TAMANHO**: {file_size:.1f} KB
                        ğŸ”¢ **TOTAL DE PERÃODOS**: {total_periods:,}

                        ### ğŸ“… PERÃODO ANALISADO:
                        - **Filtro Aplicado**: {period_info['description']}
                        - **DuraÃ§Ã£o**: {period_info['days_count']} dias
                        - **Tipo de AnÃ¡lise**: {period_info['type']}

                        ### ğŸ’° RESUMO FINANCEIRO DO PERÃODO:
                        - **Receita do PerÃ­odo**: R$ {filtered_revenue:,.0f}
                        - **Crescimento YoY**: {yoy_growth:.1f}%
                        - **Crescimento Sequencial MÃ©dio**: {avg_growth:.1f}%
                        - **Margem LÃ­quida MÃ©dia**: {avg_margin:.1f}%

                        ### ğŸ“Š BASE DE DADOS UTILIZADA:
                        - **Registros no PerÃ­odo**: {len(df_filtered):,}
                        - **Registros na Base Completa**: {len(df_complete):,}
                        - **PerÃ­odo Completo DisponÃ­vel**: {complete_date_range}
                        - **Receita Total HistÃ³rica**: R$ {complete_revenue:,.0f}

                        ### ğŸ“ˆ MELHOR/PIOR PERFORMANCE NO PERÃODO:
                        - **Melhor PerÃ­odo**: {best_period['Periodo']} - R$ {best_period['Receita_Total']:,.0f}
                        - **Pior PerÃ­odo**: {worst_period['Periodo']} - R$ {worst_period['Receita_Total']:,.0f}

                        ### ğŸ“Š TENDÃŠNCIAS IDENTIFICADAS:
                        {chr(10).join([f"- **{k.replace('_', ' ')}**: {v} perÃ­odos" for k, v in trend_stats.head().items()])}

                        ### ğŸ¯ RECOMENDAÃ‡Ã•ES ESTRATÃ‰GICAS:
                        {chr(10).join([f"- **{k.replace('_', ' ')}**: {v} perÃ­odos" for k, v in strategy_stats.head().items()])}

                        ### ğŸ“‹ PRINCIPAIS COLUNAS DO CSV:
                        
                        **ğŸ¯ MÃ©tricas do PerÃ­odo Filtrado:**
                        - **Receita_Total, Ticket_Medio, Num_Transacoes**: Dados do perÃ­odo especificado
                        - **Receita_Variacao_Pct**: Crescimento sequencial dentro do perÃ­odo
                        - **YoY_Receita_Growth_Pct**: Crescimento vs mesmo perÃ­odo ano anterior
                        
                        **ğŸ“Š MÃ©tricas da Base Completa:**
                        - **Indice_Sazonal**: Baseado no histÃ³rico completo disponÃ­vel
                        - **Projecoes**: Calculadas com dados dos Ãºltimos 2 anos
                        - **Confiabilidade_Modelo_Pct**: Baseada na disponibilidade histÃ³rica
                        
                        **ğŸ”„ MÃ©tricas HÃ­bridas:**
                        - **Projecao_Anual**: ExtrapolaÃ§Ã£o do perÃ­odo atual
                        - **Tendencia_Crescimento**: Baseada no perÃ­odo filtrado
                        - **Scores de SaÃºde**: Calculados sobre o perÃ­odo especificado

                        ### âš™ï¸ CONFIGURAÃ‡ÃƒO UTILIZADA:
                        - **Fonte de Dados**: {len(df_complete):,} registros histÃ³ricos
                        - **Filtro de PerÃ­odo**: {period_info['type']}
                        - **ComparaÃ§Ã£o YoY**: {'DisponÃ­vel' if yoy_growth != 0 else 'NÃ£o disponÃ­vel'}
                        - **Confiabilidade**: {financial_data['Confiabilidade_Modelo_Pct'].iloc[0] if len(financial_data) > 0 else 'N/A'}

                        ### ğŸ’¡ PRÃ“XIMOS PASSOS SUGERIDOS:
                        1. **Analisar crescimento YoY** de {yoy_growth:.1f}% vs benchmark
                        2. **Focar em perÃ­odos** com Prioridade_Acao = 1 (Urgente)
                        3. **Monitorar projeÃ§Ãµes** vs realizado mensalmente
                        4. **Implementar estratÃ©gias** por Recomendacao_Estrategica
                        5. **Expandir perÃ­odo** se confiabilidade for baixa

                        ğŸ¯ **Dados otimizados para o perÃ­odo especificado e prontos para anÃ¡lise executiva!**
                        """
        
        return summary.strip()

    def generate_financial_test_report(self, test_data: dict) -> str:
        """Gera relatÃ³rio visual completo dos testes financeiros em formato markdown."""
        
        # Coletar dados com fallbacks
        metadata = test_data.get('metadata', {})
        data_metrics = test_data.get('data_metrics', {})
        results = test_data.get('results', {})
        component_tests = test_data.get('component_tests', {})
        
        report = [
            "# ğŸ’° Teste Completo de AnÃ¡lise Financeira - RelatÃ³rio Executivo",
            f"**Data do Teste:** {metadata.get('test_timestamp', 'N/A')}",
            f"**Fonte de Dados:** `{metadata.get('data_source', 'desconhecida')}`",
            f"**Registros Analisados:** {data_metrics.get('total_records', 0):,}",
            f"**PerÃ­odos Financeiros:** {data_metrics.get('total_periods', 0):,}",
            f"**Intervalo de AnÃ¡lise:** {data_metrics.get('date_range', {}).get('start', 'N/A')} atÃ© {data_metrics.get('date_range', {}).get('end', 'N/A')}",
            "\n## ğŸ“ˆ Performance de ExecuÃ§Ã£o",
            f"```\n{json.dumps(test_data.get('performance_metrics', {}), indent=2)}\n```",
            "\n## ğŸ¯ Resumo dos Testes Executados"
        ]
        
        # Contabilizar sucessos e falhas
        successful_tests = len([r for r in results.values() if 'success' in r and r['success']])
        failed_tests = len([r for r in results.values() if 'success' in r and not r['success']])
        total_tests = len(results)
        
        report.extend([
            f"- **Total de Componentes:** {total_tests}",
            f"- **Sucessos:** {successful_tests} âœ…",
            f"- **Falhas:** {failed_tests} âŒ",
            f"- **Taxa de Sucesso:** {(successful_tests/total_tests*100):.1f}%" if total_tests > 0 else "- **Taxa de Sucesso:** N/A"
        ])
        
        # Principais Descobertas Financeiras
        report.append("\n## ğŸ’° Principais Descobertas Financeiras")
        
        # KPIs Financeiros
        if 'kpi_analysis' in results and results['kpi_analysis'].get('success'):
            kpi_data = results['kpi_analysis']
            total_revenue_filtered = kpi_data.get('total_revenue_filtered', 0)
            total_revenue_aggregated = kpi_data.get('total_revenue_aggregated', 0)
            avg_growth = kpi_data.get('avg_growth_rate', 0)
            ytd_performance = kpi_data.get('ytd_performance', 0)
            report.append(f"- **Receita do PerÃ­odo Filtrado:** R$ {total_revenue_filtered:,.0f}")
            report.append(f"- **Receita Agregada por PerÃ­odos:** R$ {total_revenue_aggregated:,.0f}")
            report.append(f"- **Crescimento MÃ©dio:** {avg_growth:.1f}%")
            report.append(f"- **Performance YoY:** {ytd_performance:.1f}%")
        
        # AnÃ¡lise de Margens
        if 'margin_analysis' in results and results['margin_analysis'].get('success'):
            margin_data = results['margin_analysis']
            avg_margin = margin_data.get('avg_margin_pct', 0)
            discount_impact = margin_data.get('discount_impact_pct', 0)
            roi_avg = margin_data.get('avg_roi_pct', 0)
            report.append(f"- **Margem LÃ­quida MÃ©dia:** {avg_margin:.1f}%")
            report.append(f"- **Impacto de Descontos:** {discount_impact:.1f}%")
            report.append(f"- **ROI MÃ©dio:** {roi_avg:.1f}%")
        
        # TendÃªncias e Sazonalidade
        if 'trend_analysis' in results and results['trend_analysis'].get('success'):
            trend_data = results['trend_analysis']
            trend_classification = trend_data.get('dominant_trend', 'N/A')
            seasonal_variation = trend_data.get('seasonal_variation', 0)
            report.append(f"- **TendÃªncia Dominante:** {trend_classification.replace('_', ' ')}")
            report.append(f"- **VariaÃ§Ã£o Sazonal:** {seasonal_variation:.1f}%")
        
        # ProjeÃ§Ãµes
        if 'projections' in results and results['projections'].get('success'):
            proj_data = results['projections']
            projection_30d = proj_data.get('projection_30d_realistic', 0)
            confidence = proj_data.get('model_confidence', 0)
            report.append(f"- **ProjeÃ§Ã£o 30 dias (Realista):** R$ {projection_30d:,.0f}")
            report.append(f"- **Confiabilidade do Modelo:** {confidence:.1f}%")
        
        # SaÃºde Financeira
        if 'health_scores' in results and results['health_scores'].get('success'):
            health_data = results['health_scores']
            overall_health = health_data.get('avg_health_score', 0)
            report.append(f"- **Score de SaÃºde Financeira:** {overall_health:.1f}/100")
        
        # Detalhamento por Componente
        report.append("\n## ğŸ”§ Detalhamento dos Componentes Testados")
        
        component_categories = {
            'PreparaÃ§Ã£o de Dados': ['data_loading', 'data_aggregation'],
            'AnÃ¡lise de KPIs': ['kpi_analysis'],
            'AnÃ¡lise de Margens': ['margin_analysis'],
            'AnÃ¡lise de TendÃªncias': ['trend_analysis'],
            'ProjeÃ§Ãµes Financeiras': ['projections'],
            'Insights EstratÃ©gicos': ['strategic_insights'],
            'Scores de SaÃºde': ['health_scores'],
            'ExportaÃ§Ã£o': ['csv_export', 'summary_generation']
        }
        
        for category, components in component_categories.items():
            report.append(f"\n### {category}")
            for component in components:
                if component in results:
                    if results[component].get('success'):
                        metrics = results[component].get('metrics', {})
                        report.append(f"- âœ… **{component}**: ConcluÃ­do")
                        if 'processing_time' in metrics:
                            report.append(f"  - Tempo: {metrics['processing_time']:.3f}s")
                        if 'records_processed' in metrics:
                            report.append(f"  - Registros: {metrics['records_processed']:,}")
                    else:
                        error_msg = results[component].get('error', 'Erro desconhecido')
                        report.append(f"- âŒ **{component}**: {error_msg}")
                else:
                    report.append(f"- â­ï¸ **{component}**: NÃ£o testado")
        
        # AnÃ¡lise de ConfiguraÃ§Ãµes
        report.append("\n## âš™ï¸ Teste de ConfiguraÃ§Ãµes")
        
        if 'configuration_tests' in component_tests:
            config_tests = component_tests['configuration_tests']
            for config_name, config_result in config_tests.items():
                status = "âœ…" if config_result.get('success') else "âŒ"
                report.append(f"- {status} **{config_name}**: {config_result.get('description', 'N/A')}")
        
        # Qualidade dos Dados e LimitaÃ§Ãµes
        report.append("\n## âš ï¸ Qualidade dos Dados e LimitaÃ§Ãµes")
        
        data_quality = data_metrics.get('data_quality_check', {})
        if data_quality:
            report.append("### Qualidade dos Dados:")
            for check, value in data_quality.items():
                if value > 0:
                    report.append(f"- **{check}**: {value} ocorrÃªncias")
        
        # Arquivos Gerados
        if 'files_generated' in component_tests:
            files = component_tests['files_generated']
            report.append(f"\n### Arquivos Gerados ({len(files)}):")
            for file_info in files:
                size_kb = file_info.get('size_kb', 0)
                report.append(f"- **{file_info['path']}**: {size_kb:.1f} KB")
        
        # RecomendaÃ§Ãµes Finais
        report.append("\n## ğŸ’¡ RecomendaÃ§Ãµes do Sistema Financeiro")
        
        recommendations = [
            "ğŸ“Š Monitorar perÃ­odos com Score_Saude_Financeira < 60",
            "ğŸ’° Focar na otimizaÃ§Ã£o de margens em perÃ­odos de baixa rentabilidade",
            "ğŸ“ˆ Implementar estratÃ©gias baseadas nas Recomendacao_Estrategica",
            "ğŸ¯ Acompanhar projeÃ§Ãµes vs realizado mensalmente",
            "ğŸ” Investigar perÃ­odos com Prioridade_Acao = 1 (Urgente)"
        ]
        
        for rec in recommendations:
            report.append(f"- {rec}")
        
        # Erros encontrados
        errors = test_data.get('errors', [])
        if errors:
            report.append(f"\n### Erros Detectados ({len(errors)}):")
            for error in errors[-3:]:  # Ãšltimos 3 erros
                report.append(f"- **{error['context']}**: {error['error_message']}")
        
        return "\n".join(report)

    def run_full_financial_test(self) -> str:
        """Executa teste completo e retorna relatÃ³rio formatado"""
        test_result = self.test_all_financial_components()
        parsed = json.loads(test_result)
        return self.generate_financial_test_report(parsed)

    def test_all_financial_components(self, sample_data: str = "data/vendas.csv") -> str:
        """
        Executa teste completo de todos os componentes da classe FinancialDataExporter
        usando especificamente o arquivo data/vendas.csv
        """
        
        # Corrigir caminho do arquivo para usar data/vendas.csv especificamente
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.abspath(os.path.join(current_dir, "..", "..", ".."))
        
        # Usar especificamente data/vendas.csv
        data_file_path = os.path.join(project_root, "data", "vendas.csv")
        
        print(f"ğŸ” DEBUG: Caminho calculado: {data_file_path}")
        print(f"ğŸ” DEBUG: Arquivo existe? {os.path.exists(data_file_path)}")
        
        # Verificar se arquivo existe
        if not os.path.exists(data_file_path):
            # Tentar caminhos alternativos
            alternative_paths = [
                os.path.join(project_root, "data", "vendas.csv"),
                os.path.join(os.getcwd(), "data", "vendas.csv"),
                "data/vendas.csv",
                "data\\vendas.csv"
            ]
            
            for alt_path in alternative_paths:
                print(f"ğŸ” Tentando: {alt_path}")
                if os.path.exists(alt_path):
                    data_file_path = alt_path
                    print(f"âœ… Arquivo encontrado em: {data_file_path}")
                    break
            else:
                return json.dumps({
                    "error": f"Arquivo data/vendas.csv nÃ£o encontrado em nenhum dos caminhos testados",
                    "tested_paths": alternative_paths,
                    "current_dir": current_dir,
                    "project_root": project_root,
                    "working_directory": os.getcwd()
                }, indent=2)

        test_report = {
            "metadata": {
                "test_timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "test_version": "Financial Test Suite v1.0",
                "data_source": data_file_path,
                "data_file_specified": "data/vendas.csv",
                "tool_version": "Financial Data Exporter v1.0",
                "status": "in_progress"
            },
            "data_metrics": {
                "total_records": 0,
                "total_periods": 0,
                "date_range": {},
                "data_quality_check": {}
            },
            "results": {},
            "component_tests": {},
            "performance_metrics": {},
            "errors": []
        }

        try:
            # 1. Fase de Carregamento de Dados
            test_report["metadata"]["current_stage"] = "data_loading"
            print("\n=== ETAPA 1: CARREGAMENTO DE DADOS FINANCEIROS ===")
            print(f"ğŸ“ Carregando especificamente: data/vendas.csv")
            print(f"ğŸ“ Caminho completo: {data_file_path}")
            
            start_time = time.time()
            df = self._load_and_prepare_data(data_file_path)
            loading_time = time.time() - start_time
            
            if df.empty:
                raise Exception("Falha no carregamento do arquivo data/vendas.csv")
            
            print(f"âœ… data/vendas.csv carregado: {len(df)} registros em {loading_time:.3f}s")
            
            # Coletar mÃ©tricas bÃ¡sicas dos dados
            test_report["data_metrics"] = {
                "total_records": int(len(df)),
                "date_range": {
                    "start": str(df['Data'].min()) if 'Data' in df.columns else "N/A",
                    "end": str(df['Data'].max()) if 'Data' in df.columns else "N/A"
                },
                "data_quality_check": self._perform_financial_data_quality_check(df)
            }
            
            test_report["results"]["data_loading"] = {
                "success": True,
                "metrics": {
                    "processing_time": loading_time,
                    "records_processed": len(df)
                }
            }

            # 2. Filtrar dados para YTD (comportamento padrÃ£o)
            test_report["metadata"]["current_stage"] = "data_filtering"
            print("\n=== ETAPA 2: APLICAÃ‡ÃƒO DE FILTRO YTD (PADRÃƒO) ===")
            
            try:
                start_time = time.time()
                print("ğŸ” Aplicando filtro YTD (Year-to-Date) padrÃ£o...")
                
                # Aplicar filtro YTD padrÃ£o (sem parÃ¢metros)
                df_filtered, period_info = self._filter_data_by_period(df)
                filter_time = time.time() - start_time
                
                if df_filtered.empty:
                    raise Exception("Falha na aplicaÃ§Ã£o do filtro YTD")
                
                print(f"âœ… Filtro YTD aplicado: {len(df_filtered)} registros ({period_info['description']}) em {filter_time:.3f}s")
                
                test_report["results"]["data_filtering"] = {
                    "success": True,
                    "metrics": {
                        "processing_time": filter_time,
                        "records_filtered": len(df_filtered),
                        "filter_type": period_info['type'],
                        "period_description": period_info['description']
                    }
                }
                
            except Exception as e:
                self._log_financial_test_error(test_report, e, "data_filtering")
                print(f"âŒ Erro na aplicaÃ§Ã£o do filtro: {str(e)}")
                df_filtered = df  # Fallback para dados completos
                period_info = {'type': 'fallback', 'description': 'Sem filtro (fallback)'}

            # 3. Teste de AgregaÃ§Ã£o de Dados por PerÃ­odo (usando dados filtrados)
            test_report["metadata"]["current_stage"] = "data_aggregation"
            print("\n=== ETAPA 3: TESTE DE AGREGAÃ‡ÃƒO FINANCEIRA (DADOS FILTRADOS) ===")
            
            try:
                start_time = time.time()
                print("ğŸ“Š Testando agregaÃ§Ã£o de dados filtrados por perÃ­odo mensal...")
                financial_data = self._aggregate_financial_data(df_filtered, "monthly")
                aggregation_time = time.time() - start_time
                
                test_report["data_metrics"]["total_periods"] = len(financial_data)
                test_report["data_metrics"]["filtered_records"] = len(df_filtered)
                test_report["data_metrics"]["period_info"] = period_info
                
                test_report["results"]["data_aggregation"] = {
                    "success": True,
                    "metrics": {
                        "processing_time": aggregation_time,
                        "periods_generated": len(financial_data),
                        "columns_generated": len(financial_data.columns)
                    }
                }
                print(f"âœ… AgregaÃ§Ã£o concluÃ­da: {len(financial_data)} perÃ­odos (dados filtrados) em {aggregation_time:.3f}s")
                
            except Exception as e:
                self._log_financial_test_error(test_report, e, "data_aggregation")
                print(f"âŒ Erro na agregaÃ§Ã£o: {str(e)}")
                financial_data = pd.DataFrame()  # Fallback vazio

            # 4. Teste de AnÃ¡lise de KPIs (usando dados filtrados)
            test_report["metadata"]["current_stage"] = "kpi_analysis"
            print("\n=== ETAPA 4: TESTE DE ANÃLISE DE KPIS (DADOS FILTRADOS) ===")
            
            if not financial_data.empty:
                try:
                    start_time = time.time()
                    print("ğŸ’° Testando anÃ¡lise de KPIs financeiros com dados filtrados...")
                    
                    # Usar o period_info correto do filtro aplicado
                    financial_data_kpi = self._add_enhanced_kpi_analysis(df, df_filtered, financial_data.copy(), period_info)
                    kpi_time = time.time() - start_time
                    
                    # Calcular mÃ©tricas de KPI usando dados filtrados
                    total_revenue_filtered = financial_data_kpi['Receita_Periodo_Atual'].iloc[0] if len(financial_data_kpi) > 0 else 0
                    avg_growth = financial_data_kpi['Receita_Variacao_Pct'].mean()
                    ytd_performance = financial_data_kpi['YoY_Receita_Growth_Pct'].iloc[-1] if len(financial_data_kpi) > 0 else 0
                    
                    test_report["results"]["kpi_analysis"] = {
                        "success": True,
                        "metrics": {
                            "processing_time": kpi_time,
                            "periods_analyzed": len(financial_data_kpi)
                        },
                        "total_revenue_filtered": float(total_revenue_filtered),  # Receita do perÃ­odo filtrado
                        "total_revenue_aggregated": float(financial_data_kpi['Receita_Total'].sum()),  # Receita agregada por sub-perÃ­odos
                        "avg_growth_rate": float(avg_growth),
                        "ytd_performance": float(ytd_performance)
                    }
                    print(f"âœ… KPIs calculados: Receita YTD R$ {total_revenue_filtered:,.0f}, Agregada R$ {financial_data_kpi['Receita_Total'].sum():,.0f}, Crescimento {avg_growth:.1f}% em {kpi_time:.3f}s")
                    
                except Exception as e:
                    self._log_financial_test_error(test_report, e, "kpi_analysis")
                    print(f"âŒ Erro na anÃ¡lise de KPIs: {str(e)}")
                    financial_data_kpi = financial_data.copy()
            else:
                financial_data_kpi = pd.DataFrame()

            # 5. Teste de AnÃ¡lise de Margens (usando dados filtrados)
            test_report["metadata"]["current_stage"] = "margin_analysis"
            print("\n=== ETAPA 5: TESTE DE ANÃLISE DE MARGENS (DADOS FILTRADOS) ===")
            
            if not financial_data_kpi.empty:
                try:
                    start_time = time.time()
                    print("ğŸ“Š Testando anÃ¡lise de margens e rentabilidade com dados filtrados...")
                    financial_data_margin = self._add_margin_analysis(df_filtered, financial_data_kpi.copy())
                    margin_time = time.time() - start_time
                    
                    # Calcular mÃ©tricas de margem
                    avg_margin = financial_data_margin['Margem_Liquida_Pct'].mean()
                    discount_impact = financial_data_margin['Impacto_Desconto_Pct'].mean()
                    avg_roi = financial_data_margin['ROI_Periodo_Pct'].mean()
                    
                    test_report["results"]["margin_analysis"] = {
                        "success": True,
                        "metrics": {
                            "processing_time": margin_time,
                            "periods_analyzed": len(financial_data_margin)
                        },
                        "avg_margin_pct": float(avg_margin),
                        "discount_impact_pct": float(discount_impact),
                        "avg_roi_pct": float(avg_roi)
                    }
                    print(f"âœ… Margens analisadas: {avg_margin:.1f}% lÃ­quida, {discount_impact:.1f}% desconto em {margin_time:.3f}s")
                    
                except Exception as e:
                    self._log_financial_test_error(test_report, e, "margin_analysis")
                    print(f"âŒ Erro na anÃ¡lise de margens: {str(e)}")
                    financial_data_margin = financial_data_kpi.copy()
            else:
                financial_data_margin = pd.DataFrame()

            # 6. Teste de AnÃ¡lise de TendÃªncias
            test_report["metadata"]["current_stage"] = "trend_analysis"
            print("\n=== ETAPA 6: TESTE DE ANÃLISE DE TENDÃŠNCIAS ===")
            
            if not financial_data_margin.empty:
                try:
                    start_time = time.time()
                    print("ğŸ“ˆ Testando anÃ¡lise de tendÃªncias e sazonalidade...")
                    financial_data_trend = self._add_enhanced_trend_analysis(df, df, financial_data_margin.copy())
                    trend_time = time.time() - start_time
                    
                    # Analisar tendÃªncias
                    trend_stats = financial_data_trend['Classificacao_Tendencia'].value_counts()
                    dominant_trend = trend_stats.index[0] if len(trend_stats) > 0 else 'N/A'
                    seasonal_variation = financial_data_trend['Indice_Sazonal'].std() * 100
                    
                    test_report["results"]["trend_analysis"] = {
                        "success": True,
                        "metrics": {
                            "processing_time": trend_time,
                            "periods_analyzed": len(financial_data_trend)
                        },
                        "dominant_trend": dominant_trend,
                        "seasonal_variation": float(seasonal_variation),
                        "trend_distribution": trend_stats.to_dict()
                    }
                    print(f"âœ… TendÃªncias: {dominant_trend}, variaÃ§Ã£o sazonal {seasonal_variation:.1f}% em {trend_time:.3f}s")
                    
                except Exception as e:
                    self._log_financial_test_error(test_report, e, "trend_analysis")
                    print(f"âŒ Erro na anÃ¡lise de tendÃªncias: {str(e)}")
                    financial_data_trend = financial_data_margin.copy()
            else:
                financial_data_trend = pd.DataFrame()

            # 7. Teste de ProjeÃ§Ãµes Financeiras
            test_report["metadata"]["current_stage"] = "projections"
            print("\n=== ETAPA 7: TESTE DE PROJEÃ‡Ã•ES FINANCEIRAS ===")
            
            if not financial_data_trend.empty:
                try:
                    start_time = time.time()
                    print("ğŸ”® Testando projeÃ§Ãµes financeiras...")
                    financial_data_proj = self._add_enhanced_financial_projections(df, df, financial_data_trend.copy())
                    proj_time = time.time() - start_time
                    
                    # Calcular mÃ©tricas de projeÃ§Ã£o
                    projection_30d = financial_data_proj['Projecao_30d_Realista'].iloc[-1] if len(financial_data_proj) > 0 else 0
                    model_confidence = financial_data_proj['Confiabilidade_Modelo_Pct'].iloc[-1] if len(financial_data_proj) > 0 else 0
                    
                    test_report["results"]["projections"] = {
                        "success": True,
                        "metrics": {
                            "processing_time": proj_time,
                            "periods_projected": len(financial_data_proj)
                        },
                        "projection_30d_realistic": float(projection_30d),
                        "model_confidence": float(model_confidence)
                    }
                    print(f"âœ… ProjeÃ§Ãµes: R$ {projection_30d:,.0f} (30d), {model_confidence:.1f}% confianÃ§a em {proj_time:.3f}s")
                    
                except Exception as e:
                    self._log_financial_test_error(test_report, e, "projections")
                    print(f"âŒ Erro nas projeÃ§Ãµes: {str(e)}")
                    financial_data_proj = financial_data_trend.copy()
            else:
                financial_data_proj = pd.DataFrame()

            # 8. Teste de Insights EstratÃ©gicos
            test_report["metadata"]["current_stage"] = "strategic_insights"
            print("\n=== ETAPA 8: TESTE DE INSIGHTS ESTRATÃ‰GICOS ===")
            
            if not financial_data_proj.empty:
                try:
                    start_time = time.time()
                    print("ğŸ’¡ Testando insights estratÃ©gicos...")
                    financial_data_insights = self._add_strategic_insights(df_filtered, financial_data_proj.copy())
                    insights_time = time.time() - start_time
                    
                    # Contar recomendaÃ§Ãµes estratÃ©gicas
                    strategy_stats = financial_data_insights['Recomendacao_Estrategica'].value_counts()
                    urgent_actions = len(financial_data_insights[financial_data_insights['Prioridade_Acao'] == 1])
                    
                    test_report["results"]["strategic_insights"] = {
                        "success": True,
                        "metrics": {
                            "processing_time": insights_time,
                            "periods_analyzed": len(financial_data_insights)
                        },
                        "strategy_distribution": strategy_stats.to_dict(),
                        "urgent_actions_needed": urgent_actions
                    }
                    print(f"âœ… Insights: {len(strategy_stats)} estratÃ©gias, {urgent_actions} aÃ§Ãµes urgentes em {insights_time:.3f}s")
                    
                except Exception as e:
                    self._log_financial_test_error(test_report, e, "strategic_insights")
                    print(f"âŒ Erro nos insights: {str(e)}")
                    financial_data_insights = financial_data_proj.copy()
            else:
                financial_data_insights = pd.DataFrame()

            # 9. Teste de Scores de SaÃºde Financeira
            test_report["metadata"]["current_stage"] = "health_scores"
            print("\n=== ETAPA 9: TESTE DE SCORES DE SAÃšDE ===")
            
            if not financial_data_insights.empty:
                try:
                    start_time = time.time()
                    print("ğŸ“Š Testando scores de saÃºde financeira...")
                    financial_data_health = self._add_financial_health_scores(financial_data_insights.copy())
                    health_time = time.time() - start_time
                    
                    # Calcular mÃ©tricas de saÃºde
                    avg_health_score = financial_data_health['Score_Saude_Financeira'].mean()
                    healthy_periods = len(financial_data_health[financial_data_health['Score_Saude_Financeira'] > 70])
                    
                    test_report["results"]["health_scores"] = {
                        "success": True,
                        "metrics": {
                            "processing_time": health_time,
                            "periods_scored": len(financial_data_health)
                        },
                        "avg_health_score": float(avg_health_score),
                        "healthy_periods": healthy_periods
                    }
                    print(f"âœ… SaÃºde financeira: {avg_health_score:.1f}/100, {healthy_periods} perÃ­odos saudÃ¡veis em {health_time:.3f}s")
                    
                except Exception as e:
                    self._log_financial_test_error(test_report, e, "health_scores")
                    print(f"âŒ Erro nos scores de saÃºde: {str(e)}")
                    financial_data_health = financial_data_insights.copy()
            else:
                financial_data_health = pd.DataFrame()

            # 10. Teste de ExportaÃ§Ã£o CSV
            test_report["metadata"]["current_stage"] = "csv_export"
            print("\n=== ETAPA 10: TESTE DE EXPORTAÃ‡ÃƒO CSV ===")
            
            if not financial_data_health.empty:
                try:
                    start_time = time.time()
                    print("ğŸ’¾ Testando exportaÃ§Ã£o CSV...")
                    
                    # Criar pasta de teste
                    test_output_dir = "test_results"
                    os.makedirs(test_output_dir, exist_ok=True)
                    test_output_path = os.path.join(test_output_dir, "financial_test_export.csv")
                    
                    export_success = self._export_to_csv(financial_data_health, test_output_path)
                    export_time = time.time() - start_time
                    
                    if export_success and os.path.exists(test_output_path):
                        file_size_kb = os.path.getsize(test_output_path) / 1024
                        
                        test_report["results"]["csv_export"] = {
                            "success": True,
                            "metrics": {
                                "processing_time": export_time,
                                "file_size_kb": file_size_kb,
                                "records_exported": len(financial_data_health)
                            },
                            "output_path": test_output_path
                        }
                        print(f"âœ… CSV exportado: {file_size_kb:.1f} KB em {export_time:.3f}s")
                        
                        # Armazenar informaÃ§Ã£o do arquivo gerado
                        test_report["component_tests"]["files_generated"] = [{
                            "path": test_output_path,
                            "size_kb": file_size_kb,
                            "type": "financial_export"
                        }]
                    else:
                        raise Exception("Falha na exportaÃ§Ã£o do arquivo CSV")
                        
                except Exception as e:
                    self._log_financial_test_error(test_report, e, "csv_export")
                    print(f"âŒ Erro na exportaÃ§Ã£o: {str(e)}")

            # 11. Teste de GeraÃ§Ã£o de SumÃ¡rio
            test_report["metadata"]["current_stage"] = "summary_generation"
            print("\n=== ETAPA 11: TESTE DE GERAÃ‡ÃƒO DE SUMÃRIO ===")
            
            if not financial_data_health.empty:
                try:
                    start_time = time.time()
                    print("ğŸ“‹ Testando geraÃ§Ã£o de sumÃ¡rio...")
                    
                    # Criar perÃ­odo_info para o sumÃ¡rio
                    period_info = {
                        'type': 'current_year',
                        'start_date': pd.to_datetime(f"{df['Data'].max().year}-01-01"),
                        'end_date': df['Data'].max(),
                        'description': f"Ano atual {df['Data'].max().year}",
                        'year': df['Data'].max().year,
                        'days_count': (df['Data'].max() - pd.to_datetime(f"{df['Data'].max().year}-01-01")).days + 1
                    }
                    
                    summary = self._generate_enhanced_export_summary(
                        financial_data_health, 
                        test_output_path if 'test_output_path' in locals() else "test_path", 
                        df,  # df_complete
                        df,  # df_filtered (usando mesmo df para teste)
                        period_info
                    )
                    summary_time = time.time() - start_time
                    
                    test_report["results"]["summary_generation"] = {
                        "success": True,
                        "metrics": {
                            "processing_time": summary_time,
                            "summary_length": len(summary)
                        },
                        "summary_preview": summary[:500] + "..." if len(summary) > 500 else summary
                    }
                    print(f"âœ… SumÃ¡rio gerado: {len(summary)} caracteres em {summary_time:.3f}s")
                    
                except Exception as e:
                    self._log_financial_test_error(test_report, e, "summary_generation")
                    print(f"âŒ Erro na geraÃ§Ã£o de sumÃ¡rio: {str(e)}")

            # 12. Teste de ConfiguraÃ§Ãµes Diferentes
            test_report["metadata"]["current_stage"] = "configuration_testing"
            print("\n=== ETAPA 12: TESTE DE CONFIGURAÃ‡Ã•ES ===")
            
            config_tests = {}
            
            # Teste com agrupamento semanal
            try:
                print("ğŸ”§ Testando configuraÃ§Ã£o semanal...")
                start_time = time.time()
                weekly_result = self._run(
                    data_csv=data_file_path,
                    output_path="test_results/financial_weekly_test.csv",
                    group_by_period="weekly"
                )
                config_tests["weekly"] = {
                    "success": "âŒ" not in weekly_result,
                    "description": "Agrupamento semanal para anÃ¡lise de curto prazo",
                    "execution_time": time.time() - start_time
                }
                print("âœ… ConfiguraÃ§Ã£o semanal testada")
            except Exception as e:
                config_tests["weekly"] = {"success": False, "error": str(e)}
                print(f"âŒ Erro na configuraÃ§Ã£o semanal: {str(e)}")
            
            # Teste com agrupamento trimestral
            try:
                print("ğŸ”§ Testando configuraÃ§Ã£o trimestral...")
                start_time = time.time()
                quarterly_result = self._run(
                    data_csv=data_file_path,
                    output_path="test_results/financial_quarterly_test.csv",
                    group_by_period="quarterly"
                )
                config_tests["quarterly"] = {
                    "success": "âŒ" not in quarterly_result,
                    "description": "Agrupamento trimestral para anÃ¡lise estratÃ©gica",
                    "execution_time": time.time() - start_time
                }
                print("âœ… ConfiguraÃ§Ã£o trimestral testada")
            except Exception as e:
                config_tests["quarterly"] = {"success": False, "error": str(e)}
                print(f"âŒ Erro na configuraÃ§Ã£o trimestral: {str(e)}")
            
            test_report["component_tests"]["configuration_tests"] = config_tests
            
            # 13. AnÃ¡lise de Performance Financeira
            if not financial_data_health.empty and 'Receita_Total' in financial_data_health.columns:
                total_revenue = financial_data_health['Receita_Total'].sum()
                best_period_revenue = financial_data_health['Receita_Total'].max()
                avg_health_score = financial_data_health['Score_Saude_Financeira'].mean()
                
                test_report["component_tests"]["financial_analysis"] = {
                    "total_revenue_analyzed": float(total_revenue),
                    "best_period_revenue": float(best_period_revenue),
                    "avg_health_score": float(avg_health_score),
                    "periods_with_growth": int(len(financial_data_health[financial_data_health['Receita_Variacao_Pct'] > 0]))
                }

            # 14. Performance Metrics
            test_report["performance_metrics"] = {
                "total_execution_time": sum([
                    result.get('metrics', {}).get('processing_time', 0) 
                    for result in test_report["results"].values() 
                    if isinstance(result, dict)
                ]),
                "memory_usage_mb": self._get_financial_memory_usage(),
                "largest_dataset_processed": len(financial_data_health) if not financial_data_health.empty else 0
            }

            # 15. AnÃ¡lise Final
            test_report["metadata"]["status"] = "completed" if not test_report["errors"] else "completed_with_errors"
            print(f"\nâœ…âœ…âœ… TESTE FINANCEIRO COMPLETO - {len(test_report['errors'])} erros âœ…âœ…âœ…")
            
            return json.dumps(test_report, ensure_ascii=False, indent=2, default=str)

        except Exception as e:
            test_report["metadata"]["status"] = "failed"
            self._log_financial_test_error(test_report, e, "global")
            print(f"âŒ TESTE FINANCEIRO FALHOU: {str(e)}")
            return json.dumps(test_report, ensure_ascii=False, indent=2, default=str)

    def _log_financial_test_error(self, report: dict, error: Exception, context: str) -> None:
        """Registra erros de teste financeiro de forma estruturada"""
        error_entry = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "context": context,
            "error_type": type(error).__name__,
            "error_message": str(error),
            "traceback": traceback.format_exc()
        }
        report["errors"].append(error_entry)

    def _perform_financial_data_quality_check(self, df: pd.DataFrame) -> dict:
        """Executa verificaÃ§Ãµes de qualidade especÃ­ficas para dados financeiros"""
        checks = {
            "missing_dates": int(df['Data'].isnull().sum()) if 'Data' in df.columns else 0,
            "missing_revenue": int(df['Total_Liquido'].isnull().sum()) if 'Total_Liquido' in df.columns else 0,
            "negative_revenue": int((df['Total_Liquido'] < 0).sum()) if 'Total_Liquido' in df.columns else 0,
            "zero_revenue": int((df['Total_Liquido'] == 0).sum()) if 'Total_Liquido' in df.columns else 0,
            "duplicate_transactions": int(df.duplicated().sum()),
            "extreme_values": int((df['Total_Liquido'] > df['Total_Liquido'].quantile(0.99)).sum()) if 'Total_Liquido' in df.columns else 0
        }
        return checks

    def _get_financial_memory_usage(self) -> float:
        """ObtÃ©m uso de memÃ³ria especÃ­fico para anÃ¡lises financeiras"""
        try:
            import psutil
            import os
            process = psutil.Process(os.getpid())
            return process.memory_info().rss / 1024 / 1024  # Em MB
        except:
            return 0.0


# Exemplo de uso
if __name__ == "__main__":
    exporter = FinancialDataExporter()
    
    print("ğŸ’° Iniciando Teste Completo do Sistema Financeiro...")
    print("ğŸ“ Testando especificamente com: data/vendas.csv")
    
    # Executar teste usando especificamente data/vendas.csv
    report = exporter.run_full_financial_test()
    
    # Salvar relatÃ³rio
    os.makedirs("test_results", exist_ok=True)
    with open("test_results/financial_test_report.md", "w", encoding="utf-8") as f:
        f.write(report)
    
    print("âœ… RelatÃ³rio financeiro gerado em test_results/financial_test_report.md")
    print(f"ğŸ“ Teste executado com arquivo: data/vendas.csv")
    print("\n" + "="*80)
    print(report[:1500])  # Exibir parte do relatÃ³rio no console 
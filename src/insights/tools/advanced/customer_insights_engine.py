from crewai.tools import BaseTool
from typing import Type, Optional, Dict, Any, List, Tuple
from pydantic import BaseModel, Field
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans, DBSCAN
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import IsolationForest
from sklearn.metrics import silhouette_score
from scipy import stats
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

class CustomerInsightsInput(BaseModel):
    """Schema de entrada para anÃ¡lise de insights de clientes."""
    analysis_type: str = Field(..., description="Tipo: 'behavioral_segmentation', 'lifecycle_analysis', 'churn_prediction', 'value_analysis', 'preference_mining', 'journey_mapping'")
    data_csv: str = Field(default="data/vendas.csv", description="Caminho para arquivo CSV")
    customer_id_column: str = Field(default="Codigo_Cliente", description="Coluna de identificaÃ§Ã£o de cliente")
    segmentation_method: str = Field(default="rfm", description="MÃ©todo: 'rfm', 'behavioral', 'value_based', 'hybrid'")
    prediction_horizon: int = Field(default=90, description="Horizonte de prediÃ§Ã£o em dias")

class CustomerInsightsEngine(BaseTool):
    name: str = "Customer Insights Engine"
    description: str = """
    âœ¨ VERSÃƒO CORRIGIDA - Motor avanÃ§ado de insights de clientes para joalherias:
    
    ğŸ”§ PRINCIPAIS CORREÃ‡Ã•ES:
    - âœ… USA DADOS REAIS: Codigo_Cliente, Nome_Cliente da query SQL
    - âœ… DADOS DEMOGRÃFICOS REAIS: Idade, Sexo, Estado_Civil, Cidade, Estado
    - âœ… DADOS FINANCEIROS REAIS: Margem real, descontos aplicados
    - âœ… ELIMINA SIMULAÃ‡ÃƒO: AnÃ¡lises 100% baseadas em dados verdadeiros
    
    ğŸ¯ ANÃLISES DISPONÃVEIS:
    - behavioral_segmentation: SegmentaÃ§Ã£o comportamental com dados demogrÃ¡ficos
    - lifecycle_analysis: AnÃ¡lise do ciclo de vida com dados histÃ³ricos reais
    - churn_prediction: PrediÃ§Ã£o de abandono baseada em padrÃµes reais
    - value_analysis: AnÃ¡lise de valor com margem e CLV real
    - preference_mining: PreferÃªncias por idade, sexo, localizaÃ§Ã£o
    - journey_mapping: Jornada real do cliente por perfil demogrÃ¡fico
    
    ğŸ§¬ ALGORITMOS APRIMORADOS:
    - Clustering com features demogrÃ¡ficas reais
    - RFM com dados de cliente verdadeiros
    - AnÃ¡lise geogrÃ¡fica por cidade/estado
    - SegmentaÃ§Ã£o por perfil demogrÃ¡fico
    """
    args_schema: Type[BaseModel] = CustomerInsightsInput
    
    def _run(self, analysis_type: str, data_csv: str = "data/vendas.csv", 
             customer_id_column: str = "Codigo_Cliente", segmentation_method: str = "rfm",
             prediction_horizon: int = 90) -> str:
        try:
            print("ğŸ” Iniciando anÃ¡lise com dados REAIS...")
            
            # Carregar e preparar dados REAIS
            df = pd.read_csv(data_csv, sep=';', encoding='utf-8')
            df = self._prepare_customer_data(df, customer_id_column)
            
            if df is None or len(df) < 20:
                return "Erro: Dados insuficientes para anÃ¡lise de clientes (mÃ­nimo 20 registros)"
            
            print(f"âœ… Dados preparados: {len(df)} clientes Ãºnicos")
            
            # DicionÃ¡rio de anÃ¡lises
            customer_analyses = {
                'behavioral_segmentation': self._behavioral_segmentation,
                'lifecycle_analysis': self._lifecycle_analysis,
                'churn_prediction': self._churn_prediction,
                'value_analysis': self._value_analysis,
                'preference_mining': self._preference_mining,
                'journey_mapping': self._journey_mapping
            }
            
            if analysis_type not in customer_analyses:
                return f"AnÃ¡lise '{analysis_type}' nÃ£o suportada. OpÃ§Ãµes: {list(customer_analyses.keys())}"
            
            result = customer_analyses[analysis_type](df, segmentation_method, prediction_horizon)
            return self._format_customer_result(analysis_type, result)
            
        except Exception as e:
            return f"Erro na anÃ¡lise de clientes: {str(e)}"
    
    def _prepare_customer_data(self, df: pd.DataFrame, customer_id_column: str) -> Optional[pd.DataFrame]:
        """Preparar dados de clientes REAIS usando todos os campos da query SQL."""
        try:
            print("ğŸ—ï¸ Preparando dados de clientes REAIS...")
            
            # Converter data
            df['Data'] = pd.to_datetime(df['Data'], errors='coerce')
            df = df.dropna(subset=['Data'])
            
            # USAR DADOS REAIS - NUNCA SIMULAR
            if customer_id_column not in df.columns or df[customer_id_column].isna().all():
                return self._handle_missing_customer_data(df)
            
            # Limpar dados de cliente
            df = df[df[customer_id_column].notna()]
            df = df[df[customer_id_column] != '']
            df[customer_id_column] = df[customer_id_column].astype(str).str.strip()
            
            print(f"âœ… Usando {customer_id_column} real: {df[customer_id_column].nunique()} clientes Ãºnicos")
            
            # Validar campos disponÃ­veis
            available_fields = self._validate_available_fields(df)
            print(f"ğŸ“Š Campos disponÃ­veis: {available_fields}")
            
            # Preparar features de cliente REAIS
            df = self._calculate_real_derived_fields(df)
            
            # Agregar dados por cliente usando TODOS os campos disponÃ­veis
            customer_data = self._aggregate_customer_metrics(df, customer_id_column, available_fields)
            
            print(f"ğŸ¯ AnÃ¡lise final: {len(customer_data)} clientes com {len(customer_data.columns)} mÃ©tricas")
            
            return customer_data
            
        except Exception as e:
            print(f"âŒ Erro na preparaÃ§Ã£o de dados de clientes REAIS: {str(e)}")
            return None
    
    def _handle_missing_customer_data(self, df: pd.DataFrame) -> Optional[pd.DataFrame]:
        """Lidar com dados faltantes de cliente de forma transparente."""
        print("âš ï¸ ATENÃ‡ÃƒO: Codigo_Cliente nÃ£o disponÃ­vel nos dados")
        print("ğŸ” Verificando campos alternativos...")
        
        # Verificar se hÃ¡ Nome_Cliente
        if 'Nome_Cliente' in df.columns and not df['Nome_Cliente'].isna().all():
            print("âœ… Usando Nome_Cliente como identificador")
            df['Customer_ID_Alt'] = df['Nome_Cliente'].astype(str).str.strip()
            return self._prepare_customer_data(df, 'Customer_ID_Alt')
        
        # Se nÃ£o hÃ¡ dados de cliente, retornar erro explicativo
        print("âŒ Nenhum identificador de cliente disponÃ­vel")
        return None
    
    def _validate_available_fields(self, df: pd.DataFrame) -> Dict[str, List[str]]:
        """Validar quais campos da query SQL estÃ£o disponÃ­veis."""
        field_categories = {
            'demographics': ['Idade', 'Sexo', 'Estado_Civil', 'Data_Nascimento'],
            'geographic': ['Cidade', 'Estado'],
            'financial': ['Custo_Produto', 'Preco_Tabela', 'Desconto_Aplicado'],
            'product': ['Grupo_Produto', 'Subgrupo_Produto', 'Metal', 'Colecao'],
            'sales': ['Codigo_Vendedor', 'Nome_Vendedor'],
            'inventory': ['Estoque_Atual'],
            'basic': ['Total_Liquido', 'Quantidade', 'Data']
        }
        
        available = {}
        for category, fields in field_categories.items():
            available[category] = [field for field in fields if field in df.columns]
        
        return available
    
    def _calculate_real_derived_fields(self, df: pd.DataFrame) -> pd.DataFrame:
        """Calcular campos derivados usando dados reais."""
        print("âš™ï¸ Calculando campos derivados com dados REAIS...")
        
        # Campos financeiros reais
        if 'Custo_Produto' in df.columns and 'Total_Liquido' in df.columns:
            df['Margem_Real'] = df['Total_Liquido'] - df['Custo_Produto']
            df['Margem_Percentual'] = (df['Margem_Real'] / df['Total_Liquido'] * 100).replace([np.inf, -np.inf], 0)
            print("âœ… Margem real calculada")
        
        if 'Desconto_Aplicado' in df.columns and 'Preco_Tabela' in df.columns:
            df['Desconto_Percentual'] = (df['Desconto_Aplicado'] / df['Preco_Tabela'] * 100).replace([np.inf, -np.inf], 0)
            print("âœ… Desconto percentual calculado")
        
        # Campos demogrÃ¡ficos derivados
        if 'Idade' in df.columns:
            df['Faixa_Etaria'] = pd.cut(df['Idade'], 
                                       bins=[0, 25, 35, 45, 55, 100], 
                                       labels=['18-25', '26-35', '36-45', '46-55', '55+'])
            print("âœ… Faixa etÃ¡ria calculada")
        
        # Campos bÃ¡sicos
        df['Preco_Unitario'] = df['Total_Liquido'] / df['Quantidade'].replace(0, 1)
        df['Ano_Mes'] = df['Data'].dt.to_period('M').astype(str)
        df['Trimestre'] = df['Data'].dt.quarter
        df['Mes'] = df['Data'].dt.month
        
        return df
    
    def _simulate_customer_ids(self, df: pd.DataFrame) -> pd.DataFrame:
        """Simular IDs de clientes baseado em padrÃµes de compra."""
        # EstratÃ©gia: agrupar compras similares por valor, data e produtos
        df = df.copy()
        
        # Criar clusters baseados em valor e tempo
        df['Date_Numeric'] = df['Data'].astype('int64') // 10**9  # Convert to seconds
        
        # Normalizar para clustering
        features_for_clustering = ['Total_Liquido', 'Date_Numeric']
        if 'Quantidade' in df.columns:
            features_for_clustering.append('Quantidade')
        
        scaler = StandardScaler()
        scaled_features = scaler.fit_transform(df[features_for_clustering])
        
        # Usar DBSCAN para agrupar transaÃ§Ãµes similares
        dbscan = DBSCAN(eps=0.5, min_samples=1)
        clusters = dbscan.fit_predict(scaled_features)
        
        df['Customer_ID'] = f'CUST_' + pd.Series(clusters).astype(str)
        
        return df
    
    def _aggregate_customer_metrics(self, df: pd.DataFrame, customer_id_column: str, available_fields: Dict[str, List[str]]) -> pd.DataFrame:
        """Agregar mÃ©tricas por cliente usando TODOS os campos reais disponÃ­veis."""
        print("ğŸ“Š Agregando mÃ©tricas por cliente com dados REAIS...")
        
        current_date = df['Data'].max()
        
        # AgregaÃ§Ãµes bÃ¡sicas
        base_agg = {
            'Total_Liquido': ['sum', 'mean', 'count', 'std'],
            'Quantidade': 'sum',
            'Data': ['min', 'max'],
            'Preco_Unitario': ['mean', 'std']
        }
        
        # Adicionar agregaÃ§Ãµes para campos financeiros reais
        if 'Margem_Real' in df.columns:
            base_agg['Margem_Real'] = ['sum', 'mean']
            base_agg['Margem_Percentual'] = ['mean', 'std']
        
        if 'Desconto_Percentual' in df.columns:
            base_agg['Desconto_Percentual'] = ['mean', 'std']
        
        # AgregaÃ§Ãµes demogrÃ¡ficas (primeiro valor, assumindo consistÃªncia)
        demographic_agg = {}
        for field in available_fields.get('demographics', []):
            if field in df.columns:
                demographic_agg[field] = 'first'
        
        # AgregaÃ§Ãµes geogrÃ¡ficas
        geographic_agg = {}
        for field in available_fields.get('geographic', []):
            if field in df.columns:
                geographic_agg[field] = 'first'
        
        # AgregaÃ§Ãµes de produto (moda para preferÃªncias)
        product_agg = {}
        for field in available_fields.get('product', []):
            if field in df.columns:
                product_agg[field] = lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'N/A'
        
        # Combinar todas as agregaÃ§Ãµes
        all_agg = {**base_agg, **demographic_agg, **geographic_agg, **product_agg}
        
        # Executar agregaÃ§Ã£o
        customer_metrics = df.groupby(customer_id_column).agg(all_agg).fillna(0)
        
        # Flatten columns
        customer_metrics.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col 
                                  for col in customer_metrics.columns]
        
        # Calcular mÃ©tricas RFM REAIS
        customer_metrics = self._calculate_real_rfm_metrics(customer_metrics, current_date)
        
        # Calcular mÃ©tricas de comportamento REAIS
        customer_metrics = self._calculate_real_behavioral_metrics(customer_metrics)
        
        print(f"âœ… {len(customer_metrics)} clientes com {len(customer_metrics.columns)} mÃ©tricas agregadas")
        
        return customer_metrics
    
    def _calculate_real_rfm_metrics(self, customer_metrics: pd.DataFrame, current_date: pd.Timestamp) -> pd.DataFrame:
        """Calcular mÃ©tricas RFM usando dados reais."""
        print("ğŸ¯ Calculando mÃ©tricas RFM REAIS...")
        
        # Recency (dias desde Ãºltima compra)
        customer_metrics['Recency'] = (current_date - pd.to_datetime(customer_metrics['Data_max'])).dt.days
        
        # Frequency (nÃºmero de transaÃ§Ãµes)
        customer_metrics['Frequency'] = customer_metrics['Total_Liquido_count']
        
        # Monetary (valor total)
        customer_metrics['Monetary'] = customer_metrics['Total_Liquido_sum']
        
        # MÃ©tricas de tempo
        customer_metrics['Customer_Lifetime_Days'] = (
            pd.to_datetime(customer_metrics['Data_max']) - 
            pd.to_datetime(customer_metrics['Data_min'])
        ).dt.days + 1
        
        customer_metrics['Avg_Days_Between_Purchases'] = (
            customer_metrics['Customer_Lifetime_Days'] / customer_metrics['Frequency']
        ).replace([np.inf], 0)
        
        # ConsistÃªncia de compra
        customer_metrics['Purchase_Consistency'] = 1 / (1 + customer_metrics['Total_Liquido_std'].fillna(0))
        
        return customer_metrics
    
    def _calculate_real_behavioral_metrics(self, customer_metrics: pd.DataFrame) -> pd.DataFrame:
        """Calcular mÃ©tricas comportamentais usando dados reais."""
        print("ğŸ§  Calculando mÃ©tricas comportamentais REAIS...")
        
        # Ticket mÃ©dio real
        customer_metrics['AOV_Real'] = customer_metrics['Total_Liquido_mean']
        
        # Valor vitalÃ­cio estimado (baseado em dados reais)
        customer_metrics['CLV_Estimado'] = (
            customer_metrics['AOV_Real'] * 
            customer_metrics['Frequency'] * 
            np.maximum(customer_metrics['Customer_Lifetime_Days'] / 365, 1)
        )
        
        # Margem do cliente (se disponÃ­vel)
        if 'Margem_Real_sum' in customer_metrics.columns:
            customer_metrics['Customer_Margin'] = customer_metrics['Margem_Real_sum']
            customer_metrics['Margin_Rate'] = customer_metrics['Margem_Real_mean']
        
        # Sensibilidade a desconto (se disponÃ­vel)
        if 'Desconto_Percentual_mean' in customer_metrics.columns:
            customer_metrics['Discount_Sensitivity'] = customer_metrics['Desconto_Percentual_mean']
        
        return customer_metrics
    
    def _behavioral_segmentation(self, customer_data: pd.DataFrame, method: str, 
                                horizon: int) -> Dict[str, Any]:
        """SegmentaÃ§Ã£o comportamental usando dados demogrÃ¡ficos REAIS."""
        print("ğŸ­ Executando segmentaÃ§Ã£o comportamental com dados REAIS...")
        
        result = {}
        
        # RFM tradicional com dados reais
        if method == 'rfm':
            result['rfm_analysis'] = self._rfm_segmentation(customer_data)
        elif method == 'behavioral':
            result['behavioral_analysis'] = self._advanced_behavioral_segmentation(customer_data)
        elif method == 'value_based':
            result['value_analysis'] = self._value_based_segmentation(customer_data)
        elif method == 'hybrid':
            result['hybrid_analysis'] = self._hybrid_segmentation(customer_data)
        else:
            result['rfm_analysis'] = self._rfm_segmentation(customer_data)
        
        # SegmentaÃ§Ã£o demogrÃ¡fica REAL
        demographic_cols = [col for col in customer_data.columns if any(demo in col for demo in ['Idade', 'Sexo', 'Estado_Civil', 'Faixa_Etaria'])]
        if demographic_cols:
            result['demographic_segmentation'] = self._real_demographic_segmentation(customer_data)
            print("âœ… SegmentaÃ§Ã£o demogrÃ¡fica adicionada")
        
        # SegmentaÃ§Ã£o geogrÃ¡fica REAL
        geographic_cols = [col for col in customer_data.columns if any(geo in col for geo in ['Cidade', 'Estado'])]
        if geographic_cols:
            result['geographic_segmentation'] = self._real_geographic_segmentation(customer_data)
            print("âœ… SegmentaÃ§Ã£o geogrÃ¡fica adicionada")
        
        # Clustering comportamental avanÃ§ado com features demogrÃ¡ficas
        behavioral_features = self._select_behavioral_features(customer_data)
        if len(behavioral_features) >= 3:
            result['advanced_clustering'] = self._real_advanced_clustering(customer_data, behavioral_features)
            print("âœ… Clustering avanÃ§ado com dados reais")
        
        return result
    
    def _real_demographic_segmentation(self, customer_data: pd.DataFrame) -> Dict[str, Any]:
        """SegmentaÃ§Ã£o demogrÃ¡fica com dados REAIS."""
        print("ğŸ‘¥ Executando segmentaÃ§Ã£o demogrÃ¡fica com dados REAIS...")
        
        demographic_analysis = {}
        
        # AnÃ¡lise por idade
        age_cols = [col for col in customer_data.columns if 'Faixa_Etaria' in col or 'Idade' in col]
        if age_cols:
            age_col = age_cols[0]  # Usar primeira coluna encontrada
            if not customer_data[age_col].isna().all():
                age_analysis = customer_data.groupby(age_col).agg({
                    'Monetary': ['mean', 'sum', 'count'],
                    'Frequency': 'mean',
                    'CLV_Estimado': 'mean' if 'CLV_Estimado' in customer_data.columns else 'count'
                }).round(2)
                
                demographic_analysis['age_segments'] = age_analysis.to_dict()
                print(f"âœ… AnÃ¡lise por idade usando {age_col}")
        
        # AnÃ¡lise por gÃªnero
        gender_cols = [col for col in customer_data.columns if 'Sexo' in col]
        if gender_cols:
            gender_col = gender_cols[0]
            if not customer_data[gender_col].isna().all():
                gender_analysis = customer_data.groupby(gender_col).agg({
                    'Monetary': ['mean', 'sum', 'count'],
                    'Frequency': 'mean',
                    'AOV_Real': 'mean' if 'AOV_Real' in customer_data.columns else 'count'
                }).round(2)
                
                demographic_analysis['gender_segments'] = gender_analysis.to_dict()
                print(f"âœ… AnÃ¡lise por gÃªnero usando {gender_col}")
        
        # AnÃ¡lise por estado civil
        marital_cols = [col for col in customer_data.columns if 'Estado_Civil' in col]
        if marital_cols:
            marital_col = marital_cols[0]
            if not customer_data[marital_col].isna().all():
                marital_analysis = customer_data.groupby(marital_col).agg({
                    'Monetary': ['mean', 'sum', 'count'],
                    'AOV_Real': 'mean' if 'AOV_Real' in customer_data.columns else 'count'
                }).round(2)
                
                demographic_analysis['marital_segments'] = marital_analysis.to_dict()
                print(f"âœ… AnÃ¡lise por estado civil usando {marital_col}")
        
        # Cross-analysis: Idade x GÃªnero (se ambos disponÃ­veis)
        if 'age_segments' in demographic_analysis and 'gender_segments' in demographic_analysis:
            try:
                age_col = age_cols[0]
                gender_col = gender_cols[0]
                cross_analysis = customer_data.groupby([age_col, gender_col])['Monetary'].mean().unstack()
                demographic_analysis['age_gender_cross'] = cross_analysis.to_dict()
                print("âœ… Cross-analysis idade x gÃªnero")
            except Exception as e:
                print(f"âš ï¸ Cross-analysis falhou: {e}")
        
        return demographic_analysis
    
    def _real_geographic_segmentation(self, customer_data: pd.DataFrame) -> Dict[str, Any]:
        """SegmentaÃ§Ã£o geogrÃ¡fica com dados REAIS."""
        print("ğŸ—ºï¸ Executando segmentaÃ§Ã£o geogrÃ¡fica com dados REAIS...")
        
        geographic_analysis = {}
        
        # AnÃ¡lise por estado
        state_cols = [col for col in customer_data.columns if 'Estado' in col]
        if state_cols:
            state_col = state_cols[0]
            if not customer_data[state_col].isna().all():
                state_analysis = customer_data.groupby(state_col).agg({
                    'Monetary': ['mean', 'sum', 'count'],
                    'Frequency': 'mean',
                    'CLV_Estimado': 'mean' if 'CLV_Estimado' in customer_data.columns else 'count'
                }).round(2)
                
                geographic_analysis['state_segments'] = state_analysis.to_dict()
                print(f"âœ… AnÃ¡lise por estado usando {state_col}")
        
        # AnÃ¡lise por cidade (top 20)
        city_cols = [col for col in customer_data.columns if 'Cidade' in col]
        if city_cols:
            city_col = city_cols[0]
            if not customer_data[city_col].isna().all():
                city_analysis = customer_data.groupby(city_col).agg({
                    'Monetary': ['mean', 'sum', 'count'],
                    'Frequency': 'mean'
                }).round(2)
                
                # Top 20 cidades por receita
                top_cities = city_analysis.nlargest(20, ('Monetary', 'sum'))
                geographic_analysis['top_cities'] = top_cities.to_dict()
                print(f"âœ… Top 20 cidades por receita usando {city_col}")
        
        return geographic_analysis
    
    def _select_behavioral_features(self, customer_data: pd.DataFrame) -> List[str]:
        """Selecionar features comportamentais disponÃ­veis para clustering."""
        potential_features = [
            'Recency', 'Frequency', 'Monetary', 'AOV_Real', 'CLV_Estimado',
            'Purchase_Consistency', 'Customer_Lifetime_Days', 'Avg_Days_Between_Purchases'
        ]
        
        # Adicionar features financeiras se disponÃ­veis
        financial_features = [col for col in customer_data.columns 
                            if any(word in col for word in ['Margem', 'Desconto', 'Margin', 'Discount'])]
        
        # Adicionar features demogrÃ¡ficas numÃ©ricas se disponÃ­veis
        demographic_features = [col for col in customer_data.columns 
                              if any(demo in col for demo in ['Idade_first', 'Idade'])]
        
        # Filtrar features que existem nos dados
        all_potential = potential_features + financial_features + demographic_features
        available_features = [f for f in all_potential if f in customer_data.columns]
        
        print(f"ğŸ“Š Features selecionadas para clustering: {available_features}")
        return available_features
    
    def _real_advanced_clustering(self, customer_data: pd.DataFrame, features: List[str]) -> Dict[str, Any]:
        """Clustering comportamental avanÃ§ado com dados reais."""
        print("ğŸ”¬ Executando clustering avanÃ§ado com dados REAIS...")
        
        # Preparar dados para clustering
        X = customer_data[features].fillna(0)
        
        # Padronizar
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # Encontrar nÃºmero Ã³timo de clusters
        optimal_k = self._find_optimal_clusters_silhouette(X_scaled, max_k=6)
        
        # K-means clustering
        kmeans = KMeans(n_clusters=optimal_k, random_state=42)
        clusters = kmeans.fit_predict(X_scaled)
        
        customer_data['Behavioral_Cluster'] = clusters
        
        # AnÃ¡lise dos clusters
        cluster_analysis = {}
        for cluster_id in range(optimal_k):
            cluster_data = customer_data[customer_data['Behavioral_Cluster'] == cluster_id]
            
            cluster_profile = {
                'size': len(cluster_data),
                'percentage': round(len(cluster_data) / len(customer_data) * 100, 1),
                'avg_monetary': round(cluster_data['Monetary'].mean(), 2),
                'avg_frequency': round(cluster_data['Frequency'].mean(), 1),
                'avg_recency': round(cluster_data['Recency'].mean(), 1)
            }
            
            # Adicionar insights demogrÃ¡ficos se disponÃ­veis
            age_cols = [col for col in cluster_data.columns if 'Faixa_Etaria' in col or 'Idade' in col]
            if age_cols and not cluster_data[age_cols[0]].isna().all():
                mode_age = cluster_data[age_cols[0]].mode()
                cluster_profile['dominant_age_group'] = mode_age.iloc[0] if len(mode_age) > 0 else 'N/A'
            
            gender_cols = [col for col in cluster_data.columns if 'Sexo' in col]
            if gender_cols and not cluster_data[gender_cols[0]].isna().all():
                mode_gender = cluster_data[gender_cols[0]].mode()
                cluster_profile['dominant_gender'] = mode_gender.iloc[0] if len(mode_gender) > 0 else 'N/A'
            
            cluster_analysis[f'Cluster_{cluster_id}'] = cluster_profile
        
        return {
            'optimal_clusters': optimal_k,
            'cluster_analysis': cluster_analysis,
            'features_used': features,
            'silhouette_score': round(silhouette_score(X_scaled, clusters), 3)
        }
    
    def _rfm_segmentation(self, customer_data: pd.DataFrame) -> Dict[str, Any]:
        """SegmentaÃ§Ã£o RFM tradicional."""
        try:
            # Calcular scores RFM
            customer_data['R_Score'] = pd.qcut(customer_data['Recency'], 5, labels=[5,4,3,2,1], duplicates='drop')
            customer_data['F_Score'] = pd.qcut(customer_data['Frequency'].rank(method='first'), 5, labels=[1,2,3,4,5], duplicates='drop')
            customer_data['M_Score'] = pd.qcut(customer_data['Monetary'].rank(method='first'), 5, labels=[1,2,3,4,5], duplicates='drop')
            
            # Converter para int
            customer_data['R_Score'] = customer_data['R_Score'].astype(int)
            customer_data['F_Score'] = customer_data['F_Score'].astype(int)
            customer_data['M_Score'] = customer_data['M_Score'].astype(int)
            
            # Classificar segmentos
            customer_data['RFM_Segment'] = customer_data.apply(self._classify_rfm_segment, axis=1)
            
            # AnÃ¡lise dos segmentos
            segment_analysis = customer_data.groupby('RFM_Segment').agg({
                'Recency': ['count', 'mean'],
                'Frequency': 'mean',
                'Monetary': ['mean', 'sum'],
                'Customer_Lifetime_Days': 'mean'
            }).round(2)
            
            segment_analysis.columns = ['Count', 'Avg_Recency', 'Avg_Frequency', 'Avg_Monetary', 'Total_Monetary', 'Avg_Lifetime']
            
            # Insights por segmento
            segment_insights = {}
            for segment in customer_data['RFM_Segment'].unique():
                segment_data = customer_data[customer_data['RFM_Segment'] == segment]
                
                insights = []
                avg_monetary = segment_data['Monetary'].mean()
                avg_frequency = segment_data['Frequency'].mean()
                avg_recency = segment_data['Recency'].mean()
                
                if avg_monetary > customer_data['Monetary'].mean() * 1.5:
                    insights.append("Alto valor monetÃ¡rio")
                if avg_frequency > customer_data['Frequency'].mean() * 1.5:
                    insights.append("Alta frequÃªncia de compra")
                if avg_recency < 30:
                    insights.append("Compra recente")
                elif avg_recency > 180:
                    insights.append("Cliente inativo")
                
                segment_insights[segment] = insights
            
            # Matriz de migraÃ§Ã£o (simulada)
            migration_matrix = self._simulate_segment_migration(customer_data)
            
            return {
                'segmentation_method': 'RFM',
                'segment_distribution': customer_data['RFM_Segment'].value_counts().to_dict(),
                'segment_analysis': segment_analysis.to_dict(),
                'segment_insights': segment_insights,
                'migration_matrix': migration_matrix,
                'total_customers': len(customer_data)
            }
            
        except Exception as e:
            return {'error': f"Erro na segmentaÃ§Ã£o RFM: {str(e)}"}
    
    def _advanced_behavioral_segmentation(self, customer_data: pd.DataFrame) -> Dict[str, Any]:
        """Wrapper para segmentaÃ§Ã£o comportamental avanÃ§ada."""
        behavioral_features = self._select_behavioral_features(customer_data)
        if len(behavioral_features) >= 3:
            return self._real_advanced_clustering(customer_data, behavioral_features)
        else:
            return {'error': 'Features insuficientes para segmentaÃ§Ã£o comportamental'}
    
    def _value_based_segmentation(self, customer_data: pd.DataFrame) -> Dict[str, Any]:
        """Wrapper para segmentaÃ§Ã£o baseada em valor."""
        return self._value_analysis(customer_data, 'value_based', 90)
    
    def _hybrid_segmentation(self, customer_data: pd.DataFrame) -> Dict[str, Any]:
        """SegmentaÃ§Ã£o hÃ­brida combinando mÃºltiplos critÃ©rios."""
        rfm_result = self._rfm_segmentation(customer_data)
        
        # Incluir anÃ¡lises demogrÃ¡ficas se disponÃ­veis
        demographic_cols = [col for col in customer_data.columns if any(demo in col for demo in ['Idade', 'Sexo', 'Estado_Civil'])]
        if demographic_cols:
            demographic_result = self._real_demographic_segmentation(customer_data)
        else:
            demographic_result = {'info': 'Dados demogrÃ¡ficos nÃ£o disponÃ­veis'}
        
        return {
            'segmentation_method': 'Hybrid (RFM + Demographic + Geographic)',
            'rfm_component': rfm_result,
            'demographic_component': demographic_result,
            'total_customers': len(customer_data)
        }
    
    # MÃ©todos auxiliares necessÃ¡rios
    def _classify_rfm_segment(self, row) -> str:
        """Classificar segmento RFM."""
        r, f, m = row['R_Score'], row['F_Score'], row['M_Score']
        
        if r >= 4 and f >= 4 and m >= 4:
            return 'Champions'
        elif r >= 3 and f >= 3 and m >= 3:
            return 'Loyal Customers'
        elif r >= 4 and f <= 2:
            return 'New Customers'
        elif r >= 3 and f <= 2:
            return 'Potential Loyalists'
        elif r <= 2 and f >= 3:
            return 'At Risk'
        elif r <= 2 and f <= 2 and m >= 3:
            return 'Cannot Lose Them'
        elif r <= 2 and f <= 2 and m <= 2:
            return 'Lost'
        else:
            return 'Others'
    
    def _find_optimal_clusters_silhouette(self, X: np.ndarray, max_k: int = 8) -> int:
        """Encontrar nÃºmero Ã³timo de clusters usando silhouette score."""
        if len(X) < 4:
            return 2
        
        max_k = min(max_k, len(X) - 1)
        silhouette_scores = []
        
        for k in range(2, max_k + 1):
            try:
                kmeans = KMeans(n_clusters=k, random_state=42)
                cluster_labels = kmeans.fit_predict(X)
                silhouette_avg = silhouette_score(X, cluster_labels)
                silhouette_scores.append(silhouette_avg)
            except:
                continue
        
        if silhouette_scores:
            optimal_k = silhouette_scores.index(max(silhouette_scores)) + 2
            return optimal_k
        else:
            return 3
    
    def _analyze_lifecycle_transitions(self, customer_data: pd.DataFrame) -> Dict[str, Any]:
        """Analisar transiÃ§Ãµes do ciclo de vida."""
        # Estimativa baseada em padrÃµes
        transitions = {
            'New_to_Growing': 0.65,
            'Growing_to_Loyal': 0.35,
            'Loyal_to_VIP': 0.25,
            'At_Risk_to_Lost': 0.40
        }
        
        return transitions
    
    def _identify_churn_risk_factors(self, customer_data: pd.DataFrame) -> List[str]:
        """Identificar fatores de risco de churn."""
        factors = []
        
        # AnÃ¡lise de recÃªncia
        high_recency = customer_data[customer_data['Recency'] > 180]
        if len(high_recency) > 0:
            factors.append(f"{len(high_recency)} clientes sem compra hÃ¡ 6+ meses")
        
        # Baixa frequÃªncia
        low_frequency = customer_data[customer_data['Frequency'] == 1]
        if len(low_frequency) > 0:
            factors.append(f"{len(low_frequency)} clientes com apenas 1 compra")
        
        # Queda na consistÃªncia
        if 'Purchase_Consistency' in customer_data.columns:
            inconsistent = customer_data[customer_data['Purchase_Consistency'] < 0.3]
            if len(inconsistent) > 0:
                factors.append(f"{len(inconsistent)} clientes com padrÃ£o irregular")
        
        return factors
    
    def _generate_retention_strategies(self, customer_data: pd.DataFrame) -> Dict[str, List[str]]:
        """Gerar estratÃ©gias de retenÃ§Ã£o por segmento."""
        strategies = {}
        
        for risk_category in customer_data['Churn_Risk_Category'].unique():
            if pd.isna(risk_category):
                continue
                
            if risk_category == 'High Risk':
                strategies[risk_category] = [
                    "Contato pessoal imediato",
                    "Oferta especial personalizada",
                    "Programa VIP exclusivo",
                    "Desconto significativo na prÃ³xima compra"
                ]
            elif risk_category == 'Medium Risk':
                strategies[risk_category] = [
                    "Email marketing personalizado",
                    "Lembrete de produtos favoritos",
                    "Programa de fidelidade",
                    "Cross-sell baseado em histÃ³rico"
                ]
            else:  # Low Risk
                strategies[risk_category] = [
                    "Newsletter regular",
                    "Novidades e lanÃ§amentos",
                    "Programa de indicaÃ§Ã£o",
                    "ManutenÃ§Ã£o do relacionamento"
                ]
        
        return strategies
    
    def _calculate_churn_financial_impact(self, customer_data: pd.DataFrame) -> Dict[str, float]:
        """Calcular impacto financeiro do churn."""
        high_risk = customer_data[customer_data['Churn_Risk_Category'] == 'High Risk']
        
        potential_lost_revenue = high_risk['Monetary'].sum()
        potential_lost_clv = high_risk['CLV_Estimado'].sum() if 'CLV_Estimado' in customer_data.columns else potential_lost_revenue * 1.5
        
        return {
            'high_risk_current_value': round(potential_lost_revenue, 2),
            'potential_lost_clv': round(potential_lost_clv, 2),
            'retention_investment_suggested': round(potential_lost_clv * 0.1, 2)  # 10% do CLV
        }
    
    def _analyze_value_concentration(self, customer_data: pd.DataFrame) -> Dict[str, float]:
        """Analisar concentraÃ§Ã£o de valor."""
        # Regra 80/20
        clv_column = 'CLV_Estimado' if 'CLV_Estimado' in customer_data.columns else 'Monetary'
        
        sorted_customers = customer_data.sort_values(clv_column, ascending=False)
        top_20_pct = int(len(sorted_customers) * 0.2)
        
        top_20_value = sorted_customers.head(top_20_pct)[clv_column].sum()
        total_value = sorted_customers[clv_column].sum()
        
        concentration_80_20 = (top_20_value / total_value * 100) if total_value > 0 else 0
        
        return {
            'top_20_percent_value_share': round(concentration_80_20, 1),
            'value_distribution': 'Concentrated' if concentration_80_20 > 80 else 'Balanced'
        }
    
    def _analyze_stage_transitions(self, customer_data: pd.DataFrame) -> Dict[str, float]:
        """Analisar transiÃ§Ãµes entre estÃ¡gios da jornada."""
        # Estimativas baseadas em padrÃµes tÃ­picos
        transitions = {
            'new_to_growing': 0.45,
            'growing_to_loyal': 0.35,
            'loyal_to_vip': 0.20
        }
        
        return transitions
    
    def _identify_friction_points(self, customer_data: pd.DataFrame) -> List[str]:
        """Identificar pontos de atrito na jornada."""
        friction_points = []
        
        # Alta taxa de clientes one-time
        one_time = len(customer_data[customer_data['Frequency'] == 1])
        one_time_rate = one_time / len(customer_data) * 100
        
        if one_time_rate > 60:
            friction_points.append(f"Alta taxa de one-time buyers ({one_time_rate:.1f}%)")
        
        # Longo intervalo entre compras
        avg_interval = customer_data['Avg_Days_Between_Purchases'].mean()
        if avg_interval > 180:
            friction_points.append(f"Intervalo longo entre compras ({avg_interval:.0f} dias)")
        
        # Baixa conversÃ£o para alto valor
        high_value = len(customer_data[customer_data['Monetary'] > customer_data['Monetary'].quantile(0.8)])
        high_value_rate = high_value / len(customer_data) * 100
        
        if high_value_rate < 15:
            friction_points.append(f"Baixa conversÃ£o para alto valor ({high_value_rate:.1f}%)")
        
        return friction_points

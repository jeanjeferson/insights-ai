from crewai.tools import BaseTool
from typing import Type, Optional, Dict, Any, List, Tuple
from pydantic import BaseModel, Field
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans, DBSCAN
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import IsolationForest
from sklearn.metrics import silhouette_score
from scipy import stats
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

class CustomerInsightsInput(BaseModel):
    """Schema de entrada para an√°lise de insights de clientes."""
    analysis_type: str = Field(..., description="Tipo: 'behavioral_segmentation', 'lifecycle_analysis', 'churn_prediction', 'value_analysis', 'preference_mining', 'journey_mapping'")
    data_csv: str = Field(default="data/vendas.csv", description="Caminho para arquivo CSV")
    customer_id_column: str = Field(default="Codigo_Cliente", description="Coluna de identifica√ß√£o de cliente")
    segmentation_method: str = Field(default="rfm", description="M√©todo: 'rfm', 'behavioral', 'value_based', 'hybrid'")
    prediction_horizon: int = Field(default=90, description="Horizonte de predi√ß√£o em dias")

class CustomerInsightsEngine(BaseTool):
    name: str = "Customer Insights Engine"
    description: str = """
    ‚ú® VERS√ÉO CORRIGIDA - Motor avan√ßado de insights de clientes para joalherias:
    
    üîß PRINCIPAIS CORRE√á√ïES:
    - ‚úÖ USA DADOS REAIS: Codigo_Cliente, Nome_Cliente da query SQL
    - ‚úÖ DADOS DEMOGR√ÅFICOS REAIS: Idade, Sexo, Estado_Civil, Cidade, Estado
    - ‚úÖ DADOS FINANCEIROS REAIS: Margem real, descontos aplicados
    - ‚úÖ ELIMINA SIMULA√á√ÉO: An√°lises 100% baseadas em dados verdadeiros
    
    üéØ AN√ÅLISES DISPON√çVEIS:
    - behavioral_segmentation: Segmenta√ß√£o comportamental com dados demogr√°ficos
    - lifecycle_analysis: An√°lise do ciclo de vida com dados hist√≥ricos reais
    - churn_prediction: Predi√ß√£o de abandono baseada em padr√µes reais
    - value_analysis: An√°lise de valor com margem e CLV real
    - preference_mining: Prefer√™ncias por idade, sexo, localiza√ß√£o
    - journey_mapping: Jornada real do cliente por perfil demogr√°fico
    
    üß¨ ALGORITMOS APRIMORADOS:
    - Clustering com features demogr√°ficas reais
    - RFM com dados de cliente verdadeiros
    - An√°lise geogr√°fica por cidade/estado
    - Segmenta√ß√£o por perfil demogr√°fico
    """
    args_schema: Type[BaseModel] = CustomerInsightsInput
    
    def _run(self, analysis_type: str, data_csv: str = "data/vendas.csv", 
             customer_id_column: str = "Codigo_Cliente", segmentation_method: str = "rfm",
             prediction_horizon: int = 90) -> str:
        try:
            print("üîç Iniciando an√°lise com dados REAIS...")
            
            # Carregar e preparar dados REAIS
            df = pd.read_csv(data_csv, sep=';', encoding='utf-8')
            df = self._prepare_customer_data(df, customer_id_column)
            
            if df is None or len(df) < 20:
                return "Erro: Dados insuficientes para an√°lise de clientes (m√≠nimo 20 registros)"
            
            print(f"‚úÖ Dados preparados: {len(df)} clientes √∫nicos")
            
            # Dicion√°rio de an√°lises
            customer_analyses = {
                'behavioral_segmentation': self._behavioral_segmentation,
                'lifecycle_analysis': self._lifecycle_analysis,
                'churn_prediction': self._churn_prediction,
                'value_analysis': self._value_analysis,
                'preference_mining': self._preference_mining,
                'journey_mapping': self._journey_mapping
            }
            
            if analysis_type not in customer_analyses:
                return f"An√°lise '{analysis_type}' n√£o suportada. Op√ß√µes: {list(customer_analyses.keys())}"
            
            result = customer_analyses[analysis_type](df, segmentation_method, prediction_horizon)
            return self._format_customer_result(analysis_type, result)
            
        except Exception as e:
            return f"Erro na an√°lise de clientes: {str(e)}"
    
    def _prepare_customer_data(self, df: pd.DataFrame, customer_id_column: str) -> Optional[pd.DataFrame]:
        """Preparar dados de clientes REAIS usando todos os campos da query SQL."""
        try:
            print("üèóÔ∏è Preparando dados de clientes REAIS...")
            
            # Converter data
            df['Data'] = pd.to_datetime(df['Data'], errors='coerce')
            df = df.dropna(subset=['Data'])
            
            # USAR DADOS REAIS - NUNCA SIMULAR
            if customer_id_column not in df.columns or df[customer_id_column].isna().all():
                return self._handle_missing_customer_data(df)
            
            # Limpar dados de cliente
            df = df[df[customer_id_column].notna()]
            df = df[df[customer_id_column] != '']
            df[customer_id_column] = df[customer_id_column].astype(str).str.strip()
            
            print(f"‚úÖ Usando {customer_id_column} real: {df[customer_id_column].nunique()} clientes √∫nicos")
            
            # Validar campos dispon√≠veis
            available_fields = self._validate_available_fields(df)
            print(f"üìä Campos dispon√≠veis: {available_fields}")
            
            # Preparar features de cliente REAIS
            df = self._calculate_real_derived_fields(df)
            
            # Agregar dados por cliente usando TODOS os campos dispon√≠veis
            customer_data = self._aggregate_customer_metrics(df, customer_id_column, available_fields)
            
            print(f"üéØ An√°lise final: {len(customer_data)} clientes com {len(customer_data.columns)} m√©tricas")
            
            return customer_data
            
        except Exception as e:
            print(f"‚ùå Erro na prepara√ß√£o de dados de clientes REAIS: {str(e)}")
            return None
    
    def _handle_missing_customer_data(self, df: pd.DataFrame) -> Optional[pd.DataFrame]:
        """Lidar com dados faltantes de cliente de forma transparente."""
        print("‚ö†Ô∏è ATEN√á√ÉO: Codigo_Cliente n√£o dispon√≠vel nos dados")
        print("üîç Verificando campos alternativos...")
        
        # Verificar se h√° Nome_Cliente
        if 'Nome_Cliente' in df.columns and not df['Nome_Cliente'].isna().all():
            print("‚úÖ Usando Nome_Cliente como identificador")
            df['Customer_ID_Alt'] = df['Nome_Cliente'].astype(str).str.strip()
            return self._prepare_customer_data(df, 'Customer_ID_Alt')
        
        # Se n√£o h√° dados de cliente, retornar erro explicativo
        print("‚ùå Nenhum identificador de cliente dispon√≠vel")
        return None
    
    def _validate_available_fields(self, df: pd.DataFrame) -> Dict[str, List[str]]:
        """Validar quais campos da query SQL est√£o dispon√≠veis."""
        field_categories = {
            'demographics': ['Idade', 'Sexo', 'Estado_Civil', 'Data_Nascimento'],
            'geographic': ['Cidade', 'Estado'],
            'financial': ['Custo_Produto', 'Preco_Tabela', 'Desconto_Aplicado'],
            'product': ['Grupo_Produto', 'Subgrupo_Produto', 'Metal', 'Colecao'],
            'sales': ['Codigo_Vendedor', 'Nome_Vendedor'],
            'inventory': ['Estoque_Atual'],
            'basic': ['Total_Liquido', 'Quantidade', 'Data']
        }
        
        available = {}
        for category, fields in field_categories.items():
            available[category] = [field for field in fields if field in df.columns]
        
        return available
    
    def _calculate_real_derived_fields(self, df: pd.DataFrame) -> pd.DataFrame:
        """Calcular campos derivados usando dados reais."""
        print("‚öôÔ∏è Calculando campos derivados com dados REAIS...")
        
        # Campos financeiros reais
        if 'Custo_Produto' in df.columns and 'Total_Liquido' in df.columns:
            df['Margem_Real'] = df['Total_Liquido'] - df['Custo_Produto']
            df['Margem_Percentual'] = (df['Margem_Real'] / df['Total_Liquido'] * 100).replace([np.inf, -np.inf], 0)
            print("‚úÖ Margem real calculada")
        
        if 'Desconto_Aplicado' in df.columns and 'Preco_Tabela' in df.columns:
            df['Desconto_Percentual'] = (df['Desconto_Aplicado'] / df['Preco_Tabela'] * 100).replace([np.inf, -np.inf], 0)
            print("‚úÖ Desconto percentual calculado")
        
        # Campos demogr√°ficos derivados
        if 'Idade' in df.columns:
            df['Faixa_Etaria'] = pd.cut(df['Idade'], 
                                       bins=[0, 25, 35, 45, 55, 100], 
                                       labels=['18-25', '26-35', '36-45', '46-55', '55+'])
            print("‚úÖ Faixa et√°ria calculada")
        
        # Campos b√°sicos
        df['Preco_Unitario'] = df['Total_Liquido'] / df['Quantidade'].replace(0, 1)
        df['Ano_Mes'] = df['Data'].dt.to_period('M').astype(str)
        df['Trimestre'] = df['Data'].dt.quarter
        df['Mes'] = df['Data'].dt.month
        
        return df
    
    def _simulate_customer_ids(self, df: pd.DataFrame) -> pd.DataFrame:
        """Simular IDs de clientes baseado em padr√µes de compra."""
        # Estrat√©gia: agrupar compras similares por valor, data e produtos
        df = df.copy()
        
        # Criar clusters baseados em valor e tempo
        df['Date_Numeric'] = df['Data'].astype('int64') // 10**9  # Convert to seconds
        
        # Normalizar para clustering
        features_for_clustering = ['Total_Liquido', 'Date_Numeric']
        if 'Quantidade' in df.columns:
            features_for_clustering.append('Quantidade')
        
        scaler = StandardScaler()
        scaled_features = scaler.fit_transform(df[features_for_clustering])
        
        # Usar DBSCAN para agrupar transa√ß√µes similares
        dbscan = DBSCAN(eps=0.5, min_samples=1)
        clusters = dbscan.fit_predict(scaled_features)
        
        df['Customer_ID'] = f'CUST_' + pd.Series(clusters).astype(str)
        
        return df
    
    def _aggregate_customer_metrics(self, df: pd.DataFrame, customer_id_column: str, available_fields: Dict[str, List[str]]) -> pd.DataFrame:
        """Agregar m√©tricas por cliente usando TODOS os campos reais dispon√≠veis."""
        print("üìä Agregando m√©tricas por cliente com dados REAIS...")
        
        current_date = df['Data'].max()
        
        # Agrega√ß√µes b√°sicas
        base_agg = {
            'Total_Liquido': ['sum', 'mean', 'count', 'std'],
            'Quantidade': 'sum',
            'Data': ['min', 'max'],
            'Preco_Unitario': ['mean', 'std']
        }
        
        # Adicionar agrega√ß√µes para campos financeiros reais
        if 'Margem_Real' in df.columns:
            base_agg['Margem_Real'] = ['sum', 'mean']
            base_agg['Margem_Percentual'] = ['mean', 'std']
        
        if 'Desconto_Percentual' in df.columns:
            base_agg['Desconto_Percentual'] = ['mean', 'std']
        
        # Agrega√ß√µes demogr√°ficas (primeiro valor, assumindo consist√™ncia)
        demographic_agg = {}
        for field in available_fields.get('demographics', []):
            if field in df.columns:
                demographic_agg[field] = 'first'
        
        # Agrega√ß√µes geogr√°ficas
        geographic_agg = {}
        for field in available_fields.get('geographic', []):
            if field in df.columns:
                geographic_agg[field] = 'first'
        
        # Agrega√ß√µes de produto (moda para prefer√™ncias)
        product_agg = {}
        for field in available_fields.get('product', []):
            if field in df.columns:
                product_agg[field] = lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'N/A'
        
        # Combinar todas as agrega√ß√µes
        all_agg = {**base_agg, **demographic_agg, **geographic_agg, **product_agg}
        
        # Executar agrega√ß√£o
        customer_metrics = df.groupby(customer_id_column).agg(all_agg).fillna(0)
        
        # Flatten columns
        customer_metrics.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col 
                                  for col in customer_metrics.columns]
        
        # Calcular m√©tricas RFM REAIS
        customer_metrics = self._calculate_real_rfm_metrics(customer_metrics, current_date)
        
        # Calcular m√©tricas de comportamento REAIS
        customer_metrics = self._calculate_real_behavioral_metrics(customer_metrics)
        
        print(f"‚úÖ {len(customer_metrics)} clientes com {len(customer_metrics.columns)} m√©tricas agregadas")
        
        return customer_metrics
    
    def _calculate_real_rfm_metrics(self, customer_metrics: pd.DataFrame, current_date: pd.Timestamp) -> pd.DataFrame:
        """Calcular m√©tricas RFM usando dados reais."""
        print("üéØ Calculando m√©tricas RFM REAIS...")
        
        # Recency (dias desde √∫ltima compra)
        customer_metrics['Recency'] = (current_date - pd.to_datetime(customer_metrics['Data_max'])).dt.days
        
        # Frequency (n√∫mero de transa√ß√µes)
        customer_metrics['Frequency'] = customer_metrics['Total_Liquido_count']
        
        # Monetary (valor total)
        customer_metrics['Monetary'] = customer_metrics['Total_Liquido_sum']
        
        # M√©tricas de tempo
        customer_metrics['Customer_Lifetime_Days'] = (
            pd.to_datetime(customer_metrics['Data_max']) - 
            pd.to_datetime(customer_metrics['Data_min'])
        ).dt.days + 1
        
        customer_metrics['Avg_Days_Between_Purchases'] = (
            customer_metrics['Customer_Lifetime_Days'] / customer_metrics['Frequency']
        ).replace([np.inf], 0)
        
        # Consist√™ncia de compra
        customer_metrics['Purchase_Consistency'] = 1 / (1 + customer_metrics['Total_Liquido_std'].fillna(0))
        
        return customer_metrics
    
    def _calculate_real_behavioral_metrics(self, customer_metrics: pd.DataFrame) -> pd.DataFrame:
        """Calcular m√©tricas comportamentais usando dados reais."""
        print("üß† Calculando m√©tricas comportamentais REAIS...")
        
        # Ticket m√©dio real
        customer_metrics['AOV_Real'] = customer_metrics['Total_Liquido_mean']
        
        # Valor vital√≠cio estimado (baseado em dados reais)
        customer_metrics['CLV_Estimado'] = (
            customer_metrics['AOV_Real'] * 
            customer_metrics['Frequency'] * 
            np.maximum(customer_metrics['Customer_Lifetime_Days'] / 365, 1)
        )
        
        # Margem do cliente (se dispon√≠vel)
        if 'Margem_Real_sum' in customer_metrics.columns:
            customer_metrics['Customer_Margin'] = customer_metrics['Margem_Real_sum']
            customer_metrics['Margin_Rate'] = customer_metrics['Margem_Real_mean']
        
        # Sensibilidade a desconto (se dispon√≠vel)
        if 'Desconto_Percentual_mean' in customer_metrics.columns:
            customer_metrics['Discount_Sensitivity'] = customer_metrics['Desconto_Percentual_mean']
        
        return customer_metrics
    
    def _behavioral_segmentation(self, customer_data: pd.DataFrame, method: str, 
                                horizon: int) -> Dict[str, Any]:
        """Segmenta√ß√£o comportamental usando dados demogr√°ficos REAIS."""
        print("üé≠ Executando segmenta√ß√£o comportamental com dados REAIS...")
        
        result = {}
        
        # RFM tradicional com dados reais
        if method == 'rfm':
            result['rfm_analysis'] = self._rfm_segmentation(customer_data)
        elif method == 'behavioral':
            result['behavioral_analysis'] = self._advanced_behavioral_segmentation(customer_data)
        elif method == 'value_based':
            result['value_analysis'] = self._value_based_segmentation(customer_data)
        elif method == 'hybrid':
            result['hybrid_analysis'] = self._hybrid_segmentation(customer_data)
        else:
            result['rfm_analysis'] = self._rfm_segmentation(customer_data)
        
        # Segmenta√ß√£o demogr√°fica REAL
        demographic_cols = [col for col in customer_data.columns if any(demo in col for demo in ['Idade', 'Sexo', 'Estado_Civil', 'Faixa_Etaria'])]
        if demographic_cols:
            result['demographic_segmentation'] = self._real_demographic_segmentation(customer_data)
            print("‚úÖ Segmenta√ß√£o demogr√°fica adicionada")
        
        # Segmenta√ß√£o geogr√°fica REAL
        geographic_cols = [col for col in customer_data.columns if any(geo in col for geo in ['Cidade', 'Estado'])]
        if geographic_cols:
            result['geographic_segmentation'] = self._real_geographic_segmentation(customer_data)
            print("‚úÖ Segmenta√ß√£o geogr√°fica adicionada")
        
        # Clustering comportamental avan√ßado com features demogr√°ficas
        behavioral_features = self._select_behavioral_features(customer_data)
        if len(behavioral_features) >= 3:
            result['advanced_clustering'] = self._real_advanced_clustering(customer_data, behavioral_features)
            print("‚úÖ Clustering avan√ßado com dados reais")
        
        return result
    
    def _real_demographic_segmentation(self, customer_data: pd.DataFrame) -> Dict[str, Any]:
        """Segmenta√ß√£o demogr√°fica com dados REAIS."""
        print("üë• Executando segmenta√ß√£o demogr√°fica com dados REAIS...")
        
        demographic_analysis = {}
        
        # An√°lise por idade
        age_cols = [col for col in customer_data.columns if 'Faixa_Etaria' in col or 'Idade' in col]
        if age_cols:
            age_col = age_cols[0]  # Usar primeira coluna encontrada
            if not customer_data[age_col].isna().all():
                age_analysis = customer_data.groupby(age_col).agg({
                    'Monetary': ['mean', 'sum', 'count'],
                    'Frequency': 'mean',
                    'CLV_Estimado': 'mean' if 'CLV_Estimado' in customer_data.columns else 'count'
                }).round(2)
                
                demographic_analysis['age_segments'] = age_analysis.to_dict()
                print(f"‚úÖ An√°lise por idade usando {age_col}")
        
        # An√°lise por g√™nero
        gender_cols = [col for col in customer_data.columns if 'Sexo' in col]
        if gender_cols:
            gender_col = gender_cols[0]
            if not customer_data[gender_col].isna().all():
                gender_analysis = customer_data.groupby(gender_col).agg({
                    'Monetary': ['mean', 'sum', 'count'],
                    'Frequency': 'mean',
                    'AOV_Real': 'mean' if 'AOV_Real' in customer_data.columns else 'count'
                }).round(2)
                
                demographic_analysis['gender_segments'] = gender_analysis.to_dict()
                print(f"‚úÖ An√°lise por g√™nero usando {gender_col}")
        
        # An√°lise por estado civil
        marital_cols = [col for col in customer_data.columns if 'Estado_Civil' in col]
        if marital_cols:
            marital_col = marital_cols[0]
            if not customer_data[marital_col].isna().all():
                marital_analysis = customer_data.groupby(marital_col).agg({
                    'Monetary': ['mean', 'sum', 'count'],
                    'AOV_Real': 'mean' if 'AOV_Real' in customer_data.columns else 'count'
                }).round(2)
                
                demographic_analysis['marital_segments'] = marital_analysis.to_dict()
                print(f"‚úÖ An√°lise por estado civil usando {marital_col}")
        
        # Cross-analysis: Idade x G√™nero (se ambos dispon√≠veis)
        if 'age_segments' in demographic_analysis and 'gender_segments' in demographic_analysis:
            try:
                age_col = age_cols[0]
                gender_col = gender_cols[0]
                cross_analysis = customer_data.groupby([age_col, gender_col])['Monetary'].mean().unstack()
                demographic_analysis['age_gender_cross'] = cross_analysis.to_dict()
                print("‚úÖ Cross-analysis idade x g√™nero")
            except Exception as e:
                print(f"‚ö†Ô∏è Cross-analysis falhou: {e}")
        
        return demographic_analysis
    
    def _real_geographic_segmentation(self, customer_data: pd.DataFrame) -> Dict[str, Any]:
        """Segmenta√ß√£o geogr√°fica com dados REAIS."""
        print("üó∫Ô∏è Executando segmenta√ß√£o geogr√°fica com dados REAIS...")
        
        geographic_analysis = {}
        
        # An√°lise por estado
        state_cols = [col for col in customer_data.columns if 'Estado' in col]
        if state_cols:
            state_col = state_cols[0]
            if not customer_data[state_col].isna().all():
                state_analysis = customer_data.groupby(state_col).agg({
                    'Monetary': ['mean', 'sum', 'count'],
                    'Frequency': 'mean',
                    'CLV_Estimado': 'mean' if 'CLV_Estimado' in customer_data.columns else 'count'
                }).round(2)
                
                geographic_analysis['state_segments'] = state_analysis.to_dict()
                print(f"‚úÖ An√°lise por estado usando {state_col}")
        
        # An√°lise por cidade (top 20)
        city_cols = [col for col in customer_data.columns if 'Cidade' in col]
        if city_cols:
            city_col = city_cols[0]
            if not customer_data[city_col].isna().all():
                city_analysis = customer_data.groupby(city_col).agg({
                    'Monetary': ['mean', 'sum', 'count'],
                    'Frequency': 'mean'
                }).round(2)
                
                # Top 20 cidades por receita
                top_cities = city_analysis.nlargest(20, ('Monetary', 'sum'))
                geographic_analysis['top_cities'] = top_cities.to_dict()
                print(f"‚úÖ Top 20 cidades por receita usando {city_col}")
        
        return geographic_analysis
    
    def _select_behavioral_features(self, customer_data: pd.DataFrame) -> List[str]:
        """Selecionar features comportamentais dispon√≠veis para clustering."""
        potential_features = [
            'Recency', 'Frequency', 'Monetary', 'AOV_Real', 'CLV_Estimado',
            'Purchase_Consistency', 'Customer_Lifetime_Days', 'Avg_Days_Between_Purchases'
        ]
        
        # Adicionar features financeiras se dispon√≠veis
        financial_features = [col for col in customer_data.columns 
                            if any(word in col for word in ['Margem', 'Desconto', 'Margin', 'Discount'])]
        
        # Adicionar features demogr√°ficas num√©ricas se dispon√≠veis
        demographic_features = [col for col in customer_data.columns 
                              if any(demo in col for demo in ['Idade_first', 'Idade'])]
        
        # Filtrar features que existem nos dados
        all_potential = potential_features + financial_features + demographic_features
        available_features = [f for f in all_potential if f in customer_data.columns]
        
        print(f"üìä Features selecionadas para clustering: {available_features}")
        return available_features
    
    def _real_advanced_clustering(self, customer_data: pd.DataFrame, features: List[str]) -> Dict[str, Any]:
        """Clustering comportamental avan√ßado com dados reais."""
        print("üî¨ Executando clustering avan√ßado com dados REAIS...")
        
        # Preparar dados para clustering
        X = customer_data[features].fillna(0)
        
        # Padronizar
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # Encontrar n√∫mero √≥timo de clusters
        optimal_k = self._find_optimal_clusters_silhouette(X_scaled, max_k=6)
        
        # K-means clustering
        kmeans = KMeans(n_clusters=optimal_k, random_state=42)
        clusters = kmeans.fit_predict(X_scaled)
        
        customer_data['Behavioral_Cluster'] = clusters
        
        # An√°lise dos clusters
        cluster_analysis = {}
        for cluster_id in range(optimal_k):
            cluster_data = customer_data[customer_data['Behavioral_Cluster'] == cluster_id]
            
            cluster_profile = {
                'size': len(cluster_data),
                'percentage': round(len(cluster_data) / len(customer_data) * 100, 1),
                'avg_monetary': round(cluster_data['Monetary'].mean(), 2),
                'avg_frequency': round(cluster_data['Frequency'].mean(), 1),
                'avg_recency': round(cluster_data['Recency'].mean(), 1)
            }
            
            # Adicionar insights demogr√°ficos se dispon√≠veis
            age_cols = [col for col in cluster_data.columns if 'Faixa_Etaria' in col or 'Idade' in col]
            if age_cols and not cluster_data[age_cols[0]].isna().all():
                mode_age = cluster_data[age_cols[0]].mode()
                cluster_profile['dominant_age_group'] = mode_age.iloc[0] if len(mode_age) > 0 else 'N/A'
            
            gender_cols = [col for col in cluster_data.columns if 'Sexo' in col]
            if gender_cols and not cluster_data[gender_cols[0]].isna().all():
                mode_gender = cluster_data[gender_cols[0]].mode()
                cluster_profile['dominant_gender'] = mode_gender.iloc[0] if len(mode_gender) > 0 else 'N/A'
            
            cluster_analysis[f'Cluster_{cluster_id}'] = cluster_profile
        
        return {
            'optimal_clusters': optimal_k,
            'cluster_analysis': cluster_analysis,
            'features_used': features,
            'silhouette_score': round(silhouette_score(X_scaled, clusters), 3)
        }
    
    def _rfm_segmentation(self, customer_data: pd.DataFrame) -> Dict[str, Any]:
        """Segmenta√ß√£o RFM tradicional."""
        try:
            # Calcular scores RFM
            customer_data['R_Score'] = pd.qcut(customer_data['Recency'], 5, labels=[5,4,3,2,1], duplicates='drop')
            customer_data['F_Score'] = pd.qcut(customer_data['Frequency'].rank(method='first'), 5, labels=[1,2,3,4,5], duplicates='drop')
            customer_data['M_Score'] = pd.qcut(customer_data['Monetary'].rank(method='first'), 5, labels=[1,2,3,4,5], duplicates='drop')
            
            # Converter para int
            customer_data['R_Score'] = customer_data['R_Score'].astype(int)
            customer_data['F_Score'] = customer_data['F_Score'].astype(int)
            customer_data['M_Score'] = customer_data['M_Score'].astype(int)
            
            # Classificar segmentos
            customer_data['RFM_Segment'] = customer_data.apply(self._classify_rfm_segment, axis=1)
            
            # An√°lise dos segmentos
            segment_analysis = customer_data.groupby('RFM_Segment').agg({
                'Recency': ['count', 'mean'],
                'Frequency': 'mean',
                'Monetary': ['mean', 'sum'],
                'Customer_Lifetime_Days': 'mean'
            }).round(2)
            
            segment_analysis.columns = ['Count', 'Avg_Recency', 'Avg_Frequency', 'Avg_Monetary', 'Total_Monetary', 'Avg_Lifetime']
            
            # Insights por segmento
            segment_insights = {}
            for segment in customer_data['RFM_Segment'].unique():
                segment_data = customer_data[customer_data['RFM_Segment'] == segment]
                
                insights = []
                avg_monetary = segment_data['Monetary'].mean()
                avg_frequency = segment_data['Frequency'].mean()
                avg_recency = segment_data['Recency'].mean()
                
                if avg_monetary > customer_data['Monetary'].mean() * 1.5:
                    insights.append("Alto valor monet√°rio")
                if avg_frequency > customer_data['Frequency'].mean() * 1.5:
                    insights.append("Alta frequ√™ncia de compra")
                if avg_recency < 30:
                    insights.append("Compra recente")
                elif avg_recency > 180:
                    insights.append("Cliente inativo")
                
                segment_insights[segment] = insights
            
            # Matriz de migra√ß√£o (simulada)
            migration_matrix = self._simulate_segment_migration(customer_data)
            
            return {
                'segmentation_method': 'RFM',
                'segment_distribution': customer_data['RFM_Segment'].value_counts().to_dict(),
                'segment_analysis': segment_analysis.to_dict(),
                'segment_insights': segment_insights,
                'migration_matrix': migration_matrix,
                'total_customers': len(customer_data)
            }
            
        except Exception as e:
            return {'error': f"Erro na segmenta√ß√£o RFM: {str(e)}"}
    
    def _advanced_behavioral_segmentation(self, customer_data: pd.DataFrame) -> Dict[str, Any]:
        """Wrapper para segmenta√ß√£o comportamental avan√ßada."""
        behavioral_features = self._select_behavioral_features(customer_data)
        if len(behavioral_features) >= 3:
            return self._real_advanced_clustering(customer_data, behavioral_features)
        else:
            return {'error': 'Features insuficientes para segmenta√ß√£o comportamental'}
    
    def _value_based_segmentation(self, customer_data: pd.DataFrame) -> Dict[str, Any]:
        """Wrapper para segmenta√ß√£o baseada em valor."""
        return self._value_analysis(customer_data, 'value_based', 90)
    
    def _hybrid_segmentation(self, customer_data: pd.DataFrame) -> Dict[str, Any]:
        """Segmenta√ß√£o h√≠brida combinando m√∫ltiplos crit√©rios."""
        rfm_result = self._rfm_segmentation(customer_data)
        
        # Incluir an√°lises demogr√°ficas se dispon√≠veis
        demographic_cols = [col for col in customer_data.columns if any(demo in col for demo in ['Idade', 'Sexo', 'Estado_Civil'])]
        if demographic_cols:
            demographic_result = self._real_demographic_segmentation(customer_data)
        else:
            demographic_result = {'info': 'Dados demogr√°ficos n√£o dispon√≠veis'}
        
        return {
            'segmentation_method': 'Hybrid (RFM + Demographic + Geographic)',
            'rfm_component': rfm_result,
            'demographic_component': demographic_result,
            'total_customers': len(customer_data)
        }
    
    # M√©todos auxiliares necess√°rios
    def _classify_rfm_segment(self, row) -> str:
        """Classificar segmento RFM."""
        r, f, m = row['R_Score'], row['F_Score'], row['M_Score']
        
        if r >= 4 and f >= 4 and m >= 4:
            return 'Champions'
        elif r >= 3 and f >= 3 and m >= 3:
            return 'Loyal Customers'
        elif r >= 4 and f <= 2:
            return 'New Customers'
        elif r >= 3 and f <= 2:
            return 'Potential Loyalists'
        elif r <= 2 and f >= 3:
            return 'At Risk'
        elif r <= 2 and f <= 2 and m >= 3:
            return 'Cannot Lose Them'
        elif r <= 2 and f <= 2 and m <= 2:
            return 'Lost'
        else:
            return 'Others'
    
    def _find_optimal_clusters_silhouette(self, X: np.ndarray, max_k: int = 8) -> int:
        """Encontrar n√∫mero √≥timo de clusters usando silhouette score."""
        if len(X) < 4:
            return 2
        
        max_k = min(max_k, len(X) - 1)
        silhouette_scores = []
        
        for k in range(2, max_k + 1):
            try:
                kmeans = KMeans(n_clusters=k, random_state=42)
                cluster_labels = kmeans.fit_predict(X)
                silhouette_avg = silhouette_score(X, cluster_labels)
                silhouette_scores.append(silhouette_avg)
            except:
                continue
        
        if silhouette_scores:
            optimal_k = silhouette_scores.index(max(silhouette_scores)) + 2
            return optimal_k
        else:
            return 3
    
    def _analyze_lifecycle_transitions(self, customer_data: pd.DataFrame) -> Dict[str, Any]:
        """Analisar transi√ß√µes do ciclo de vida."""
        # Estimativa baseada em padr√µes
        transitions = {
            'New_to_Growing': 0.65,
            'Growing_to_Loyal': 0.35,
            'Loyal_to_VIP': 0.25,
            'At_Risk_to_Lost': 0.40
        }
        
        return transitions
    
    def _identify_churn_risk_factors(self, customer_data: pd.DataFrame) -> List[str]:
        """Identificar fatores de risco de churn."""
        factors = []
        
        # An√°lise de rec√™ncia
        high_recency = customer_data[customer_data['Recency'] > 180]
        if len(high_recency) > 0:
            factors.append(f"{len(high_recency)} clientes sem compra h√° 6+ meses")
        
        # Baixa frequ√™ncia
        low_frequency = customer_data[customer_data['Frequency'] == 1]
        if len(low_frequency) > 0:
            factors.append(f"{len(low_frequency)} clientes com apenas 1 compra")
        
        # Queda na consist√™ncia
        if 'Purchase_Consistency' in customer_data.columns:
            inconsistent = customer_data[customer_data['Purchase_Consistency'] < 0.3]
            if len(inconsistent) > 0:
                factors.append(f"{len(inconsistent)} clientes com padr√£o irregular")
        
        return factors
    
    def _generate_retention_strategies(self, customer_data: pd.DataFrame) -> Dict[str, List[str]]:
        """Gerar estrat√©gias de reten√ß√£o por segmento."""
        strategies = {}
        
        for risk_category in customer_data['Churn_Risk_Category'].unique():
            if pd.isna(risk_category):
                continue
                
            if risk_category == 'High Risk':
                strategies[risk_category] = [
                    "Contato pessoal imediato",
                    "Oferta especial personalizada",
                    "Programa VIP exclusivo",
                    "Desconto significativo na pr√≥xima compra"
                ]
            elif risk_category == 'Medium Risk':
                strategies[risk_category] = [
                    "Email marketing personalizado",
                    "Lembrete de produtos favoritos",
                    "Programa de fidelidade",
                    "Cross-sell baseado em hist√≥rico"
                ]
            else:  # Low Risk
                strategies[risk_category] = [
                    "Newsletter regular",
                    "Novidades e lan√ßamentos",
                    "Programa de indica√ß√£o",
                    "Manuten√ß√£o do relacionamento"
                ]
        
        return strategies
    
    def _calculate_churn_financial_impact(self, customer_data: pd.DataFrame) -> Dict[str, float]:
        """Calcular impacto financeiro do churn."""
        high_risk = customer_data[customer_data['Churn_Risk_Category'] == 'High Risk']
        
        potential_lost_revenue = high_risk['Monetary'].sum()
        potential_lost_clv = high_risk['CLV_Estimado'].sum() if 'CLV_Estimado' in customer_data.columns else potential_lost_revenue * 1.5
        
        return {
            'high_risk_current_value': round(potential_lost_revenue, 2),
            'potential_lost_clv': round(potential_lost_clv, 2),
            'retention_investment_suggested': round(potential_lost_clv * 0.1, 2)  # 10% do CLV
        }
    
    def _analyze_value_concentration(self, customer_data: pd.DataFrame) -> Dict[str, float]:
        """Analisar concentra√ß√£o de valor."""
        # Regra 80/20
        clv_column = 'CLV_Estimado' if 'CLV_Estimado' in customer_data.columns else 'Monetary'
        
        sorted_customers = customer_data.sort_values(clv_column, ascending=False)
        top_20_pct = int(len(sorted_customers) * 0.2)
        
        top_20_value = sorted_customers.head(top_20_pct)[clv_column].sum()
        total_value = sorted_customers[clv_column].sum()
        
        concentration_80_20 = (top_20_value / total_value * 100) if total_value > 0 else 0
        
        return {
            'top_20_percent_value_share': round(concentration_80_20, 1),
            'value_distribution': 'Concentrated' if concentration_80_20 > 80 else 'Balanced'
        }
    
    def _analyze_stage_transitions(self, customer_data: pd.DataFrame) -> Dict[str, float]:
        """Analisar transi√ß√µes entre est√°gios da jornada."""
        # Estimativas baseadas em padr√µes t√≠picos
        transitions = {
            'new_to_growing': 0.45,
            'growing_to_loyal': 0.35,
            'loyal_to_vip': 0.20
        }
        
        return transitions
    
    def _identify_friction_points(self, customer_data: pd.DataFrame) -> List[str]:
        """Identificar pontos de atrito na jornada."""
        friction_points = []
        
        # Alta taxa de clientes one-time
        one_time = len(customer_data[customer_data['Frequency'] == 1])
        one_time_rate = one_time / len(customer_data) * 100
        
        if one_time_rate > 60:
            friction_points.append(f"Alta taxa de one-time buyers ({one_time_rate:.1f}%)")
        
        # Longo intervalo entre compras
        avg_interval = customer_data['Avg_Days_Between_Purchases'].mean()
        if avg_interval > 180:
            friction_points.append(f"Intervalo longo entre compras ({avg_interval:.0f} dias)")
        
        # Baixa convers√£o para alto valor
        high_value = len(customer_data[customer_data['Monetary'] > customer_data['Monetary'].quantile(0.8)])
        high_value_rate = high_value / len(customer_data) * 100
        
        if high_value_rate < 15:
            friction_points.append(f"Baixa convers√£o para alto valor ({high_value_rate:.1f}%)")
        
        return friction_points

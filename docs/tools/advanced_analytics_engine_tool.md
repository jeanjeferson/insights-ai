# ü§ñ ADVANCED ANALYTICS ENGINE TOOL - DOCUMENTA√á√ÉO COMPLETA

## üìã **VIS√ÉO GERAL**

O `AdvancedAnalyticsEngineTool` √© um motor de an√°lises avan√ßadas com Machine Learning especialmente otimizado para joalherias. Combina algoritmos como Random Forest, XGBoost e t√©cnicas de clustering para descobrir padr√µes ocultos, prever demanda e otimizar processos de neg√≥cio.

### **Caracter√≠sticas Principais:**
- ü§ñ **Machine Learning Avan√ßado**: Random Forest, XGBoost, Isolation Forest
- üìä **An√°lises Especializadas**: 7 tipos de an√°lises para diferentes necessidades
- üéØ **Adaptativo**: Ajusta-se automaticamente √† quantidade de dados dispon√≠veis
- üìà **Previs√µes Robustas**: Intervalos de confian√ßa e valida√ß√£o estat√≠stica
- üíæ **Cache Inteligente**: Otimiza√ß√£o de performance para datasets grandes
- üìã **Schema Pydantic**: Valida√ß√µes rigorosas de entrada

---

## üèóÔ∏è **ARQUITETURA DA CLASSE**

### **Heran√ßa e Mixins:**
```python
class AdvancedAnalyticsEngineTool(BaseTool,
                                  DataPreparationMixin,
                                  ReportFormatterMixin,
                                  JewelryRFMAnalysisMixin,
                                  JewelryBusinessAnalysisMixin)
```

### **Schema de Entrada (Pydantic):**
- `analysis_type`: Tipo de an√°lise (7 op√ß√µes dispon√≠veis)
- `data_csv`: Caminho do arquivo CSV (padr√£o: "data/vendas.csv")
- `target_column`: Coluna alvo (padr√£o: "Total_Liquido")
- `prediction_horizon`: Horizonte de predi√ß√£o em dias (7-365)
- `confidence_level`: N√≠vel de confian√ßa (0.80-0.99)
- `model_complexity`: Complexidade do modelo ("simple", "balanced", "complex")
- `enable_ensemble`: Usar ensemble de modelos (recomendado: True)
- `sample_size`: Tamanho da amostra (5000-100000, None = todos)
- `cache_results`: Usar cache (recomendado: True)

---

## üéØ **FUN√á√ïES PRINCIPAIS**

### **1. `_run()` - Fun√ß√£o Principal de Execu√ß√£o**

**Objetivo:** Coordena todo o processo de an√°lise ML, desde valida√ß√£o at√© gera√ß√£o de resultados.

**Funcionamento:**
1. Valida disponibilidade de bibliotecas ML
2. Carrega e prepara dados usando m√≥dulos consolidados
3. Valida qualidade dos dados para ML
4. Executa an√°lise espec√≠fica selecionada
5. Adiciona metadados e salva no cache
6. Retorna resultado JSON estruturado

**Interpreta√ß√£o dos Resultados:**
- **Sucesso**: JSON com an√°lise completa e metadados
- **Erro**: JSON com erro detalhado e troubleshooting
- **Metadados**: Informa√ß√µes sobre o processo executado

---

### **2. `_load_and_prepare_ml_data()` - Carregamento e Prepara√ß√£o**

**Objetivo:** Carregar dados do CSV e prepar√°-los especificamente para an√°lises ML.

**Funcionamento:**
1. Verifica cache existente
2. Carrega dados do CSV com encoding correto
3. Aplica amostragem se necess√°rio
4. Executa prepara√ß√£o strict usando mixin consolidado
5. Adiciona features espec√≠ficas para ML
6. Salva no cache para reutiliza√ß√£o

**Par√¢metros:**
- `data_csv`: Caminho do arquivo
- `use_cache`: Usar cache (True/False)
- `sample_size`: Tamanho da amostra (opcional)

**Interpreta√ß√£o:**
- **Sucesso**: DataFrame preparado com features ML
- **Falha**: None (dados insuficientes ou erro de carregamento)

---

### **3. `_add_ml_features()` - Engenharia de Features**

**Objetivo:** Criar features espec√≠ficas para Machine Learning a partir dos dados brutos.

**Features Criadas:**

#### **Features Temporais:**
- `Days_Since_Start`: Dias desde o in√≠cio do per√≠odo
- `Month_Sin/Cos`: Sazonalidade circular mensal
- `Day_Of_Week`: Dia da semana (0-6)

#### **Features de Agrega√ß√£o:**
- `Customer_Frequency`: Frequ√™ncia de compras do cliente
- `Customer_AOV`: Ticket m√©dio do cliente
- `Customer_Total`: Total gasto pelo cliente
- `Product_Frequency`: Frequ√™ncia de venda do produto
- `Product_AOV`: Pre√ßo m√©dio do produto

#### **Encoding Categ√≥rico:**
- **Label Encoding**: Para vari√°veis com >10 categorias
- **One-Hot Encoding**: Para vari√°veis com ‚â§10 categorias

#### **Normaliza√ß√£o:**
- Campos num√©ricos s√£o normalizados com StandardScaler
- Criadas vers√µes `_scaled` dos campos originais

**Interpreta√ß√£o:**
- Features temporais capturam sazonalidade
- Features de agrega√ß√£o capturam comportamento
- Encoding permite uso de vari√°veis categ√≥ricas
- Normaliza√ß√£o melhora performance dos algoritmos

---

## üî¨ **AN√ÅLISES ESPECIALIZADAS**

### **4. `_ml_insights_analysis()` - Insights com ML**

**Objetivo:** Descobrir padr√µes ocultos usando Random Forest e XGBoost.

**Algoritmos Utilizados:**
- **Random Forest**: Ensemble de √°rvores de decis√£o
- **XGBoost**: Gradient boosting otimizado (se dispon√≠vel)

**Configura√ß√£o por Complexidade:**
- **Simple**: Random Forest com 50 estimadores
- **Balanced**: Random Forest (100) + XGBoost (100)
- **Complex**: Random Forest (200) + XGBoost (200)

**Estrutura do Resultado:**
```json
{
  "analysis_type": "ML Insights Analysis",
  "target_column": "Total_Liquido",
  "model_performance": {
    "Random Forest": {
      "mae": 123.45,
      "mse": 15432.10,
      "rmse": 124.23,
      "r2_score": 0.847
    }
  },
  "feature_importance": {
    "top_features": [
      {"feature": "Customer_AOV", "importance": 0.234},
      {"feature": "Product_Frequency", "importance": 0.187}
    ],
    "best_model": "Random Forest"
  },
  "business_insights": [...],
  "recommendations": [...]
}
```

**Interpreta√ß√£o das M√©tricas:**
- **MAE** (Mean Absolute Error): Erro m√©dio absoluto em unidades originais
- **MSE** (Mean Squared Error): Erro quadr√°tico m√©dio
- **RMSE** (Root MSE): Raiz do erro quadr√°tico (mesma unidade da vari√°vel)
- **R¬≤ Score**: Coeficiente de determina√ß√£o (0-1, quanto maior melhor)
  - > 0.8: Modelo excelente
  - 0.6-0.8: Modelo bom
  - < 0.6: Modelo limitado

**Feature Importance:**
- Indica quais vari√°veis mais influenciam o resultado
- Use para identificar fatores-chave do neg√≥cio
- Priorize otimiza√ß√µes nas features mais importantes

---

### **5. `_anomaly_detection_analysis()` - Detec√ß√£o de Anomalias**

**Objetivo:** Identificar transa√ß√µes ou padr√µes an√¥malos usando Isolation Forest.

**Algoritmo:** Isolation Forest
- Identifica pontos que s√£o facilmente "isolados" do restante dos dados
- Contamination = 0.1 (10% das observa√ß√µes consideradas an√¥malas)

**Estrutura do Resultado:**
```json
{
  "analysis_type": "Anomaly Detection Analysis",
  "target_column": "Total_Liquido",
  "total_anomalies": 142,
  "anomaly_percentage": 2.3,
  "anomaly_summary": {
    "avg_value": 1245.67,
    "max_value": 15432.10,
    "min_value": 23.45
  },
  "business_insights": [...],
  "recommendations": [...]
}
```

**Interpreta√ß√£o:**
- **total_anomalies**: N√∫mero absoluto de anomalias detectadas
- **anomaly_percentage**: Percentual do total de dados
- **anomaly_summary**: Estat√≠sticas das transa√ß√µes an√¥malas

**Casos de Uso:**
- Identificar vendas excepcionalmente altas (oportunidades)
- Detectar vendas suspeitas (poss√≠veis erros)
- Encontrar padr√µes de compra √∫nicos
- Investigar transa√ß√µes para insights de neg√≥cio

---

### **6. `_demand_forecasting_analysis()` - Previs√£o de Demanda Adaptativa**

**Objetivo:** Prever demanda futura adaptando-se ao volume de dados dispon√≠veis.

**Estrat√©gia Adaptativa:**

#### **Dados Limitados (<14 dias):**
- **M√©todo**: M√©dias m√≥veis simples
- **Features**: M√©dias dos √∫ltimos 7/14 dias
- **Confiabilidade**: Baixa - experimental

#### **Dados Moderados (14-30 dias):**
- **M√©todo**: Random Forest b√°sico (50 estimadores)
- **Features**: day_of_week, month, lag_3, lag_7, rolling_mean_3
- **Confiabilidade**: M√©dia - adequado para orienta√ß√£o

#### **Dados Abundantes (>30 dias):**
- **M√©todo**: Random Forest completo (50-200 estimadores)
- **Features**: Lags m√∫ltiplos, m√©dias m√≥veis, tend√™ncias, sazonalidade
- **Confiabilidade**: Alta - adequado para planejamento

**Features Utilizadas:**
- **Lags**: Valores hist√≥ricos (lag_3, lag_7, lag_14, lag_30)
- **Rolling**: M√©dias e desvios m√≥veis
- **Temporais**: Dia da semana, m√™s, trimestre
- **Tend√™ncia**: Tend√™ncia linear e sazonalidade circular

**Estrutura do Resultado:**
```json
{
  "analysis_type": "Demand Forecasting Analysis",
  "target_column": "Total_Liquido",
  "prediction_horizon": 30,
  "data_summary": {
    "total_period_days": 730,
    "actual_data_days": 485,
    "data_coverage": 66.4,
    "model_type": "Random Forest (Balanced)",
    "features_count": 12
  },
  "forecast_summary": {
    "avg_predicted": 1234.56,
    "total_predicted": 37036.80,
    "min_predicted": 856.23,
    "max_predicted": 1876.45,
    "confidence_lower": 987.65,
    "confidence_upper": 1481.47
  },
  "historical_baseline": {
    "avg_daily": 1198.34,
    "recent_avg": 1289.67,
    "trend": "crescente"
  },
  "daily_predictions": [
    {
      "date": "2024-01-01",
      "predicted_value": 1245.67,
      "confidence_lower": 996.54,
      "confidence_upper": 1494.80
    }
  ],
  "business_insights": [...],
  "recommendations": [...]
}
```

**Interpreta√ß√£o dos Resultados:**

#### **Data Summary:**
- **total_period_days**: Per√≠odo total dos dados
- **actual_data_days**: Dias com dados reais
- **data_coverage**: Percentual de cobertura
- **model_type**: Tipo de modelo utilizado
- **features_count**: N√∫mero de features

#### **Forecast Summary:**
- **avg_predicted**: Demanda m√©dia prevista
- **total_predicted**: Demanda total no per√≠odo
- **confidence_lower/upper**: Intervalos de confian√ßa

#### **Historical Baseline:**
- **avg_daily**: M√©dia hist√≥rica di√°ria
- **recent_avg**: M√©dia dos √∫ltimos 7 dias
- **trend**: Dire√ß√£o da tend√™ncia

#### **Daily Predictions:**
- Previs√µes di√°rias detalhadas
- Intervalos de confian√ßa por dia
- Primeiros 15 dias do horizonte

**Como Usar:**
1. **Planejamento de Estoque**: Use total_predicted para compras
2. **Gest√£o de Caixa**: Use avg_predicted para fluxo di√°rio
3. **An√°lise de Risco**: Use intervalos de confian√ßa
4. **Monitoramento**: Compare realizados vs. previstos

---

### **7. `_customer_behavior_analysis()` - Segmenta√ß√£o Comportamental**

**Objetivo:** Segmentar clientes baseado em padr√µes comportamentais usando clustering ML.

**Algoritmo:** K-Means Clustering
- Utiliza StandardScaler para normaliza√ß√£o
- K √≥timo calculado heuristicamente (min(5, clientes/10))

**Features para Clustering:**
- **Frequ√™ncia**: N√∫mero de transa√ß√µes
- **Valor Monet√°rio**: Soma e m√©dia de gastos
- **Rec√™ncia**: Dias desde √∫ltima compra
- **Volume**: Quantidade total comprada

**Estrutura do Resultado:**
```json
{
  "analysis_type": "Customer Behavior Analysis",
  "target_column": "Total_Liquido",
  "total_customers": 1247,
  "clusters_identified": 4,
  "cluster_profiles": {
    "Cluster_0": {
      "size": 312,
      "size_percentage": 25.0,
      "avg_revenue": 2345.67,
      "avg_frequency": 8.5,
      "avg_recency": 15.2,
      "total_revenue": 731849.04,
      "classification": "VIP"
    }
  },
  "business_insights": [...],
  "recommendations": [...]
}
```

**Classifica√ß√£o Autom√°tica dos Clusters:**
- **VIP**: Revenue > percentil 80
- **Frequente**: Frequency > percentil 70
- **Ativo**: Recency < 30 dias
- **Regular**: Demais casos

**Interpreta√ß√£o dos Profiles:**
- **size**: N√∫mero de clientes no cluster
- **size_percentage**: Percentual do total
- **avg_revenue**: Receita m√©dia por cliente
- **avg_frequency**: Frequ√™ncia m√©dia de compras
- **avg_recency**: Dias m√©dios desde √∫ltima compra
- **total_revenue**: Receita total do cluster

**Estrat√©gias por Segmento:**
- **VIP**: Programas de fidelidade premium, atendimento personalizado
- **Frequente**: Recompensas por frequ√™ncia, produtos exclusivos
- **Ativo**: Manter engajamento, cross-sell
- **Regular**: Campanhas de ativa√ß√£o, ofertas especiais

---

## üõ†Ô∏è **FUN√á√ïES AUXILIARES**

### **8. `_select_ml_features()` - Sele√ß√£o de Features**

**Objetivo:** Selecionar automaticamente as melhores features para ML.

**Crit√©rios de Sele√ß√£o:**
1. Apenas campos num√©ricos
2. Excluir vari√°veis n√£o-preditivas (IDs, datas)
3. Remover campos com todos valores nulos
4. Limitar a 20 features (evitar overfitting)

**Features Priorizadas:**
- Features engineered (_scaled, _encoded)
- Campos de valor e quantidade
- Features de agrega√ß√£o (Customer_*, Product_*)
- Features temporais (Month_Sin, Day_Of_Week)

---

### **9. `_configure_ml_models()` - Configura√ß√£o de Modelos**

**Objetivo:** Configurar modelos ML baseado na complexidade desejada.

**Configura√ß√µes por Complexidade:**

#### **Simple:**
- Random Forest: 50 estimadores
- Execu√ß√£o r√°pida, menor precis√£o

#### **Balanced (Padr√£o):**
- Random Forest: 100 estimadores
- XGBoost: 100 estimadores (se dispon√≠vel)
- Equil√≠brio entre velocidade e precis√£o

#### **Complex:**
- Random Forest: 200 estimadores, max_depth=10
- XGBoost: 200 estimadores, max_depth=6
- Maior precis√£o, execu√ß√£o mais lenta

---

### **10. `_generate_adaptive_predictions()` - Previs√µes Adaptativas**

**Objetivo:** Gerar previs√µes futuras usando modelo treinado e simula√ß√£o temporal.

**Processo:**
1. Para cada dia futuro, constr√≥i features baseadas em:
   - Data futura (day_of_week, month, etc.)
   - Valores hist√≥ricos (lags)
   - M√©dias m√≥veis calculadas
2. Aplica modelo treinado
3. Valida resultado (n√£o negativo, limite superior)
4. Atualiza hist√≥rico para pr√≥xima previs√£o

**Sanidade Checks:**
- Valores n√£o podem ser negativos
- Limite superior: 3x a m√©dia recente
- Continuidade temporal nas previs√µes

---

### **11. `_calculate_prediction_confidence()` - Intervalos de Confian√ßa**

**Objetivo:** Calcular intervalos de confian√ßa adaptativos para previs√µes.

**Metodologia:**
1. Calcula coeficiente de varia√ß√£o hist√≥rico
2. Define fator de confian√ßa entre 10% e 30%
3. Aplica fatores √†s previs√µes

**Interpreta√ß√£o:**
- **confidence_level**: N√≠vel de confian√ßa calculado
- **lower/upper_factor**: Multiplicadores para intervalos
- Maior variabilidade hist√≥rica = intervalos mais amplos

---

## üìä **INTERPRETA√á√ÉO AVAN√áADA DE RESULTADOS**

### **M√©tricas de Performance dos Modelos:**

#### **R¬≤ Score (Coeficiente de Determina√ß√£o):**
- **0.9-1.0**: Excelente - Modelo explica >90% da vari√¢ncia
- **0.7-0.9**: Muito Bom - Adequado para decis√µes estrat√©gicas
- **0.5-0.7**: Bom - √ötil para an√°lises t√°ticas
- **0.3-0.5**: Regular - Insights limitados
- **<0.3**: Pobre - Necessita mais dados ou features

#### **RMSE vs. M√©dia:**
- **RMSE < 10% da m√©dia**: Excelente precis√£o
- **RMSE 10-20% da m√©dia**: Boa precis√£o
- **RMSE 20-30% da m√©dia**: Precis√£o limitada
- **RMSE > 30% da m√©dia**: Baixa precis√£o

### **Feature Importance:**
- **>0.2**: Feature cr√≠tica - foco estrat√©gico
- **0.1-0.2**: Feature importante - monitorar
- **0.05-0.1**: Feature moderada - considerar
- **<0.05**: Feature irrelevante - pode remover

### **Confian√ßa das Previs√µes:**
- **Confidence Level >0.8**: Previs√µes muito confi√°veis
- **Confidence Level 0.6-0.8**: Previs√µes confi√°veis
- **Confidence Level <0.6**: Previs√µes indicativas

---

## üéØ **CASOS DE USO PR√ÅTICOS**

### **1. Planejamento de Compras:**
```python
# Usar demand_forecasting com horizon=90 para trimestre
result = tool._run(
    analysis_type="demand_forecasting",
    prediction_horizon=90,
    model_complexity="balanced"
)
# Interpretar: total_predicted para volume de compras
```

### **2. Identifica√ß√£o de Oportunidades:**
```python
# Usar anomaly_detection para encontrar padr√µes √∫nicos
result = tool._run(
    analysis_type="anomaly_detection",
    target_column="Total_Liquido"
)
# Investigar anomalias com valores altos
```

### **3. Segmenta√ß√£o para Marketing:**
```python
# Usar customer_behavior para campanhas direcionadas
result = tool._run(
    analysis_type="customer_behavior"
)
# Desenvolver estrat√©gias por cluster_profiles
```

### **4. Otimiza√ß√£o de Fatores-Chave:**
```python
# Usar ml_insights para identificar drivers de vendas
result = tool._run(
    analysis_type="ml_insights",
    model_complexity="complex",
    enable_ensemble=True
)
# Focar nas top_features para maximizar impacto
```

---

## ‚ö†Ô∏è **TROUBLESHOOTING COMUM**

### **Problemas de Dados:**

#### **"Dados insuficientes para ML":**
- **Causa**: Menos de 100 registros
- **Solu√ß√£o**: Aumentar per√≠odo ou usar Statistical Analysis Tool

#### **"Coluna alvo n√£o encontrada":**
- **Causa**: target_column incorreto
- **Solu√ß√£o**: Verificar nomes exatos das colunas (use 'Total_Liquido')

#### **"Features insuficientes":**
- **Causa**: Dados muito simples ou muitos NaN
- **Solu√ß√£o**: Melhorar qualidade dos dados ou usar KPI Calculator

### **Problemas de Performance:**

#### **Execu√ß√£o muito lenta:**
- Use `sample_size=10000` para datasets grandes
- Configure `model_complexity="simple"`
- Ative `cache_results=True`

#### **Baixa precis√£o do modelo:**
- Aumente `model_complexity="complex"`
- Colete mais dados hist√≥ricos
- Verifique qualidade dos dados

### **Problemas de Bibliotecas:**

#### **"Scikit-learn n√£o dispon√≠vel":**
```bash
pip install scikit-learn
```

#### **"XGBoost n√£o dispon√≠vel":**
```bash
pip install xgboost
```

---

## üìà **RECOMENDA√á√ïES DE USO**

### **Para Datasets Pequenos (<1000 registros):**
- Use `model_complexity="simple"`
- Configure `sample_size=None`
- Prefira Statistical Analysis Tool para an√°lises b√°sicas

### **Para Datasets M√©dios (1000-10000 registros):**
- Use `model_complexity="balanced"` (padr√£o)
- Configure `enable_ensemble=True`
- Ative `cache_results=True`

### **Para Datasets Grandes (>10000 registros):**
- Use `model_complexity="complex"` para m√°xima precis√£o
- Configure `sample_size=50000` se necess√°rio
- Use `cache_results=True` obrigatoriamente

### **Para An√°lises em Produ√ß√£o:**
- Sempre valide resultados com equipe de neg√≥cio
- Monitore desvios entre previsto vs. realizado
- Atualize modelos mensalmente com novos dados
- Mantenha hist√≥rico de performance dos modelos

---

## üîÑ **PR√ìXIMAS VERS√ïES**

### **Placeholders Ativos (v4.1):**
- `_product_lifecycle_analysis()`: An√°lise de ciclo de vida completa
- `_price_optimization_analysis()`: Otimiza√ß√£o de pre√ßos com elasticidade
- `_inventory_optimization_analysis()`: Gest√£o otimizada de estoque

### **Melhorias Planejadas:**
- Deep Learning com redes neurais
- An√°lise de s√©ries temporais com ARIMA/Prophet
- A/B Testing automatizado
- Integra√ß√£o com dados externos (economia, concorr√™ncia)

---

*Documenta√ß√£o gerada automaticamente - Advanced Analytics Engine Tool v4.0* 